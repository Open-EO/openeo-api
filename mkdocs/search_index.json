{
    "docs": [
        {
            "location": "/index.html",
            "text": "OpenEO - Core Concepts and API Reference\n\n\nWork in progress, please contribute by adding \nissues\n.\n\n\nopenEO develops an open API that connects clients like R, python and javascript to big Earth observation cloud back-ends in a simple and unified way. \n\n\nThe following pages introduce the core concepts of the project. Make sure to introduce yourself to the major technical terms used in the openEO project by reading the \nglossary\n.\n\n\nThe OpenEO Core API defines a \nRESTful API\n that lets cloud back-ends with large Earth observation datasets communicate with front end analysis applications in an interoperable way. This documentation describes important API concepts and design decisions and gives a complete \nAPI reference documentation\n.\n\n\nAs an overview, the OpenEO API specifies how to\n\n\n\n\ndiscover which Earth observation data and processes are available at cloud back-ends,\n\n\nexecute (chained) processes on back-ends, \n\n\nrun \nuser-defined functions\n (UDFs) on back-ends where UDFs can be exposed to the data in different ways, \n\n\ndownload (intermediate) results as web services, and\n\n\nmanage user content including accounting.\n\n\n\n\nThe API is defined as an \nOpenAPI 2.0\n (formerly known as Swagger 2.0) JSON file.\n\n\n \n\n\nOpenEO\n, A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications is a H2020 project funded under call EO-2-2017: EO Big Data Shift, under proposal number 776242. It will run from Oct 2017 to Sept 2020.",
            "title": "Home"
        },
        {
            "location": "/index.html#openeo-core-concepts-and-api-reference",
            "text": "Work in progress, please contribute by adding  issues .  openEO develops an open API that connects clients like R, python and javascript to big Earth observation cloud back-ends in a simple and unified way.   The following pages introduce the core concepts of the project. Make sure to introduce yourself to the major technical terms used in the openEO project by reading the  glossary .  The OpenEO Core API defines a  RESTful API  that lets cloud back-ends with large Earth observation datasets communicate with front end analysis applications in an interoperable way. This documentation describes important API concepts and design decisions and gives a complete  API reference documentation .  As an overview, the OpenEO API specifies how to   discover which Earth observation data and processes are available at cloud back-ends,  execute (chained) processes on back-ends,   run  user-defined functions  (UDFs) on back-ends where UDFs can be exposed to the data in different ways,   download (intermediate) results as web services, and  manage user content including accounting.   The API is defined as an  OpenAPI 2.0  (formerly known as Swagger 2.0) JSON file.     OpenEO , A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications is a H2020 project funded under call EO-2-2017: EO Big Data Shift, under proposal number 776242. It will run from Oct 2017 to Sept 2020.",
            "title": "OpenEO - Core Concepts and API Reference"
        },
        {
            "location": "/glossary/index.html",
            "text": "Glossary\n\n\nThis glossary introduces, and tries to define, the major technical terms used in the openEO project.\n\n\nThe acronym \nopenEO\n contracts two concepts:\n\n\n\n\nopen\n: used here in the context of open source software; open source software is available in source code form, and can be freely modified and redistributed; the openEO project will create open source software, reusable under a liberal open source license (Apache 2.0)\n\n\nEO\n: Earth observation; openEO targets the processing and analysis of Earth observation data\n\n\n\n\nFurther terms:\n\n\n\n\nAPI\n: application programming interface (\nwikipedia\n); a communication protocol between client and back-end\n\n\nclient\n: software environment (software) that end-users directly interact with, e.g. R (rstudio), python (jupyter notebook), and javascript (web browser); R and python are two major data science platforms; javascript is a major language for web development\n\n\n(cloud) back-end\n: server; computer infrastructure (one or more physical computers or virtual machines) used for storing EO data and processing it\n\n\nbig Earth observation cloud back-end\n server infrastructure where industry and researchers analyse large amounts of EO data\n\n\nsimple\n many end-users now use python or R to analyse data and javascript to develop web applications; analysing large amounts of EO imagery should be equally simple, and seamlessly integrate with existing workflows\n\n\nunified\n current EO cloud back-ends all have \na different API\n, making EO data analysis hard to validate,difficult to reproduce, and back-ends difficult to compare in terms of capability and costs, or to combine in a joint analysis across back-ends. A unified API can resolve many of these problems.\n\n\n\n\nDatasets\n\n\nCEOS (\nCEOS OpenSearch Best Practice Document v1.2\n) defines \nGranules\n and \nCollections\n as follows: \"A \ngranule\n is the finest granularity of data that can be independently managed. A granule usually matches the individual file of EO satellite data.\", and \"A \ncollection\n is an aggregation of granules sharing the same product specification. A collection typically corresponds to the series of products derived from data acquired by a sensor on board a satellite and having the same mode of operation.\"\n\n\nThe same document lists the synonyms used (by organisations) for:\n\n\n\n\ngranule\n: dataset (ISO 19115), dataset (ESA), granule (NASA), product (ESA, CNES), scene (JAXA)\n\n\ncollection\n: dataset series (ISO 19115), collection (CNES, NASA), dataset (JAXA), dataset series (ESA), product (JAXA)\n\n\n\n\nHere, we will use \ngranule\n and \ncollection\n.\n\n\nA \ngranule\n will typically refer to a limited area and a single overpass leading to a very short observation period (seconds), or a temporal aggregation of such data as e.g. for 16-day MODIS composites.\n\n\nThe open geospatial consortium published a document on \nOGC OpenSearch Geo and Time Extensions\n.\n\n\nProcesses and Jobs\n\n\nThe terms \nprocess\n, \nprocess graph\n and \njob\n have different meanings in the OpenEO API specification.\n\n\nA \nprocess\n is simply the description of an operation as provided by the back end, similar to a function definition in programming languages. \n\n\nIn this context OpenEO will:\n\n\n\n\nconsider, or allow to consider, band as a dimension\n\n\nconsider imagery (image collections) to consist of one \nor more\n collections, as argument to functions; allow filtering on a particular collection, or joining them into a single collection\n\n\nallow filtering on attributes, e.g. on cloud-free pixels, or pixels inside a \nMULTIPOLYGON\n describing the floodplains of the Danube. This filters on attributes rather than dimensions.\n\n\nProvide generic aggregate operations that aggregate over one or more dimenions. Clients may provide dimension-specific aggregation functions for particular cases (such as \nmin_time\n) \n\n\n\n\nA \nprocess graph\n includes specific process calls, i.e. references to one or more processes including specific values for input arguments similar to a function call in programming. However, process graphs can chain multiple processes. In particular, arguments of processes in general can be again (recursive) process graphs, input datasets, or simple scalar or array values.\n\n\nA \njob\n brings one process graph to the back-end and organizes its execution, which may or may not induce costs. Jobs furthermore allow to run process graphs from different \ndata views\n (see section on \ndata views\n). Views define at which resolution and extent we look at the data during processing and hence allow to try out process graphs on small subsets, or work interactively within web map applications. For more information about jobs and their evaluation types, see the section on \njobs\n.\n\n\nAggregation vs. resampling\n\n\nAggregation\n computes new values from sets of values that are \nuniquely\n assigned to groups. It involves a grouping predicate (e.g. monthly, 100 m x 100 m grid cells; think of SQL's \ngroup_by\n), and an aggregation function (e.g., \nmean\n) that computes one or more new values from the original ones.\n\n\nExamples:\n\n\n\n\na time series aggregation may return a regression slope and intercept for every pixel time series, for a single band (group by: full time extent)\n\n\na time series may be aggregated to monthly values by computing the mean for all values in a month (group by: months)\n\n\nspatial\n aggregation involves computing e.g. \nmean\n pixel values on a 100 x 100 m grid, from 10 m x 10 m pixels, where each original pixel is assigned uniquely to a larger pixel (group by: 100 m x 100 m grid cells)\n\n\n\n\nNote that for the first example, the aggregation function not only requires time series values, but also their time stamps.\n\n\nResampling\n is a broader term where we have data at one resolution, and need values at another (also called \nscaling\n). In case we have values at a 100 m x 100 m grid and need values at a 10 m x 10 m grid, the original values will be reused many times, and may be be simply assigned to the nearest high resolution grid cells (\"nearest neighbor\"), or may be interpolated somehow (e.g. by bilinear interpolation). Resampling from finer to coarser grid by nearest neighbor may again be a special case of aggregation.\n\n\nWhen the target grid or time series has a lower resolution (larger grid cells) or lower frequency (longer time intervals) than the source grid, aggregation might be used for resampling. For example, if the resolutions are fairly similar, say the source collection has values for consecutive 10 day intervals and the target needs values for consecutive 16 day intervals, then some form of interpolation may be more appropriate than aggregation as defined here.\n\n\nAPI\n\n\nThe API developed by the openEO project uses \nHTTP REST\n for communication between client and back-end server.",
            "title": "Glossary"
        },
        {
            "location": "/glossary/index.html#glossary",
            "text": "This glossary introduces, and tries to define, the major technical terms used in the openEO project.  The acronym  openEO  contracts two concepts:   open : used here in the context of open source software; open source software is available in source code form, and can be freely modified and redistributed; the openEO project will create open source software, reusable under a liberal open source license (Apache 2.0)  EO : Earth observation; openEO targets the processing and analysis of Earth observation data   Further terms:   API : application programming interface ( wikipedia ); a communication protocol between client and back-end  client : software environment (software) that end-users directly interact with, e.g. R (rstudio), python (jupyter notebook), and javascript (web browser); R and python are two major data science platforms; javascript is a major language for web development  (cloud) back-end : server; computer infrastructure (one or more physical computers or virtual machines) used for storing EO data and processing it  big Earth observation cloud back-end  server infrastructure where industry and researchers analyse large amounts of EO data  simple  many end-users now use python or R to analyse data and javascript to develop web applications; analysing large amounts of EO imagery should be equally simple, and seamlessly integrate with existing workflows  unified  current EO cloud back-ends all have  a different API , making EO data analysis hard to validate,difficult to reproduce, and back-ends difficult to compare in terms of capability and costs, or to combine in a joint analysis across back-ends. A unified API can resolve many of these problems.",
            "title": "Glossary"
        },
        {
            "location": "/glossary/index.html#datasets",
            "text": "CEOS ( CEOS OpenSearch Best Practice Document v1.2 ) defines  Granules  and  Collections  as follows: \"A  granule  is the finest granularity of data that can be independently managed. A granule usually matches the individual file of EO satellite data.\", and \"A  collection  is an aggregation of granules sharing the same product specification. A collection typically corresponds to the series of products derived from data acquired by a sensor on board a satellite and having the same mode of operation.\"  The same document lists the synonyms used (by organisations) for:   granule : dataset (ISO 19115), dataset (ESA), granule (NASA), product (ESA, CNES), scene (JAXA)  collection : dataset series (ISO 19115), collection (CNES, NASA), dataset (JAXA), dataset series (ESA), product (JAXA)   Here, we will use  granule  and  collection .  A  granule  will typically refer to a limited area and a single overpass leading to a very short observation period (seconds), or a temporal aggregation of such data as e.g. for 16-day MODIS composites.  The open geospatial consortium published a document on  OGC OpenSearch Geo and Time Extensions .",
            "title": "Datasets"
        },
        {
            "location": "/glossary/index.html#processes-and-jobs",
            "text": "The terms  process ,  process graph  and  job  have different meanings in the OpenEO API specification.  A  process  is simply the description of an operation as provided by the back end, similar to a function definition in programming languages.   In this context OpenEO will:   consider, or allow to consider, band as a dimension  consider imagery (image collections) to consist of one  or more  collections, as argument to functions; allow filtering on a particular collection, or joining them into a single collection  allow filtering on attributes, e.g. on cloud-free pixels, or pixels inside a  MULTIPOLYGON  describing the floodplains of the Danube. This filters on attributes rather than dimensions.  Provide generic aggregate operations that aggregate over one or more dimenions. Clients may provide dimension-specific aggregation functions for particular cases (such as  min_time )    A  process graph  includes specific process calls, i.e. references to one or more processes including specific values for input arguments similar to a function call in programming. However, process graphs can chain multiple processes. In particular, arguments of processes in general can be again (recursive) process graphs, input datasets, or simple scalar or array values.  A  job  brings one process graph to the back-end and organizes its execution, which may or may not induce costs. Jobs furthermore allow to run process graphs from different  data views  (see section on  data views ). Views define at which resolution and extent we look at the data during processing and hence allow to try out process graphs on small subsets, or work interactively within web map applications. For more information about jobs and their evaluation types, see the section on  jobs .  Aggregation vs. resampling  Aggregation  computes new values from sets of values that are  uniquely  assigned to groups. It involves a grouping predicate (e.g. monthly, 100 m x 100 m grid cells; think of SQL's  group_by ), and an aggregation function (e.g.,  mean ) that computes one or more new values from the original ones.  Examples:   a time series aggregation may return a regression slope and intercept for every pixel time series, for a single band (group by: full time extent)  a time series may be aggregated to monthly values by computing the mean for all values in a month (group by: months)  spatial  aggregation involves computing e.g.  mean  pixel values on a 100 x 100 m grid, from 10 m x 10 m pixels, where each original pixel is assigned uniquely to a larger pixel (group by: 100 m x 100 m grid cells)   Note that for the first example, the aggregation function not only requires time series values, but also their time stamps.  Resampling  is a broader term where we have data at one resolution, and need values at another (also called  scaling ). In case we have values at a 100 m x 100 m grid and need values at a 10 m x 10 m grid, the original values will be reused many times, and may be be simply assigned to the nearest high resolution grid cells (\"nearest neighbor\"), or may be interpolated somehow (e.g. by bilinear interpolation). Resampling from finer to coarser grid by nearest neighbor may again be a special case of aggregation.  When the target grid or time series has a lower resolution (larger grid cells) or lower frequency (longer time intervals) than the source grid, aggregation might be used for resampling. For example, if the resolutions are fairly similar, say the source collection has values for consecutive 10 day intervals and the target needs values for consecutive 16 day intervals, then some form of interpolation may be more appropriate than aggregation as defined here.",
            "title": "Processes and Jobs"
        },
        {
            "location": "/glossary/index.html#api",
            "text": "The API developed by the openEO project uses  HTTP REST  for communication between client and back-end server.",
            "title": "API"
        },
        {
            "location": "/arch/index.html",
            "text": "Architecture\n\n\nThe OpenEO core API defines a language how clients communicate to back-ends in order to analyze large Earth observation datasets. The API will be implemented by drivers for specific back-ends. Some first architecture considerations are listed below.\n\n\n\n\nThe OpenEO core API is a contract betewen clients and backends that describes the communication only\n\n\nEach back-end runs its own API instance including the specific back-end driver. There is no core API instance that runs more than one driver.\n\n\nClients in R, Python, and JavaScript connect directly to the backends and communicate with the backends over HTTP(s) acoording to the OpenEO core API specification.\n\n\nAPI instances can run on back-end servers or additional intermediate layers, which then communicate to back-ends in a back-end specific way.\n\n\nBack-ends may add functionality and extend the core API wherever there is need.\n\n\nThere will be a central backend registry service, to allow users to search for backends with specific functionality and or data. \n\n\nThe OpenEO core API will define \nprofiles\n in order group specific functionality.\n\n\n\n\n\n\nMicroservices\n\n\nTo simplify and structure the development, the API is divided into a few microservices.\n\n\n\n\n\n\n\n\nMicroservice\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCapabilities\n\n\nThis microservice reports on the capabilities of the back-end, i.e. which API endpoints are implemented, which authentication methods are supported, and whether and how UDFs can be executed at the back-end.\n\n\n\n\n\n\nEO Data Discovery\n\n\nDescribes which datasets and image collections are available at the backend.\n\n\n\n\n\n\nProcess Discovery\n\n\nProvides services to find out which processes a back-end provides, i.e., what users can do with the available data.\n\n\n\n\n\n\nUDF Runtime Discovery\n\n\nAllows discovering the programming languages and their runtime environments to execute user-defined functions.\n\n\n\n\n\n\nJob Management\n\n\nOrganizes and manages jobs that run processes on back-ends.\n\n\n\n\n\n\nResult Access and Services\n\n\nServices to download data and job results, e.g. as WCS or WMTS service.\n\n\n\n\n\n\nUser Data Management\n\n\nManage user content and accounting. Might be split into multiple microservices, e.g. User Files and User Process Graphs might be separated.\n\n\n\n\n\n\nAuthentication\n\n\nAuthentication of users.",
            "title": "Architecture and Microservices"
        },
        {
            "location": "/arch/index.html#architecture",
            "text": "The OpenEO core API defines a language how clients communicate to back-ends in order to analyze large Earth observation datasets. The API will be implemented by drivers for specific back-ends. Some first architecture considerations are listed below.   The OpenEO core API is a contract betewen clients and backends that describes the communication only  Each back-end runs its own API instance including the specific back-end driver. There is no core API instance that runs more than one driver.  Clients in R, Python, and JavaScript connect directly to the backends and communicate with the backends over HTTP(s) acoording to the OpenEO core API specification.  API instances can run on back-end servers or additional intermediate layers, which then communicate to back-ends in a back-end specific way.  Back-ends may add functionality and extend the core API wherever there is need.  There will be a central backend registry service, to allow users to search for backends with specific functionality and or data.   The OpenEO core API will define  profiles  in order group specific functionality.",
            "title": "Architecture"
        },
        {
            "location": "/arch/index.html#microservices",
            "text": "To simplify and structure the development, the API is divided into a few microservices.     Microservice  Description      Capabilities  This microservice reports on the capabilities of the back-end, i.e. which API endpoints are implemented, which authentication methods are supported, and whether and how UDFs can be executed at the back-end.    EO Data Discovery  Describes which datasets and image collections are available at the backend.    Process Discovery  Provides services to find out which processes a back-end provides, i.e., what users can do with the available data.    UDF Runtime Discovery  Allows discovering the programming languages and their runtime environments to execute user-defined functions.    Job Management  Organizes and manages jobs that run processes on back-ends.    Result Access and Services  Services to download data and job results, e.g. as WCS or WMTS service.    User Data Management  Manage user content and accounting. Might be split into multiple microservices, e.g. User Files and User Process Graphs might be separated.    Authentication  Authentication of users.",
            "title": "Microservices"
        },
        {
            "location": "/jobs/index.html",
            "text": "Jobs\n\n\nAs described in the \nglossary\n, a \njob\n brings one process graph to the back-end and organizes its execution, which may or may not induce costs.\n\n\nThe API distinguishes two types how jobs are (asynchronously) executed at back-ends. \nLazy evaluated jobs\n runs computations on demand, i.e., with incoming requests for downloading the results. Jobs can be executed multiple times with different views (including spatial / temporal resolution and window) as provided by download requests, which could come e.g. from WCS or WMTS.  \nBatch jobs\n in contrast are directly submitted to the back office's processing system. They will run only once, potentially include a provided view, and will store results after execution. Batch jobs are typically time consuming such that user interaction is not possible. \n\n\nAs an example we consider the simple calculation of vegetation indexes on all available Sentinel 2 imagery over Europe. Batch evaluation will take all relevant images, compute the NDVI, and finally store the result whereas lazy evaluation will not start any computations on its own. As soon as a client performs a download request such as a \nGetCoverage\n WCS request, the job's process will be executed but only for requested pixels. However, back-ends are free to cache frequent intermediate results on their own.\n\n\nThere is a third way to execute jobs at the back-ends, but does not really fit into the types mentioned before. It is similar to batch jobs, but results are delivered immediately after computation, i.e. \nsynchronously executed jobs\n. \n\n\nExamples\n\n\nLazy evaluated jobs\n\n\nUse case 1 and 2\n are examples for \nlazy evaluated jobs\n.\n\n\nBatch jobs\n\n\nBatch jobs are created by queueing \nlazy evaluated jobs\n. This is accomplished by calling the endpoint \nGET /jobs/{job_id}/queue\n. Therefore the examples of posting batch jobs are similar to lazy evaluated jobs, but are followed by additional calls to the jobs microservice. Therefore use case 1 and 2 could be converted to batch jobs by queueing them after job creation.\n\n\nAn explicit example for batch jobs is \nuse case 3\n.\n\n\nSynchronously executed jobs\n\n\nWork in progress. Examples might be changed or extended in a future version.\n\n\nRetrieval of a GeoTIFF\n\n\nRequest\n\n\nHeader:\nPOST /execute HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"min_time\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"NDVI\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_daterange\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bbox\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"S2_L2A_T32TPS_20M\"\n                  },\n                  \"left\":652000,\n                  \"right\":672000,\n                  \"top\":5161000,\n                  \"bottom\":5181000,\n                  \"srs\":\"EPSG:32632\"\n                }\n              },\n              \"from\":\"2017-01-01\",\n              \"to\":\"2017-01-31\"\n            }\n          },\n          \"red\":\"B04\",\n          \"nir\":\"B8A\"\n        }\n      }\n    }\n  },\n  \"output\":{\n    \"format\":\"GTiff\",\n    \"tiled\":true,\n    \"compress\":\"jpeg\",\n    \"photometric\":\"YCBCR\",\n    \"jpeg_quality\":80\n  }\n}\n\n\n\n\nResponse\n \n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: image/tiff\nAccess-Control-Allow-Origin: <Origin>\n\nBody:\nomitted (the GeoTiff file contents)\n\n\n\n\nRetrieval of time series\n\n\nRequest\n\n\nHeader:\nPOST /execute HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  }\n}\n\n\n\n\nResponse\n \n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/octet-stream\nAccess-Control-Allow-Origin: <Origin>\n\nBody:\nomitted (the GeoPackage file contents)",
            "title": "Jobs"
        },
        {
            "location": "/jobs/index.html#jobs",
            "text": "As described in the  glossary , a  job  brings one process graph to the back-end and organizes its execution, which may or may not induce costs.  The API distinguishes two types how jobs are (asynchronously) executed at back-ends.  Lazy evaluated jobs  runs computations on demand, i.e., with incoming requests for downloading the results. Jobs can be executed multiple times with different views (including spatial / temporal resolution and window) as provided by download requests, which could come e.g. from WCS or WMTS.   Batch jobs  in contrast are directly submitted to the back office's processing system. They will run only once, potentially include a provided view, and will store results after execution. Batch jobs are typically time consuming such that user interaction is not possible.   As an example we consider the simple calculation of vegetation indexes on all available Sentinel 2 imagery over Europe. Batch evaluation will take all relevant images, compute the NDVI, and finally store the result whereas lazy evaluation will not start any computations on its own. As soon as a client performs a download request such as a  GetCoverage  WCS request, the job's process will be executed but only for requested pixels. However, back-ends are free to cache frequent intermediate results on their own.  There is a third way to execute jobs at the back-ends, but does not really fit into the types mentioned before. It is similar to batch jobs, but results are delivered immediately after computation, i.e.  synchronously executed jobs .",
            "title": "Jobs"
        },
        {
            "location": "/jobs/index.html#examples",
            "text": "Lazy evaluated jobs  Use case 1 and 2  are examples for  lazy evaluated jobs .  Batch jobs  Batch jobs are created by queueing  lazy evaluated jobs . This is accomplished by calling the endpoint  GET /jobs/{job_id}/queue . Therefore the examples of posting batch jobs are similar to lazy evaluated jobs, but are followed by additional calls to the jobs microservice. Therefore use case 1 and 2 could be converted to batch jobs by queueing them after job creation.  An explicit example for batch jobs is  use case 3 .  Synchronously executed jobs  Work in progress. Examples might be changed or extended in a future version.  Retrieval of a GeoTIFF  Request  Header:\nPOST /execute HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"min_time\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"NDVI\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_daterange\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bbox\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"S2_L2A_T32TPS_20M\"\n                  },\n                  \"left\":652000,\n                  \"right\":672000,\n                  \"top\":5161000,\n                  \"bottom\":5181000,\n                  \"srs\":\"EPSG:32632\"\n                }\n              },\n              \"from\":\"2017-01-01\",\n              \"to\":\"2017-01-31\"\n            }\n          },\n          \"red\":\"B04\",\n          \"nir\":\"B8A\"\n        }\n      }\n    }\n  },\n  \"output\":{\n    \"format\":\"GTiff\",\n    \"tiled\":true,\n    \"compress\":\"jpeg\",\n    \"photometric\":\"YCBCR\",\n    \"jpeg_quality\":80\n  }\n}  Response    Header:\nHTTP/1.1 200 OK\nContent-Type: image/tiff\nAccess-Control-Allow-Origin: <Origin>\n\nBody:\nomitted (the GeoTiff file contents)  Retrieval of time series  Request  Header:\nPOST /execute HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  }\n}  Response    Header:\nHTTP/1.1 200 OK\nContent-Type: application/octet-stream\nAccess-Control-Allow-Origin: <Origin>\n\nBody:\nomitted (the GeoPackage file contents)",
            "title": "Examples"
        },
        {
            "location": "/processgraphs/index.html",
            "text": "Process graphs\n\n\nEarly work in progress, please contribute by adding \nissues\n.\n\n\nA process graph includes specific process calls, i.e. references to one or more processes including specific values for input arguments similar to a function call in programming. However, process graphs can chain multiple processes. In particular, arguments of processes in general can be again (recursive) process graphs, input datasets, or simple scalar or array values.\n\n\nSchematic definition\n\n\nProcess\n\n\nA single process in a process graph is defined as follows:\n\n\n<Process> := {\n  \"process_id\": <string>,\n  \"args\": <ArgumentSet>\n}\n\n\n\n\nA process must always contain two key-value-pairs named \nprocess_id\n and \nargs\n and no other elements.\n\n\nprocess_id\n can currently contain three types of processes:\n\n\n\n\nBackend-defined processes, which are listed at \nGET /processes\n, e.g. \nfilter_bands\n.\n\n\nUser-defined process graphs, which are listed at \nGET /users/{user_id}/process_graphs\n. \n  They are prefixed with \n/user/\n, e.g. \n/user/my_process_graph\n.\n\n\nUser-defined functions (UDF), which is one of the predefined \nUDF types\n and can be explored at \nGET /udf_runtimes/{lang}/{udf_type}\n. UDFs are prefixed with \n/udf\n and contain also the runtime and the process name separated by \n/\n, e.g. \n/udf/Python/apply_pixel\n.\n\n\n\n\nExample 1:\n\n\nA full process graph definition.\n\n\n{\n  \"process_id\":\"min_time\",\n  \"args\":{\n    \"imagery\":{\n      \"process_id\":\"/user/custom_ndvi\",\n      \"args\":{\n        \"imagery\":{\n          \"process_id\":\"filter_daterange\",\n          \"args\":{\n            \"imagery\":{\n              \"process_id\":\"filter_bbox\",\n              \"args\":{\n                \"imagery\":{\n                  \"product_id\":\"S2_L2A_T32TPS_20M\"\n                },\n                \"left\":652000,\n                \"right\":672000,\n                \"top\":5161000,\n                \"bottom\":5181000,\n                \"srs\":\"EPSG:32632\"\n              }\n            },\n            \"from\":\"2017-01-01\",\n            \"to\":\"2017-01-31\"\n          }\n        },\n        \"red\":\"B04\",\n        \"nir\":\"B8A\"\n      }\n    }\n  }\n}\n\n\n\n\nArgument Set\n\n\nAn argument set for a process is defined as follows:\n\n\n<ArgumentSet> := {\n  <Key>: <Value>\n}\n\n\n\n\nWhereas a key (\n<Key>\n) can be any valid JSON key and a value is defined as:\n\n\n<Value> := <string|number|array|boolean|null|Process|ImageCollection>\n\n\n\n\nNote:\n string, number, array, boolean and null are the primitive data types supported by JSON. An array must always contain \none data type only\n and is allowed to contain the data types allowed for \n<Value>\n, too. In consequence, the objects allowed to be part of an array are processes and image collections only.\n\n\nExample 2:\n\n\n{\n  \"imagery\":{\n    \"process_id\":\"filter_daterange\",\n    \"args\":{\n      \"imagery\":{\n        \"product_id\":\"Sentinel2A-L1C\"\n      },\n      \"from\":\"2017-01-01\",\n      \"to\":\"2017-01-31\"\n    }\n  }\n}\n\n\n\n\nExample 3:\n\n\nIf a process needs multiple processes or image collections as input, it is allowed to use arrays of the respective types.\n\n\n{\n  \"imagery\":{\n    \"process_id\":\"union\",\n    \"args\":{\n      \"collection\":[\n        {\n          \"process_id\":\"filter_bands\",\n          \"args\":{\n            \"imagery\":{\n              \"product_id\":\"Sentinel2-L1C\"\n            },\n            \"bands\":8\n          }\n        },\n        {\n          \"process_id\":\"filter_bands\",\n          \"args\":{\n            \"imagery\":{\n              \"product_id\":\"Sentinel2-L1C\"\n            },\n            \"bands\":5\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\n\nImage Collection\n\n\nAn image collection as input dataset is defined as follows:\n\n\n<ImageCollection> := {\n  \"product_id\": <string>\n}\n\n\n\n\nNote:\n The expected names of arguments are defined by the process descriptions, which can be discovered at \nGET /processes\n and \nGET /udf_runtimes/{lang}/{udf_type}\n. Therefore, the key name for a key-value-pair holding an image collection as value doesn't necessarily need to be named \nimagery\n. The name depends on the name of the corresponding process argument the image collection is assigned to. Example 3 demonstrates this by using \ncollection\n as a key once. \n\n\nExample 4:\n\n\n{\n  \"product_id\":\"Sentinel2A-L1C\"\n}\n\n\n\n\nCore processes\n\n\nThere are some processes that we define to be core processes that should be implemented by all back-ends:\n\n\n\n\nfilter_bands\n\n\nfilter_daterange\n\n\nprocess_graph\n\n\nto be continued...\n\n\n\n\nNote:\n Currently there are few defined processes only. Those are currently only meant as an example how future documentation of processes might look like and to supplement the schematic definition above.\n\n\nLimitation:\n Process names (process ids) must never contain a forward slash \n/\n.\n\n\nfilter_bands\n\n\nAllows to extract one or multiple bands of multi-band raster image collection. Bands can be chosen either by band id, band name or by wavelength.\n\n\nArguments\n\n\n\n\nimagery\n*: Image collection to filter\n\n\n\n\nAnd one of:\n\n\n\n\nbands\n: string or array of strings containing band ids.\n\n\nnames\n: string or array of strings containing band names.\n\n\nwavelengths\n: number or two-element array of numbers containing a wavelength or a minimum and maximum wavelength respectively.\n\n\n\n\nExamples\n\n\n{\n  \"process_id\": \"filter_bands\",\n  \"args\": {\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"bands\":1\n  }\n}\n\n\n\n\n{\n  \"process_id\": \"filter_bands\",\n  \"args\": {\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"wavelengths\":[1300,2000]\n  }\n}\n\n\n\n\nfilter_daterange\n\n\nAllows to filter an image collection by temporal extent.\n\n\nArguments\n\n\n\n\nimagery\n*: Image collection to filter\n\n\n\n\nAnd at least one of:\n\n\n\n\n\n\nfrom\n: Includes all data newer than the specified ISO 8601 date or date-time with simultaneous consideration of \nto\n.\n\n\n\n\n\n\nto\n: Includes all data older than the specified ISO 8601 date or date-time with simultaneous consideration of \nfrom\n.\n\n\n\n\n\n\nExamples\n\n\n{\n  \"process_id\":\"filter_daterange\",\n  \"args\":{\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"from\":\"2017-01-01\",\n    \"to\":\"2017-01-31\"\n  }\n}\n\n\n\n\nprocess_graph\n\n\nAnother process graph can be referenced with the process \nprocess_graph\n. This could even be an externally hosted process graph.\n\n\nArguments\n\n\n\n\nimagery\n*: Image collection to apply the process graph to\n\n\nuri\n*: An URI to a process graph.\n\n\n\n\nExamples\n\n\n{\n  \"process_id\":\"process_graph\",\n  \"args\":{\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"uri\":\"http://otherhost.org/api/v1/users/12345/process_graphs/abcdef\"\n  }\n}\n\n\n\n\nto be continued...",
            "title": "Process Graphs"
        },
        {
            "location": "/processgraphs/index.html#process-graphs",
            "text": "Early work in progress, please contribute by adding  issues .  A process graph includes specific process calls, i.e. references to one or more processes including specific values for input arguments similar to a function call in programming. However, process graphs can chain multiple processes. In particular, arguments of processes in general can be again (recursive) process graphs, input datasets, or simple scalar or array values.",
            "title": "Process graphs"
        },
        {
            "location": "/processgraphs/index.html#schematic-definition",
            "text": "Process  A single process in a process graph is defined as follows:  <Process> := {\n  \"process_id\": <string>,\n  \"args\": <ArgumentSet>\n}  A process must always contain two key-value-pairs named  process_id  and  args  and no other elements.  process_id  can currently contain three types of processes:   Backend-defined processes, which are listed at  GET /processes , e.g.  filter_bands .  User-defined process graphs, which are listed at  GET /users/{user_id}/process_graphs . \n  They are prefixed with  /user/ , e.g.  /user/my_process_graph .  User-defined functions (UDF), which is one of the predefined  UDF types  and can be explored at  GET /udf_runtimes/{lang}/{udf_type} . UDFs are prefixed with  /udf  and contain also the runtime and the process name separated by  / , e.g.  /udf/Python/apply_pixel .   Example 1:  A full process graph definition.  {\n  \"process_id\":\"min_time\",\n  \"args\":{\n    \"imagery\":{\n      \"process_id\":\"/user/custom_ndvi\",\n      \"args\":{\n        \"imagery\":{\n          \"process_id\":\"filter_daterange\",\n          \"args\":{\n            \"imagery\":{\n              \"process_id\":\"filter_bbox\",\n              \"args\":{\n                \"imagery\":{\n                  \"product_id\":\"S2_L2A_T32TPS_20M\"\n                },\n                \"left\":652000,\n                \"right\":672000,\n                \"top\":5161000,\n                \"bottom\":5181000,\n                \"srs\":\"EPSG:32632\"\n              }\n            },\n            \"from\":\"2017-01-01\",\n            \"to\":\"2017-01-31\"\n          }\n        },\n        \"red\":\"B04\",\n        \"nir\":\"B8A\"\n      }\n    }\n  }\n}  Argument Set  An argument set for a process is defined as follows:  <ArgumentSet> := {\n  <Key>: <Value>\n}  Whereas a key ( <Key> ) can be any valid JSON key and a value is defined as:  <Value> := <string|number|array|boolean|null|Process|ImageCollection>  Note:  string, number, array, boolean and null are the primitive data types supported by JSON. An array must always contain  one data type only  and is allowed to contain the data types allowed for  <Value> , too. In consequence, the objects allowed to be part of an array are processes and image collections only.  Example 2:  {\n  \"imagery\":{\n    \"process_id\":\"filter_daterange\",\n    \"args\":{\n      \"imagery\":{\n        \"product_id\":\"Sentinel2A-L1C\"\n      },\n      \"from\":\"2017-01-01\",\n      \"to\":\"2017-01-31\"\n    }\n  }\n}  Example 3:  If a process needs multiple processes or image collections as input, it is allowed to use arrays of the respective types.  {\n  \"imagery\":{\n    \"process_id\":\"union\",\n    \"args\":{\n      \"collection\":[\n        {\n          \"process_id\":\"filter_bands\",\n          \"args\":{\n            \"imagery\":{\n              \"product_id\":\"Sentinel2-L1C\"\n            },\n            \"bands\":8\n          }\n        },\n        {\n          \"process_id\":\"filter_bands\",\n          \"args\":{\n            \"imagery\":{\n              \"product_id\":\"Sentinel2-L1C\"\n            },\n            \"bands\":5\n          }\n        }\n      ]\n    }\n  }\n}  Image Collection  An image collection as input dataset is defined as follows:  <ImageCollection> := {\n  \"product_id\": <string>\n}  Note:  The expected names of arguments are defined by the process descriptions, which can be discovered at  GET /processes  and  GET /udf_runtimes/{lang}/{udf_type} . Therefore, the key name for a key-value-pair holding an image collection as value doesn't necessarily need to be named  imagery . The name depends on the name of the corresponding process argument the image collection is assigned to. Example 3 demonstrates this by using  collection  as a key once.   Example 4:  {\n  \"product_id\":\"Sentinel2A-L1C\"\n}",
            "title": "Schematic definition"
        },
        {
            "location": "/processgraphs/index.html#core-processes",
            "text": "There are some processes that we define to be core processes that should be implemented by all back-ends:   filter_bands  filter_daterange  process_graph  to be continued...   Note:  Currently there are few defined processes only. Those are currently only meant as an example how future documentation of processes might look like and to supplement the schematic definition above.  Limitation:  Process names (process ids) must never contain a forward slash  / .  filter_bands  Allows to extract one or multiple bands of multi-band raster image collection. Bands can be chosen either by band id, band name or by wavelength.  Arguments   imagery *: Image collection to filter   And one of:   bands : string or array of strings containing band ids.  names : string or array of strings containing band names.  wavelengths : number or two-element array of numbers containing a wavelength or a minimum and maximum wavelength respectively.   Examples  {\n  \"process_id\": \"filter_bands\",\n  \"args\": {\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"bands\":1\n  }\n}  {\n  \"process_id\": \"filter_bands\",\n  \"args\": {\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"wavelengths\":[1300,2000]\n  }\n}  filter_daterange  Allows to filter an image collection by temporal extent.  Arguments   imagery *: Image collection to filter   And at least one of:    from : Includes all data newer than the specified ISO 8601 date or date-time with simultaneous consideration of  to .    to : Includes all data older than the specified ISO 8601 date or date-time with simultaneous consideration of  from .    Examples  {\n  \"process_id\":\"filter_daterange\",\n  \"args\":{\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"from\":\"2017-01-01\",\n    \"to\":\"2017-01-31\"\n  }\n}  process_graph  Another process graph can be referenced with the process  process_graph . This could even be an externally hosted process graph.  Arguments   imagery *: Image collection to apply the process graph to  uri *: An URI to a process graph.   Examples  {\n  \"process_id\":\"process_graph\",\n  \"args\":{\n    \"imagery\":{\n      \"product_id\":\"Sentinel2A-L1C\"\n    },\n    \"uri\":\"http://otherhost.org/api/v1/users/12345/process_graphs/abcdef\"\n  }\n}  to be continued...",
            "title": "Core processes"
        },
        {
            "location": "/udfs/index.html",
            "text": "UDFs\n\n\nUser-defined functions (UDFs) can be exposed to the data in different ways. This includes which parts of the data are passed to the function, how the function execution is parallelized, and how the expected output is structured. The OpenEO core API defines the following UDF types:\n\n\n\n\napply_pixel\n\n\napply_scene\n\n\nreduce_time\n\n\nreduce_space\n\n\nwindow_time\n\n\nwindow_space\n\n\nwindow_spacetime\n\n\naggregate_time\n\n\naggregate_space\n\n\naggregate_spacetime\n\n\nchunkreduce_time\n\n\nchunkreduce_space\n\n\nchunkreduce_spacetime\n\n\n\n\nThis document describes some details of the abovementioned UDF types. Back-ends allowing the execution of UDF's will report, which types they support. For example applying UDFs on individual scenes is not possible on higher level data cube back-ends. In the descriptions below, the question in which format data is streamed to and from the functions is not yet covered. Furthermore, the described categories only include unary operations that take one image (collection) as input.  \n\n\nUDF types\n\n\napply_pixel\n\n\nThis type applies a simple function to one pixel of the input image or image collection. The function gets the value of one pixel (including all bands) as input and produces a single scalar or tuple output. The result has the same schema as the input image (collection) but different bands. Examples include the computation of vegetation indexes or filtering cloudy pixels. \n\n\napply_scene\n\n\nThis low-level UDF type applies a function on individual scenes.  The function gets a single scene as input and produces a modified \"scene\" with the same spatial footprint. This UDF type will only be supported by OpenEO back-ends with a file-based data organization. Higher level data-cube oriented back-offices in general do not keep track of the scenes and hence will not be able to parallelize operations on scene level. The type is mostly useful for working with lower-level data products, e.g., to perform atmospheric correction or any other operation that needs scene metadata. \n\n\nreduce_time\n\n\nThis type applies a function to a single time series and produces a zero-dimensional output (scalar or tuple). Notice that the \nview\n parameter for OpenEO processes affects the resolution and window of the time series provided as input to UDFs of this type. \n\n\nreduce_space\n\n\nThis type applies a function to a temporal snapshot of the data and produces a single value or multiband tuple per snapshot. The result is a time series. \n\n\nwindow_time\n\n\nThe provided UDF is called for each pixel and will receive values from pixels within a temporal neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values. \n\n\nwindow_space\n\n\nThe provided UDF is called for each pixel and will receive values from pixels within a spatial neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values. \n\n\nwindow_spacetime\n\n\nSimilar to \nwindow_time\n and \nwindow_space\n, this type derives a new value for the central pixel of a spatiotemporal window of specified size. The provided function receives a (multispectral) spacetime array as input and produces a single value (either scalar or multispectral) as output. The result has the same number of pixels as the input dataset. Windows at boundary regions should be filled with NA values. \n\n\naggregate_time\n\n\nSimilar to \nreduce_time\n this type applies the given UDF independently on pixel time series of the input data but produces a new time series with different temporal resolution. \nreduce_time\n can be seen as a special case of \naggregate_time\n where the temporal dimension is dropped.\nExamples of this UDF type include the generation of monthly aggregates from 16 day data.  The result has the same spatial resolution.\n\n\naggregate_space\n\n\nSimilar to \naggregate_time\n, this type applies the provided function on temporal snapshots of the data and generates an image with different spatial resolution. The result will have the same temporal resolution.\n\n\nchunkreduce_time\n\n\nPartitions the input data into equally sized temporal chunks and aggregates them to a single value or tuple. The function must return a single scalar or tuple (multiband) output. The result has the same spatial but a coarser temporal resolution.\n\n\nchunkreduce_space\n\n\nSimilar to \nchunkreduce_time\n, this type applies the provided function on spatial chunks of the data and generates an aggregated value or tuple. to aggregate. The result will have the same temporal but a coarser spatial resolution. Examples of this type include the generation of image pyramids.\n\n\nchunkreduce_spacetime\n\n\nSimilar to \nchunkreduce_space\n and \nchunkreduce_time\n, UDFs of this type receive spatiotemporal chunks such that the output has lower spatial and lower temporal resolution.\n\n\nR implementation\n\n\n\n\n\n\n\n\nUDF Type\n\n\nFunction prototype\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\napply_pixel\n\n\n\n\n\n\n\n\n\n\napply_scene\n\n\n\n\n\n\n\n\n\n\nreduce_time\n\n\n\n\n\n\n\n\n\n\nreduce_space\n\n\n\n\n\n\n\n\n\n\nwindow_time\n\n\n\n\n\n\n\n\n\n\nwindow_space\n\n\n\n\n\n\n\n\n\n\nwindow_spacetime\n\n\n\n\n\n\n\n\n\n\naggregate_time\n\n\n\n\n\n\n\n\n\n\naggregate_space\n\n\n\n\n\n\n\n\n\n\naggregate_spacetime\n\n\n\n\n\n\n\n\n\n\nchunkreduce_time\n\n\n\n\n\n\n\n\n\n\nchunkreduce_space\n\n\n\n\n\n\n\n\n\n\nchunkreduce_spacetime",
            "title": "UDFs"
        },
        {
            "location": "/udfs/index.html#udfs",
            "text": "User-defined functions (UDFs) can be exposed to the data in different ways. This includes which parts of the data are passed to the function, how the function execution is parallelized, and how the expected output is structured. The OpenEO core API defines the following UDF types:   apply_pixel  apply_scene  reduce_time  reduce_space  window_time  window_space  window_spacetime  aggregate_time  aggregate_space  aggregate_spacetime  chunkreduce_time  chunkreduce_space  chunkreduce_spacetime   This document describes some details of the abovementioned UDF types. Back-ends allowing the execution of UDF's will report, which types they support. For example applying UDFs on individual scenes is not possible on higher level data cube back-ends. In the descriptions below, the question in which format data is streamed to and from the functions is not yet covered. Furthermore, the described categories only include unary operations that take one image (collection) as input.    UDF types  apply_pixel  This type applies a simple function to one pixel of the input image or image collection. The function gets the value of one pixel (including all bands) as input and produces a single scalar or tuple output. The result has the same schema as the input image (collection) but different bands. Examples include the computation of vegetation indexes or filtering cloudy pixels.   apply_scene  This low-level UDF type applies a function on individual scenes.  The function gets a single scene as input and produces a modified \"scene\" with the same spatial footprint. This UDF type will only be supported by OpenEO back-ends with a file-based data organization. Higher level data-cube oriented back-offices in general do not keep track of the scenes and hence will not be able to parallelize operations on scene level. The type is mostly useful for working with lower-level data products, e.g., to perform atmospheric correction or any other operation that needs scene metadata.   reduce_time  This type applies a function to a single time series and produces a zero-dimensional output (scalar or tuple). Notice that the  view  parameter for OpenEO processes affects the resolution and window of the time series provided as input to UDFs of this type.   reduce_space  This type applies a function to a temporal snapshot of the data and produces a single value or multiband tuple per snapshot. The result is a time series.   window_time  The provided UDF is called for each pixel and will receive values from pixels within a temporal neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values.   window_space  The provided UDF is called for each pixel and will receive values from pixels within a spatial neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values.   window_spacetime  Similar to  window_time  and  window_space , this type derives a new value for the central pixel of a spatiotemporal window of specified size. The provided function receives a (multispectral) spacetime array as input and produces a single value (either scalar or multispectral) as output. The result has the same number of pixels as the input dataset. Windows at boundary regions should be filled with NA values.   aggregate_time  Similar to  reduce_time  this type applies the given UDF independently on pixel time series of the input data but produces a new time series with different temporal resolution.  reduce_time  can be seen as a special case of  aggregate_time  where the temporal dimension is dropped.\nExamples of this UDF type include the generation of monthly aggregates from 16 day data.  The result has the same spatial resolution.  aggregate_space  Similar to  aggregate_time , this type applies the provided function on temporal snapshots of the data and generates an image with different spatial resolution. The result will have the same temporal resolution.  chunkreduce_time  Partitions the input data into equally sized temporal chunks and aggregates them to a single value or tuple. The function must return a single scalar or tuple (multiband) output. The result has the same spatial but a coarser temporal resolution.  chunkreduce_space  Similar to  chunkreduce_time , this type applies the provided function on spatial chunks of the data and generates an aggregated value or tuple. to aggregate. The result will have the same temporal but a coarser spatial resolution. Examples of this type include the generation of image pyramids.  chunkreduce_spacetime  Similar to  chunkreduce_space  and  chunkreduce_time , UDFs of this type receive spatiotemporal chunks such that the output has lower spatial and lower temporal resolution.  R implementation     UDF Type  Function prototype  Details      apply_pixel      apply_scene      reduce_time      reduce_space      window_time      window_space      window_spacetime      aggregate_time      aggregate_space      aggregate_spacetime      chunkreduce_time      chunkreduce_space      chunkreduce_spacetime",
            "title": "UDFs"
        },
        {
            "location": "/views/index.html",
            "text": "Data Views\n\n\nThe OpenEO API supports to look at datasets from different \nviews\n. Views describe at which resolution and for which spatial and temporal extent the original Earth observation data are processed and hence can be used to run processes interactively on small parts of the original data without need to wait for long-running processes. The idea is similar to what Google Earth Engine does by reducing computations only to pixels that are actually displayed.\n\n\nNote: This feature is currently not described in the API specification. It will be added after delivering the proof-of-concept.\n\n\nExample\n\n\nThe following JSON object describes a coarse resolution (0.25\u00b0 x 0.25\u00b0) view of monthly aggregated data. \n\n\n\"view\": {\n  \"space\": {\n    \"srs\": \"EPSG:4326\",\n    \"window\": {\n      \"left\": -10.21,\n      \"top\": 53.23,\n      \"right\": 12.542,\n      \"bottom\": 12.32\n    },\n    \"cell_size\": 0.25,\n    \"resampling\": \"nearest\"\n  },\n  \"time\": {\n    \"window\": {\n      \"start\": \"2017-01-01\",\n      \"end\": \"2018-01-01\"\n    },\n    \"time_step\": \"P1M\",\n    \"resampling\": \"nearest\"\n  }\n}",
            "title": "Data Views"
        },
        {
            "location": "/views/index.html#data-views",
            "text": "The OpenEO API supports to look at datasets from different  views . Views describe at which resolution and for which spatial and temporal extent the original Earth observation data are processed and hence can be used to run processes interactively on small parts of the original data without need to wait for long-running processes. The idea is similar to what Google Earth Engine does by reducing computations only to pixels that are actually displayed.  Note: This feature is currently not described in the API specification. It will be added after delivering the proof-of-concept.",
            "title": "Data Views"
        },
        {
            "location": "/views/index.html#example",
            "text": "The following JSON object describes a coarse resolution (0.25\u00b0 x 0.25\u00b0) view of monthly aggregated data.   \"view\": {\n  \"space\": {\n    \"srs\": \"EPSG:4326\",\n    \"window\": {\n      \"left\": -10.21,\n      \"top\": 53.23,\n      \"right\": 12.542,\n      \"bottom\": 12.32\n    },\n    \"cell_size\": 0.25,\n    \"resampling\": \"nearest\"\n  },\n  \"time\": {\n    \"window\": {\n      \"start\": \"2017-01-01\",\n      \"end\": \"2018-01-01\"\n    },\n    \"time_step\": \"P1M\",\n    \"resampling\": \"nearest\"\n  }\n}",
            "title": "Example"
        },
        {
            "location": "/poc/index.html",
            "text": "Proof of Concept\n\n\nThis page gives a detailed description of the OpenEO proof of concept and gives a list and specification of what needs to be implemented. The proof of concept will consist of\n\n\n\n\nat least three clearly defined example processes (see below),\n\n\na prototypical API specification including communication API call sequences of the processes (see below),\n\n\nimplementations of the processes on three back-ends, and\n\n\nprototypical clients in R, Python and potentially JavaScript.\n\n\n\n\nBelow, we define the example use cases and how they are translated to sequences of API calls.\n\n\nNote:\n Authentication is not included in these examples. Enabling authentication needs the placeholder \n<Origin>\n to be set to the requesting host, including protocol, host name/IP and port, e.g. \nhttp://localhost:8080\n. This could be done by using the Origin header value from the request.\n\n\nUse Case 1: Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery\n\n\n1. Check whether Sentinel 2A Level 1C data is available at the back-end\n\n\nRequest\n\n\nGET /data/Sentinel2A-L1C HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"product_id\":\"Sentinel-2A-L1C\",\n  \"description\":\"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n  \"source\":\"European Space Agency (ESA)\",\n  \"extent\":[\n    -34,\n    35,\n    39,\n    71\n  ],\n  \"time\":[\n    \"2016-01-01\",\n    \"2017-10-01\"\n  ],\n  \"bands\":[\n    {\n      \"band_id\":\"1\",\n      \"wavelength_nm\":443.9,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"2\",\n      \"name\":\"blue\",\n      \"wavelength_nm\":496.6,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"3\",\n      \"name\":\"green\",\n      \"wavelength_nm\":560,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"4\",\n      \"name\":\"red\",\n      \"wavelength_nm\":664.5,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"5\",\n      \"wavelength_nm\":703.9,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"6\",\n      \"wavelength_nm\":740.2,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"7\",\n      \"wavelength_nm\":782.5,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8\",\n      \"name\":\"nir\",\n      \"wavelength_nm\":835.1,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8a\",\n      \"wavelength_nm\":864.8,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"9\",\n      \"wavelength_nm\":945,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"10\",\n      \"wavelength_nm\":1373.5,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"11\",\n      \"wavelength_nm\":1613.7,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"12\",\n      \"wavelength_nm\":2202.4,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    }\n  ]\n}\n\n\n\n\n2. Check that needed processes are available\n\n\nRequest\n\n\nGET /processes/filter_bbox HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"filter_bbox\",\n  \"description\":\"Drops observations from a collection that are located outside of a given bounding box.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"left\":{\n      \"description\":\"left boundary (longitude / easting)\"\n    },\n    \"right\":{\n      \"description\":\"right boundary (longitude / easting)\"\n    },\n    \"top\":{\n      \"description\":\"top boundary (latitude / northing)\"\n    },\n    \"bottom\":{\n      \"description\":\"bottom boundary (latitude / northing)\"\n    },\n    \"srs\":{\n      \"description\":\"spatial reference system of boundaries as proj4 or EPSG:12345 like string\"\n    }\n  }\n}\n\n\n\n\nRequest\n\n\nGET /processes/filter_daterange HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"filter_daterange\",\n  \"description\":\"Drops observations from a collection that have been captured before a start or after a given end date.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"from\":{\n      \"description\":\"start date\"\n    },\n    \"to\":{\n      \"description\":\"end date\"\n    }\n  }\n}\n\n\n\n\nRequest\n\n\nGET /processes/NDVI HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"NDVI\",\n  \"description\":\"Finds the minimum value of time series for all bands of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"red\":{\n      \"description\":\"reference to the red band\"\n    },\n    \"nir\":{\n      \"description\":\"reference to the nir band\"\n    }\n  }\n}\n\n\n\n\nRequest\n\n\nGET /processes/min_time HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"min_time\",\n  \"description\":\"Finds the minimum value of time series for all bands of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    }\n  }\n}\n\n\n\n\n3. Create a job at the back-end\n\n\nRequest\n\n\nPOST /jobs HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"min_time\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"NDVI\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_daterange\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bbox\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"S2_L2A_T32TPS_20M\"\n                  },\n                  \"left\":652000,\n                  \"right\":672000,\n                  \"top\":5161000,\n                  \"bottom\":5181000,\n                  \"srs\":\"EPSG:32632\"\n                }\n              },\n              \"from\":\"2017-01-01\",\n              \"to\":\"2017-01-31\"\n            }\n          },\n          \"red\":\"B04\",\n          \"nir\":\"B8A\"\n        }\n      }\n    }\n  }\n}\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"2a8ffb20c2b235a3f3e3351f\",\n  \"status\":\"submitted\",\n  \"submitted\":\"2017-01-01T09:32:12Z\",\n  \"updated\":\"2017-01-01T09:36:18Z\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"consumed_credits\":0\n}\n\n\n\n\n4. Create a WCS service\n\n\nRequest\n\n\nPOST /services HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"job_id\":\"2a8ffb20c2b235a3f3e3351f\",\n  \"type\":\"wcs\",\n  \"args\":{\n    \"VERSION\":\"2.0.1\"\n  }\n}\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"service_id\":\"4dab456f6501bbcd\",\n  \"service_url\":\"https://openeo.org/4dab456f6501bbcd/wcs\",\n  \"service_type\":\"wcs\",\n  \"service_args\":{\n    \"VERSION\":\"2.0.1\"\n  },\n  \"job_id\":\"2a8ffb20c2b235a3f3e3351f\"\n}\n\n\n\n\n5. Download the data on demand with WCS\n\n\nRequest\n\n\nGET /services/4dab456f6501bbcd/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCapabilities HTTP/1.1\n\n\n\n\nResponse\n\n\nomitted\n\n\nRequest\n\n\nGET /services/4dab456f6501bbcd/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCoverage&COVERAGEID=2a8ffb20c2b235a3f3e3351f&FORMAT=image/tiff&SUBSET=x,http://www.opengis.net/def/crs/EPSG/0/4326(16.1,16.5)&SUBSET=y,http://www.opengis.net/def/crs/EPSG/0/4326(47.9,48.6)&&SIZE=x(200)&SIZE=y(200) HTTP/1.1\n\n\n\n\nResponse\n \n\nomitted\n\n\n6. Stop the job (and the service)\n\n\nRequest\n\n\nPATCH /jobs/2a8ffb20c2b235a3f3e3351f/cancel HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none\n\n\n\n\nUse Case 2: Create a monthly aggregated Sentinel 1 product from a custom Python script\n\n\n1. Ask the back-end for available Sentinel 1 data\n\n\nRequest\n\n\nGET /data/Sentinel1-L1-IW-GRD HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"product_id\":\"Sentinel1-L1-IW-GRD\",\n  \"description\":\"Sentinel 1 C-band Synthetic Aperture Radar (SAR) Ground Range Data\",\n  \"source\":\"European Space Agency (ESA)\",\n  \"extent\":[\n    -34,\n    35,\n    39,\n    71\n  ],\n  \"time\":[\n    \"2016-01-01\",\n    \"2017-10-01\"\n  ],\n  \"bands\":[\n    {\n      \"band_id\":\"VV\"\n    },\n    {\n      \"band_id\":\"VH\"\n    }\n  ]\n}\n\n\n\n\n2. Ask the back-end whether it supports Python UDFs of type aggregate_time and get details about expected parameters\n\n\nRequest\n\n\nGET /udf_runtimes HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"Python\":{\n    \"udf_types\":[\n      \"reduce_time\",\n      \"aggregate_time\",\n      \"apply_pixel\"\n    ],\n    \"versions\":{\n      \"3.6.3\":{\n        \"packages\":[\n          \"numpy\",\n          \"scipy\",\n          \"pandas\",\n          \"matplotlib\",\n          \"ipython\",\n          \"jupyter\",\n          \"GDAL\"\n        ]\n      }\n    }\n  }\n}\n\n\n\n\nRequest\n\n\nGET /udf_runtimes/Python/aggregate_time HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\n{\n  \"process_id\":\"/udf/Python/aggregate_time\",\n  \"description\":\"Runs a Python script for each time series of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"script\":{\n      \"description\":\"Python script that will be executed over all time series, gets time series as (Pandas) DataFrame and expects a new DataFrame as output.\"\n    },\n    \"version\":{\n      \"description\":\"Python version to use, defaults to the latest available version.\",\n      \"required\":false,\n      \"default\":\"latest\"\n    }\n  }\n}\n\n\n\n\n3. Upload python script\n\n\nRequest\n\n\nPUT /users/me/files/s1_aggregate.py HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none\n\n\n\n\n4. Create a job\n\n\nRequest\n\n\nPOST /jobs HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"/udf/Python/aggregate_time\",\n    \"args\":{\n      \"script\":\"/users/me/files/s1_aggregate.py\",\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"product_id\":\"Sentinel1-L1-IW-GRD\"\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      }\n    }\n  }\n}\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"3723c32fb7b24698832ca71f2d3f18aa\",\n  \"status\":\"submitted\",\n  \"submitted\":\"2017-01-01T09:32:12Z\",\n  \"updated\":\"2017-01-01T09:36:18Z\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"consumed_credits\":0\n}\n\n\n\n\n5. Create a TMS service\n\n\nRequest\n\n\nPOST /services HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"job_id\":\"3723c32fb7b24698832ca71f2d3f18aa\",\n  \"type\":\"tms\"\n}\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"service_id\":\"9dab4b6f6523\",\n  \"service_url\":\"http://cdn.cloudprovider.com/openeo/services/9dab4b6f6523/tms\",\n  \"service_type\":\"tms\",\n  \"job_id\":\"3723c32fb7b24698832ca71f2d3f18aa\"\n}\n\n\n\n\n6. Download results as TMS\n\n\nExample Request\n\n\nGET hhttp://cdn.cloudprovider.com/openeo/services/9dab4b6f6523/tms/2017-01-01/12/2232/2668/?bands=1 HTTP/1.1\n\n\n\n\nResponse\n\n\nomitted\n\n\nUse Case 3: Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons\n\n\n1. Check whether Sentinel 2A Level 1C data is available at the back-end\n\n\nRequest\n\n\nGET /data/Sentinel2A-L1C HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"product_id\":\"Sentinel-2A-L1C\",\n  \"description\":\"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n  \"source\":\"European Space Agency (ESA)\",\n  \"extent\":[\n    -34,\n    35,\n    39,\n    71\n  ],\n  \"time\":[\n    \"2016-01-01\",\n    \"2017-10-01\"\n  ],\n  \"bands\":[\n    {\n      \"band_id\":\"1\",\n      \"wavelength_nm\":443.9,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"2\",\n      \"name\":\"blue\",\n      \"wavelength_nm\":496.6,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"3\",\n      \"name\":\"green\",\n      \"wavelength_nm\":560,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"4\",\n      \"name\":\"red\",\n      \"wavelength_nm\":664.5,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"5\",\n      \"wavelength_nm\":703.9,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"6\",\n      \"wavelength_nm\":740.2,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"7\",\n      \"wavelength_nm\":782.5,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8\",\n      \"name\":\"nir\",\n      \"wavelength_nm\":835.1,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8a\",\n      \"wavelength_nm\":864.8,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"9\",\n      \"wavelength_nm\":945,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"10\",\n      \"wavelength_nm\":1373.5,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"11\",\n      \"wavelength_nm\":1613.7,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"12\",\n      \"wavelength_nm\":2202.4,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    }\n  ]\n}\n\n\n\n\n\n\n2. Check whether the back-end supports computing \nzonal_statistics\n\n\nRequest\n\n\nGET /processes/zonal_statistics HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"zonal_statistics\",\n  \"description\":\"Runs a Python script for each time series of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"regions\":{\n      \"description\":\"Polygon file readable by OGR\"\n    },\n    \"func\":{\n      \"description\":\"Function to apply over the polygons, one of `avg`, `min`, `max`, `median`, `q25`, or `q75`.\",\n      \"required\":false,\n      \"default\":\"avg\"\n    }\n  }\n}\n\n\n\n\n3. Upload a GeoJSON Polygon\n\n\nRequest\n\n\nPUT /user/me/files/polygon1.json HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none\n\n\n\n\n4. Create a job\n\n\nRequest\n\n\nPOST /jobs HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  }\n}\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"f6ea12c5e283438a921b525af826da08\",\n  \"status\":\"submitted\",\n  \"submitted\":\"2017-01-01T09:32:12Z\",\n  \"updated\":\"2017-01-01T09:36:18Z\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"consumed_credits\":0\n}\n\n\n\n\n5. Start batch computation at the back-end\n\n\nRequest\n\n\nPATCH /jobs/f6ea12c5e283438a921b525af826da08/queue HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none\n\n\n\n\n6. Check job status twice\n\n\nRequest\n\n\nGET /jobs/f6ea12c5e283438a921b525af826da08 HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"status\":\"running\",\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  },\n  \"submitted\":\"2017-01-01 09:32:12\",\n  \"updated\":\"2017-01-01 09:34:11\",\n  \"consumed_credits\":231\n}\n\n\n\n\nRequest\n\n\nGET /jobs/f6ea12c5e283438a921b525af826da08 HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"status\":\"finished\",\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  },\n  \"submitted\":\"2017-01-01 09:32:12\",\n  \"updated\":\"2017-01-01 09:36:57\",\n  \"consumed_credits\":450\n}\n\n\n\n\n7. Retrieve download links\n\n\nRequest\n\n\nGET /jobs/f6ea12c5e283438a921b525af826da08/download HTTP/1.1\n\n\n\n\nResponse\n\n\nHeader:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n[\n  \"https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/1.gpkg\"\n]\n\n\n\n\n\n\n8. Download file(s)\n\n\nRequest\n\n\nGET https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/1.gpkg HTTP/1.1\n\n\n\n\nResponse (GPKG file)\n\n\nomitted",
            "title": "Proof of Concept"
        },
        {
            "location": "/poc/index.html#proof-of-concept",
            "text": "This page gives a detailed description of the OpenEO proof of concept and gives a list and specification of what needs to be implemented. The proof of concept will consist of   at least three clearly defined example processes (see below),  a prototypical API specification including communication API call sequences of the processes (see below),  implementations of the processes on three back-ends, and  prototypical clients in R, Python and potentially JavaScript.   Below, we define the example use cases and how they are translated to sequences of API calls.  Note:  Authentication is not included in these examples. Enabling authentication needs the placeholder  <Origin>  to be set to the requesting host, including protocol, host name/IP and port, e.g.  http://localhost:8080 . This could be done by using the Origin header value from the request.",
            "title": "Proof of Concept"
        },
        {
            "location": "/poc/index.html#use-case-1-deriving-minimum-ndvi-measurements-over-pixel-time-series-of-sentinel-2-imagery",
            "text": "1. Check whether Sentinel 2A Level 1C data is available at the back-end  Request  GET /data/Sentinel2A-L1C HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"product_id\":\"Sentinel-2A-L1C\",\n  \"description\":\"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n  \"source\":\"European Space Agency (ESA)\",\n  \"extent\":[\n    -34,\n    35,\n    39,\n    71\n  ],\n  \"time\":[\n    \"2016-01-01\",\n    \"2017-10-01\"\n  ],\n  \"bands\":[\n    {\n      \"band_id\":\"1\",\n      \"wavelength_nm\":443.9,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"2\",\n      \"name\":\"blue\",\n      \"wavelength_nm\":496.6,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"3\",\n      \"name\":\"green\",\n      \"wavelength_nm\":560,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"4\",\n      \"name\":\"red\",\n      \"wavelength_nm\":664.5,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"5\",\n      \"wavelength_nm\":703.9,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"6\",\n      \"wavelength_nm\":740.2,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"7\",\n      \"wavelength_nm\":782.5,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8\",\n      \"name\":\"nir\",\n      \"wavelength_nm\":835.1,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8a\",\n      \"wavelength_nm\":864.8,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"9\",\n      \"wavelength_nm\":945,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"10\",\n      \"wavelength_nm\":1373.5,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"11\",\n      \"wavelength_nm\":1613.7,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"12\",\n      \"wavelength_nm\":2202.4,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    }\n  ]\n}  2. Check that needed processes are available  Request  GET /processes/filter_bbox HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"filter_bbox\",\n  \"description\":\"Drops observations from a collection that are located outside of a given bounding box.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"left\":{\n      \"description\":\"left boundary (longitude / easting)\"\n    },\n    \"right\":{\n      \"description\":\"right boundary (longitude / easting)\"\n    },\n    \"top\":{\n      \"description\":\"top boundary (latitude / northing)\"\n    },\n    \"bottom\":{\n      \"description\":\"bottom boundary (latitude / northing)\"\n    },\n    \"srs\":{\n      \"description\":\"spatial reference system of boundaries as proj4 or EPSG:12345 like string\"\n    }\n  }\n}  Request  GET /processes/filter_daterange HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"filter_daterange\",\n  \"description\":\"Drops observations from a collection that have been captured before a start or after a given end date.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"from\":{\n      \"description\":\"start date\"\n    },\n    \"to\":{\n      \"description\":\"end date\"\n    }\n  }\n}  Request  GET /processes/NDVI HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"NDVI\",\n  \"description\":\"Finds the minimum value of time series for all bands of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"red\":{\n      \"description\":\"reference to the red band\"\n    },\n    \"nir\":{\n      \"description\":\"reference to the nir band\"\n    }\n  }\n}  Request  GET /processes/min_time HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"min_time\",\n  \"description\":\"Finds the minimum value of time series for all bands of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    }\n  }\n}  3. Create a job at the back-end  Request  POST /jobs HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"min_time\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"NDVI\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_daterange\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bbox\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"S2_L2A_T32TPS_20M\"\n                  },\n                  \"left\":652000,\n                  \"right\":672000,\n                  \"top\":5161000,\n                  \"bottom\":5181000,\n                  \"srs\":\"EPSG:32632\"\n                }\n              },\n              \"from\":\"2017-01-01\",\n              \"to\":\"2017-01-31\"\n            }\n          },\n          \"red\":\"B04\",\n          \"nir\":\"B8A\"\n        }\n      }\n    }\n  }\n}  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"2a8ffb20c2b235a3f3e3351f\",\n  \"status\":\"submitted\",\n  \"submitted\":\"2017-01-01T09:32:12Z\",\n  \"updated\":\"2017-01-01T09:36:18Z\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"consumed_credits\":0\n}  4. Create a WCS service  Request  POST /services HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"job_id\":\"2a8ffb20c2b235a3f3e3351f\",\n  \"type\":\"wcs\",\n  \"args\":{\n    \"VERSION\":\"2.0.1\"\n  }\n}  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"service_id\":\"4dab456f6501bbcd\",\n  \"service_url\":\"https://openeo.org/4dab456f6501bbcd/wcs\",\n  \"service_type\":\"wcs\",\n  \"service_args\":{\n    \"VERSION\":\"2.0.1\"\n  },\n  \"job_id\":\"2a8ffb20c2b235a3f3e3351f\"\n}  5. Download the data on demand with WCS  Request  GET /services/4dab456f6501bbcd/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCapabilities HTTP/1.1  Response  omitted  Request  GET /services/4dab456f6501bbcd/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCoverage&COVERAGEID=2a8ffb20c2b235a3f3e3351f&FORMAT=image/tiff&SUBSET=x,http://www.opengis.net/def/crs/EPSG/0/4326(16.1,16.5)&SUBSET=y,http://www.opengis.net/def/crs/EPSG/0/4326(47.9,48.6)&&SIZE=x(200)&SIZE=y(200) HTTP/1.1  Response   omitted  6. Stop the job (and the service)  Request  PATCH /jobs/2a8ffb20c2b235a3f3e3351f/cancel HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none",
            "title": "Use Case 1: Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery"
        },
        {
            "location": "/poc/index.html#use-case-2-create-a-monthly-aggregated-sentinel-1-product-from-a-custom-python-script",
            "text": "1. Ask the back-end for available Sentinel 1 data  Request  GET /data/Sentinel1-L1-IW-GRD HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"product_id\":\"Sentinel1-L1-IW-GRD\",\n  \"description\":\"Sentinel 1 C-band Synthetic Aperture Radar (SAR) Ground Range Data\",\n  \"source\":\"European Space Agency (ESA)\",\n  \"extent\":[\n    -34,\n    35,\n    39,\n    71\n  ],\n  \"time\":[\n    \"2016-01-01\",\n    \"2017-10-01\"\n  ],\n  \"bands\":[\n    {\n      \"band_id\":\"VV\"\n    },\n    {\n      \"band_id\":\"VH\"\n    }\n  ]\n}  2. Ask the back-end whether it supports Python UDFs of type aggregate_time and get details about expected parameters  Request  GET /udf_runtimes HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"Python\":{\n    \"udf_types\":[\n      \"reduce_time\",\n      \"aggregate_time\",\n      \"apply_pixel\"\n    ],\n    \"versions\":{\n      \"3.6.3\":{\n        \"packages\":[\n          \"numpy\",\n          \"scipy\",\n          \"pandas\",\n          \"matplotlib\",\n          \"ipython\",\n          \"jupyter\",\n          \"GDAL\"\n        ]\n      }\n    }\n  }\n}  Request  GET /udf_runtimes/Python/aggregate_time HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\n{\n  \"process_id\":\"/udf/Python/aggregate_time\",\n  \"description\":\"Runs a Python script for each time series of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"script\":{\n      \"description\":\"Python script that will be executed over all time series, gets time series as (Pandas) DataFrame and expects a new DataFrame as output.\"\n    },\n    \"version\":{\n      \"description\":\"Python version to use, defaults to the latest available version.\",\n      \"required\":false,\n      \"default\":\"latest\"\n    }\n  }\n}  3. Upload python script  Request  PUT /users/me/files/s1_aggregate.py HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none  4. Create a job  Request  POST /jobs HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"/udf/Python/aggregate_time\",\n    \"args\":{\n      \"script\":\"/users/me/files/s1_aggregate.py\",\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"product_id\":\"Sentinel1-L1-IW-GRD\"\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      }\n    }\n  }\n}  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"3723c32fb7b24698832ca71f2d3f18aa\",\n  \"status\":\"submitted\",\n  \"submitted\":\"2017-01-01T09:32:12Z\",\n  \"updated\":\"2017-01-01T09:36:18Z\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"consumed_credits\":0\n}  5. Create a TMS service  Request  POST /services HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"job_id\":\"3723c32fb7b24698832ca71f2d3f18aa\",\n  \"type\":\"tms\"\n}  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"service_id\":\"9dab4b6f6523\",\n  \"service_url\":\"http://cdn.cloudprovider.com/openeo/services/9dab4b6f6523/tms\",\n  \"service_type\":\"tms\",\n  \"job_id\":\"3723c32fb7b24698832ca71f2d3f18aa\"\n}  6. Download results as TMS  Example Request  GET hhttp://cdn.cloudprovider.com/openeo/services/9dab4b6f6523/tms/2017-01-01/12/2232/2668/?bands=1 HTTP/1.1  Response  omitted",
            "title": "Use Case 2: Create a monthly aggregated Sentinel 1 product from a custom Python script"
        },
        {
            "location": "/poc/index.html#use-case-3-compute-time-series-of-zonal-regional-statistics-of-sentinel-2-imagery-over-user-uploaded-polygons",
            "text": "1. Check whether Sentinel 2A Level 1C data is available at the back-end  Request  GET /data/Sentinel2A-L1C HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"product_id\":\"Sentinel-2A-L1C\",\n  \"description\":\"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n  \"source\":\"European Space Agency (ESA)\",\n  \"extent\":[\n    -34,\n    35,\n    39,\n    71\n  ],\n  \"time\":[\n    \"2016-01-01\",\n    \"2017-10-01\"\n  ],\n  \"bands\":[\n    {\n      \"band_id\":\"1\",\n      \"wavelength_nm\":443.9,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"2\",\n      \"name\":\"blue\",\n      \"wavelength_nm\":496.6,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"3\",\n      \"name\":\"green\",\n      \"wavelength_nm\":560,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"4\",\n      \"name\":\"red\",\n      \"wavelength_nm\":664.5,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"5\",\n      \"wavelength_nm\":703.9,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"6\",\n      \"wavelength_nm\":740.2,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"7\",\n      \"wavelength_nm\":782.5,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8\",\n      \"name\":\"nir\",\n      \"wavelength_nm\":835.1,\n      \"res_m\":10,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"8a\",\n      \"wavelength_nm\":864.8,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"9\",\n      \"wavelength_nm\":945,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"10\",\n      \"wavelength_nm\":1373.5,\n      \"res_m\":60,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"11\",\n      \"wavelength_nm\":1613.7,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    },\n    {\n      \"band_id\":\"12\",\n      \"wavelength_nm\":2202.4,\n      \"res_m\":20,\n      \"scale\":0.0001,\n      \"offset\":0,\n      \"type\":\"int16\",\n      \"unit\":\"1\"\n    }\n  ]\n}  2. Check whether the back-end supports computing  zonal_statistics  Request  GET /processes/zonal_statistics HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"process_id\":\"zonal_statistics\",\n  \"description\":\"Runs a Python script for each time series of the input dataset.\",\n  \"args\":{\n    \"imagery\":{\n      \"description\":\"array of input collections with one element\"\n    },\n    \"regions\":{\n      \"description\":\"Polygon file readable by OGR\"\n    },\n    \"func\":{\n      \"description\":\"Function to apply over the polygons, one of `avg`, `min`, `max`, `median`, `q25`, or `q75`.\",\n      \"required\":false,\n      \"default\":\"avg\"\n    }\n  }\n}  3. Upload a GeoJSON Polygon  Request  PUT /user/me/files/polygon1.json HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none  4. Create a job  Request  POST /jobs HTTP/1.1\nContent-Type: application/json; charset=utf-8\n\nBody:\n{\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  }\n}  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"f6ea12c5e283438a921b525af826da08\",\n  \"status\":\"submitted\",\n  \"submitted\":\"2017-01-01T09:32:12Z\",\n  \"updated\":\"2017-01-01T09:36:18Z\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"consumed_credits\":0\n}  5. Start batch computation at the back-end  Request  PATCH /jobs/f6ea12c5e283438a921b525af826da08/queue HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody: none  6. Check job status twice  Request  GET /jobs/f6ea12c5e283438a921b525af826da08 HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"status\":\"running\",\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  },\n  \"submitted\":\"2017-01-01 09:32:12\",\n  \"updated\":\"2017-01-01 09:34:11\",\n  \"consumed_credits\":231\n}  Request  GET /jobs/f6ea12c5e283438a921b525af826da08 HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n{\n  \"job_id\":\"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\":\"bd6f9faf93b4\",\n  \"status\":\"finished\",\n  \"process_graph\":{\n    \"process_id\":\"zonal_statistics\",\n    \"args\":{\n      \"imagery\":{\n        \"process_id\":\"filter_daterange\",\n        \"args\":{\n          \"imagery\":{\n            \"process_id\":\"filter_bbox\",\n            \"args\":{\n              \"imagery\":{\n                \"process_id\":\"filter_bands\",\n                \"args\":{\n                  \"imagery\":{\n                    \"product_id\":\"Sentinel2-L1C\"\n                  },\n                  \"bands\":8\n                }\n              },\n              \"left\":16.1,\n              \"right\":16.6,\n              \"top\":48.6,\n              \"bottom\":47.2,\n              \"srs\":\"EPSG:4326\"\n            }\n          },\n          \"from\":\"2017-01-01\",\n          \"to\":\"2017-01-31\"\n        }\n      },\n      \"regions\":\"/users/me/files/\",\n      \"func\":\"avg\"\n    }\n  },\n  \"output\":{\n    \"format\":\"GPKG\"\n  },\n  \"submitted\":\"2017-01-01 09:32:12\",\n  \"updated\":\"2017-01-01 09:36:57\",\n  \"consumed_credits\":450\n}  7. Retrieve download links  Request  GET /jobs/f6ea12c5e283438a921b525af826da08/download HTTP/1.1  Response  Header:\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nAccess-Control-Allow-Origin: <Origin>\nAccess-Control-Allow-Credentials: true\n\nBody:\n[\n  \"https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/1.gpkg\"\n]  8. Download file(s)  Request  GET https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/1.gpkg HTTP/1.1  Response (GPKG file)  omitted",
            "title": "Use Case 3: Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons"
        },
        {
            "location": "/apireference/index.html",
            "text": "this is a placeholder file that will be replaced by generated docs of the OpenAPI spec automatically",
            "title": "API Reference"
        }
    ]
}