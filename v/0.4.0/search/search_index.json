{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"openEO - Concepts and API Reference \u00b6 Work in progress, please contribute by adding issues . openEO develops an open application programming interface(API) that connects clients like R, Python and JavaScript to big Earth observation cloud back-ends in a simple and unified way. The acronym openEO contracts two concepts: open : used here in the context of open source software; open source software is available in source code form, and can be freely modified and redistributed; the openEO project will create open source software, reusable under a liberal open source license (Apache 2.0) EO : Earth observation Jointly, the openEO targets the processing and analysis of Earth observation data. The main objectives of the project are the following concepts: Simplicity : nowadays, many end-users use Python or R to analyse data and JavaScript to develop web applications; analysing large amounts of EO imagery should be equally simple, and seamlessly integrate with existing workflows Unification : current EO cloud back-ends all have a different API , making EO data analysis hard to validate and reproduce and back-ends difficult to compare in terms of capability and costs, or to combine them in a joint analysis across back-ends. A unified API can resolve many of these problems. The following pages introduce the core concepts of the project. Make sure to introduce yourself to the major technical terms used in the openEO project by reading the glossary . The openEO API defines a HTTP API that lets cloud back-ends with large Earth observation datasets communicate with front end analysis applications in an interoperable way. This documentation describes important API concepts and design decisions and gives a complete API reference documentation . As an overview, the openEO API specifies how to discover which Earth observation data and processes are available at cloud back-ends, execute (chained) processes on back-ends, run user-defined functions (UDFs) on back-ends where UDFs can be exposed to the data in different ways, download (intermediate) results, and manage user content including accounting. The API is defined as an OpenAPI 3.0 JSON file. openEO , A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications is a H2020 project funded under call EO-2-2017: EO Big Data Shift, under proposal number 776242. It will run from Oct 2017 to Sept 2020. This project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement No 776242. The contents of this website reflects only the authors\u2019 view; the European Commission is not responsible for any use that may be made of the information it provides.","title":"Introduction"},{"location":"#openeo-concepts-and-api-reference","text":"Work in progress, please contribute by adding issues . openEO develops an open application programming interface(API) that connects clients like R, Python and JavaScript to big Earth observation cloud back-ends in a simple and unified way. The acronym openEO contracts two concepts: open : used here in the context of open source software; open source software is available in source code form, and can be freely modified and redistributed; the openEO project will create open source software, reusable under a liberal open source license (Apache 2.0) EO : Earth observation Jointly, the openEO targets the processing and analysis of Earth observation data. The main objectives of the project are the following concepts: Simplicity : nowadays, many end-users use Python or R to analyse data and JavaScript to develop web applications; analysing large amounts of EO imagery should be equally simple, and seamlessly integrate with existing workflows Unification : current EO cloud back-ends all have a different API , making EO data analysis hard to validate and reproduce and back-ends difficult to compare in terms of capability and costs, or to combine them in a joint analysis across back-ends. A unified API can resolve many of these problems. The following pages introduce the core concepts of the project. Make sure to introduce yourself to the major technical terms used in the openEO project by reading the glossary . The openEO API defines a HTTP API that lets cloud back-ends with large Earth observation datasets communicate with front end analysis applications in an interoperable way. This documentation describes important API concepts and design decisions and gives a complete API reference documentation . As an overview, the openEO API specifies how to discover which Earth observation data and processes are available at cloud back-ends, execute (chained) processes on back-ends, run user-defined functions (UDFs) on back-ends where UDFs can be exposed to the data in different ways, download (intermediate) results, and manage user content including accounting. The API is defined as an OpenAPI 3.0 JSON file. openEO , A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications is a H2020 project funded under call EO-2-2017: EO Big Data Shift, under proposal number 776242. It will run from Oct 2017 to Sept 2020. This project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement No 776242. The contents of this website reflects only the authors\u2019 view; the European Commission is not responsible for any use that may be made of the information it provides.","title":"openEO - Concepts and API Reference"},{"location":"apireference-subscriptions/","text":"openEO API for Subscriptions 0.4.0 documentation \u00b6 The openEO API specification for interoperable cloud-based processing of large Earth observation datasets. This is a subset of the openEO API that handles WebSocket-based protocols for subscriptions and notifications. openeo.authorize , openeo.welcome , openeo.subscribe and openeo.unsubsribe MUST be implemeneted by all back-ends. Security considerations: A handshake has to be performed directly after establishing the WebSocket connection. The client MUST send a openeo.authorize request and receives a openeo.welcome message after a successful authorization. The WebSocket connections MUST be closed by servers once a request with invalid authorization credentials is sent. Servers are allowed to close connections to clients that have not sent a openeo.authorize request 30 seconds after establishing a WebSocket connection. Table of Contents \u00b6 Topics Schemas Topics \u00b6 subscribe openeo.authorize \u00b6 Message Starts a handshake with the server to authorize the client. The client MUST send a openeo.authorize request directly after establishing the WebSocket connection and a openeo.welcome will be sent by the server after successful authorization. The WebSocket connections MUST be closed if invalid authorization credentials are sent. Payload Name Type Description Accepted values authorization (required) string Takes the same values as the HTTP Authorization header that is accepted by most openEO endpoints. The value is concatenated from the Authorization scheme (usually Bearer ), a space and the actual token for authorization. Any message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any Example { \"authorization\" : \"Bearer eyJhbGciOiJIUzI1NiJ9.e30.4E_Bsx-pJi3kOW9wVXN8CgbATwP09D9V5gxh9-9zSZ0\" , \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.authorize\" } } publish openeo.welcome \u00b6 Message Welcome message for clients. Sends the supported topics, excluding openeo.authorize , openeo.subscribe , openeo.unsubscribe and openeo.welcome (because these MUST be implemented by every back-end anyway). This message MUST be sent by all servers directly after receiving the openeo.authorize message with valid credentials. Payload Name Type Description Accepted values message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.topics (required) array(string) Any Example { \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.welcome\" }, \"payload\" : { \"topics\" : [ \"openeo.jobs.output\" , \"openeo.jobs.status\" , \"openeo.data\" ] } } subscribe openeo.subscribe \u00b6 Message Subscribes to certain topics. Additional parameters that may be used to restrict the scope of the subscription are described in the specific messages. For example, a restriction of a subscription to a specific job. The WebSocket connections MUST be closed if invalid authorization credentials are sent. Payload Name Type Description Accepted values authorization (required) string Takes the same values as the HTTP Authorization header that is accepted by most openEO endpoints. The value is concatenated from the Authorization scheme (usually Bearer ), a space and the actual token for authorization. Any message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.topics (required) array(object) A list of topics to (un)subscribe to/from. Any payload.topics.topic (required) string Any Example { \"authorization\" : \"Bearer eyJhbGciOiJIUzI1NiJ9.e30.4E_Bsx-pJi3kOW9wVXN8CgbATwP09D9V5gxh9-9zSZ0\" , \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.subscribe\" }, \"payload\" : { \"topics\" : [ { \"topic\" : \"openeo.jobs.status\" , \"job_id\" : \"a3cca2b2aa1e3b5b\" }, { \"topic\" : \"openeo.files\" } ] } } subscribe openeo.unsubscribe \u00b6 Message Unsubscribes from certain topics. The WebSocket connections MUST be closed if invalid authorization credentials are sent. Payload Name Type Description Accepted values authorization (required) string Takes the same values as the HTTP Authorization header that is accepted by most openEO endpoints. The value is concatenated from the Authorization scheme (usually Bearer ), a space and the actual token for authorization. Any message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.topics (required) array(object) A list of topics to (un)subscribe to/from. Any payload.topics.topic (required) string Any Example { \"authorization\" : \"Bearer eyJhbGciOiJIUzI1NiJ9.e30.4E_Bsx-pJi3kOW9wVXN8CgbATwP09D9V5gxh9-9zSZ0\" , \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.unsubscribe\" }, \"payload\" : { \"topics\" : [ { \"topic\" : \"openeo.jobs.status\" , \"job_id\" : \"a3cca2b2aa1e3b5b\" }, { \"topic\" : \"openeo.files\" } ] } } publish openeo.jobs.output \u00b6 Message Data written to the output console with processes of a job. Subscriptions to this message can be restricted to a certain job by specifying a job_id . Payload Name Type Description Accepted values message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.job_id (required) string Unique identifier of a job that is generated by the back-end during job submission. Any payload.output (required) Output data of any type Any Example { \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.jobs.debug\" }, \"payload\" : { \"job_id\" : \"a3cca2b2aa1e3b5b\" , \"output\" : \"Hello world!\" } } publish openeo.jobs.debug \u00b6 Message Debugging information from job execution. Subscriptions to this message can be restricted to a certain job by specifying a job_id . Payload Name Type Description Accepted values message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.job_id (required) string Unique identifier of a job that is generated by the back-end during job submission. Any payload.message (required) string The thrown debug message Any payload.process object Process throwing the debug message. Any payload.process.name (required) string Name of the process. Any payload.process.parameters (required) object Key-value pairs for the parameters of the process. The keys are the parameter names and the values are the actual values specified for the parameter. Specify the empty object if the process does not have any parameters or was called without parameters. Any Example { \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.jobs.debug\" }, \"payload\" : { \"job_id\" : \"a3cca2b2aa1e3b5b\" , \"message\" : \"Invalid CRS specified, defaulting to EPSG:4326.\" , \"process\" : { \"name\" : \"filter_bbox\" , \"parameters\" : { \"crs\" : \"EPSG:9999\" , \"west\" : 55 , \"south\" : 10 , \"east\" : 56 , \"north\" : 11 } } } } publish openeo.jobs.status \u00b6 Message Inform about a status change of a job. Subscriptions to this message can be restricted to a certain job by specifying a job_id . Payload Name Type Description Accepted values message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.job_id (required) string Unique identifier of a job that is generated by the back-end during job submission. Any payload.status (required) string Current status submitted , queued , running , canceled , finished , error payload.progress number Progress of a running job in percent. Any Example { \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.jobs.status\" }, \"payload\" : { \"job_id\" : \"a3cca2b2aa1e3b5b\" , \"status\" : \"running\" , \"progress\" : 75.5 } } publish openeo.files \u00b6 Message Inform about changes regarding the user files. Subscriptions to this message can't be restricted to a certain file or folder. Payload Name Type Description Accepted values message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.user_id (required) string Unique identifier of the user. Any payload.path (required) string Path of the file, relative to the user's root directory. MUST NOT start with a slash and MUST NOT be url-encoded. Any payload.action (required) string Describes what has changed. created , updated , deleted Example { \"message\" : { \"issued\" : \"2018-08-07T14:06:36Z\" , \"topic\" : \"openeo.files\" }, \"payload\" : { \"user_id\" : \"john_doe\" , \"path\" : \"new_file.txt\" , \"action\" : \"created\" } } publish openeo.data \u00b6 Message Inform about changes regarding an EO dataset. At least one of the temporal_extent and spatial_extent fields MUST be specified. Subscriptions to this message can be restricted to a certain collection by specifying name and providing a valid collection name. Payload Name Type Description Accepted values message (required) object Any message.issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any message.topic (required) string Message type Any payload (required) object Any payload.name (required) string Unique identifier for EO datasets. Any payload.temporal_extent array(string) MUST be specified if the temporal extent of the dataset has changed. The temporal extent is always specified as an array, that consists of either a single timestamp or a start and an end time, each element formatted as a RFC 3339 date-time. Specifies the temporal extent of the data that has changed, not of the whole dataset. Example: The dataset covers images from beginning of 2015 until the end of 2018. A single image has been added, captured at the first day in 2019 at 01:00:00 UTC (1am). The spatial extent specified here must be an array containing a single string: 2019-01-01T01:00:00Z . Any payload.spatial_extent object MUST always be specified. It is the spatial extent of the data that was changed. Specifies the spatial extent of the data that has changed, not of the whole dataset. Example: The dataset covers the whole world and an image of Austria has been added. The spatial extent specified here must be the bounding box of Austria. Any payload.spatial_extent.crs string Coordinate reference system. EPSG codes must be supported. In addition, proj4 strings should be supported by back-ends. Whenever possible, it is recommended to use EPSG codes instead of proj4 strings. Defaults to EPSG:4326 unless the client explicitly requests a different coordinate reference system. Any payload.spatial_extent.west (required) number West (lower left corner, coordinate axis 1). Any payload.spatial_extent.south (required) number South (lower left corner, coordinate axis 2). Any payload.spatial_extent.east (required) number East (upper right corner, coordinate axis 1). Any payload.spatial_extent.north (required) number North (upper right corner, coordinate axis 2). Any payload.spatial_extent.base number Base (optional, lower left corner, coordinate axis 3). Any payload.spatial_extent.height number Height (optional, upper right corner, coordinate axis 3). Any Example of payload (generated) { \"message\" : { \"issued\" : \"2019-01-09T16:47:16Z\" , \"topic\" : \"openeo.sample\" }, \"payload\" : { \"name\" : \"MOD18Q1\" , \"temporal_extent\" : [ \"2016-01-01T02:30:00Z\" , \"2016-01-01T04:45:00Z\" ], \"spatial_extent\" : { \"crs\" : \"EPSG:4326\" , \"west\" : 0 , \"south\" : 0 , \"east\" : 0 , \"north\" : 0 , \"base\" : 0 , \"height\" : 0 } } } Schemas \u00b6 authorization Name Type Description Accepted values authorization string Any Example \"Bearer eyJhbGciOiJIUzI1NiJ9.e30.4E_Bsx-pJi3kOW9wVXN8CgbATwP09D9V5gxh9-9zSZ0\" message Name Type Description Accepted values issued (required) string Date and time when the message was sent, formatted as a RFC 3339 date-time. Any topic (required) string Message type Any Example (generated) { \"issued\" : \"2019-01-09T16:47:16Z\" , \"topic\" : \"openeo.sample\" } collection_name Name Type Description Accepted values collection_name string Any Example \"MOD18Q1\" job_id Name Type Description Accepted values job_id string Any Example \"a3cca2b2aa1e3b5b\" user_id Name Type Description Accepted values user_id string Any Example \"john_doe\" topics Name Type Description Accepted values topics array(object) Any topics.topic (required) string Any Example [ { \"topic\" : \"openeo.jobs.output\" , \"job_id\" : 123 }, { \"topic\" : \"openeo.jobs.status\" }, { \"topic\" : \"openeo.data\" , \"name\" : \"MOD18Q1\" } ]","title":"Subscriptions API Reference"},{"location":"apireference-subscriptions/#openeo-api-for-subscriptions-040-documentation","text":"The openEO API specification for interoperable cloud-based processing of large Earth observation datasets. This is a subset of the openEO API that handles WebSocket-based protocols for subscriptions and notifications. openeo.authorize , openeo.welcome , openeo.subscribe and openeo.unsubsribe MUST be implemeneted by all back-ends. Security considerations: A handshake has to be performed directly after establishing the WebSocket connection. The client MUST send a openeo.authorize request and receives a openeo.welcome message after a successful authorization. The WebSocket connections MUST be closed by servers once a request with invalid authorization credentials is sent. Servers are allowed to close connections to clients that have not sent a openeo.authorize request 30 seconds after establishing a WebSocket connection.","title":"openEO API for Subscriptions 0.4.0 documentation"},{"location":"apireference-subscriptions/#table-of-contents","text":"Topics Schemas","title":"Table of Contents"},{"location":"apireference-subscriptions/#topics","text":"","title":"Topics"},{"location":"apireference-subscriptions/#subscribe-openeoauthorize","text":"","title":"subscribe openeo.authorize"},{"location":"apireference-subscriptions/#publish-openeowelcome","text":"","title":"publish openeo.welcome"},{"location":"apireference-subscriptions/#subscribe-openeosubscribe","text":"","title":"subscribe openeo.subscribe"},{"location":"apireference-subscriptions/#subscribe-openeounsubscribe","text":"","title":"subscribe openeo.unsubscribe"},{"location":"apireference-subscriptions/#publish-openeojobsoutput","text":"","title":"publish openeo.jobs.output"},{"location":"apireference-subscriptions/#publish-openeojobsdebug","text":"","title":"publish openeo.jobs.debug"},{"location":"apireference-subscriptions/#publish-openeojobsstatus","text":"","title":"publish openeo.jobs.status"},{"location":"apireference-subscriptions/#publish-openeofiles","text":"","title":"publish openeo.files"},{"location":"apireference-subscriptions/#publish-openeodata","text":"","title":"publish openeo.data"},{"location":"apireference-subscriptions/#schemas","text":"","title":"Schemas"},{"location":"apireference/","text":"Placeholder for generated API specification.","title":"Core API Reference"},{"location":"arch/","text":"Architecture \u00b6 The openEO API defines a language how clients communicate to back-ends in order to analyze large Earth observation datasets. The API will be implemented by drivers for specific back-ends. Some first architecture considerations are listed below. The openEO API is a contract between clients and back-ends that describes the communication only Each back-end runs its own API instance including the specific back-end driver. There is no API instance that runs more than one driver. Clients in R, Python, and JavaScript connect directly to the back-ends and communicate with the back-ends over HTTPS according to the openEO API specification. API instances can run on back-end servers or additional intermediate layers, which then communicate to back-ends in a back-end specific way. Back-ends may add functionality and extend the API wherever there is need. There will be a central back-end registry service (openEO Hub), to allow users to search for back-ends with specific functionality and or data. The openEO API may define profiles in order to group specific functionality. Figure: Architecture - openEO API shown in dark blue Microservices \u00b6 To simplify and structure the development, the API is divided into a few microservices. Microservice Description Capabilities This microservice reports on the capabilities of the back-end, i.e. which API endpoints are implemented, which authentication methods are supported, and whether and how UDFs can be executed at the back-end. EO Data Discovery Describes which datasets and image collections are available at the back-end. Process Discovery Provides services to find out which processes a back-end provides, i.e., what users can do with the available data. UDF Discovery and execution of user-defined functions. Job Management Organizes and manages jobs that run processes on back-ends. File Management Organizes and manages user-uploaded files. Process Graph Management Organizes and manages user-defined process graphs. Secondary Services Management External web services to access data and job results such as a OGC WMTS service. Account Management User management, accounting and authentication.","title":"Architecture"},{"location":"arch/#architecture","text":"The openEO API defines a language how clients communicate to back-ends in order to analyze large Earth observation datasets. The API will be implemented by drivers for specific back-ends. Some first architecture considerations are listed below. The openEO API is a contract between clients and back-ends that describes the communication only Each back-end runs its own API instance including the specific back-end driver. There is no API instance that runs more than one driver. Clients in R, Python, and JavaScript connect directly to the back-ends and communicate with the back-ends over HTTPS according to the openEO API specification. API instances can run on back-end servers or additional intermediate layers, which then communicate to back-ends in a back-end specific way. Back-ends may add functionality and extend the API wherever there is need. There will be a central back-end registry service (openEO Hub), to allow users to search for back-ends with specific functionality and or data. The openEO API may define profiles in order to group specific functionality. Figure: Architecture - openEO API shown in dark blue","title":"Architecture"},{"location":"arch/#microservices","text":"To simplify and structure the development, the API is divided into a few microservices. Microservice Description Capabilities This microservice reports on the capabilities of the back-end, i.e. which API endpoints are implemented, which authentication methods are supported, and whether and how UDFs can be executed at the back-end. EO Data Discovery Describes which datasets and image collections are available at the back-end. Process Discovery Provides services to find out which processes a back-end provides, i.e., what users can do with the available data. UDF Discovery and execution of user-defined functions. Job Management Organizes and manages jobs that run processes on back-ends. File Management Organizes and manages user-uploaded files. Process Graph Management Organizes and manages user-defined process graphs. Secondary Services Management External web services to access data and job results such as a OGC WMTS service. Account Management User management, accounting and authentication.","title":"Microservices"},{"location":"changelog/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [0.4.0] - Unreleased \u00b6 Added \u00b6 GET /jobs/{job_id}/estimate can return the estimated required storage capacity. #122 GET /jobs/{job_id} has a property progress to indicate the progress. #82 GET /.well-known/openeo allows clients to choose between versions. #148 GET / (Capabilities): Requires to return a title ( title ), a description ( description ) and the back-end version ( backend_version ). #154 Billing plans have an additional required property paid . #157 Should provide a link to the Well-Known URI in the new links property. GET /processes (Process discovery): Processes can be categorizes with the category property. Parameters can be ordered with the parameter_order property instead of having a random order. Support for references to other processes in descriptions. GET /output_formats and GET /service_types can now provide links per entry. GET /udf_runtimes provide a list of UDF runtime environments. #87 Changed \u00b6 Changed process graph to a flexible graph-like structure, which also allows callbacks. #160 The process_graph_id of stored process graphs, the service_id of services and the job_id of jobs has changed to id in responses. #130 The name property of files has changed its name to path . #133 The status property of jobs is now required. POST /validation returns HTTP status code 200 for valid and invalid process graphs and responds with a list of errors. #144 version in response of GET / renamed to api_version . Endpoint paths in GET / must follow the openAPI specification. #128 Added authentication information where missing and allowed to call POST /validation without authentication. #151 Improved client development guidelines. #124 GET /processes (Process discovery): The name property of processes has changed to id . #130 mime_type replaced with media_type in the input parameters and return values. The schema for exceptions follows the general schema for openEO errors. #139 Changed the structure of examples . Removed \u00b6 Numeric openEO error codes. Replaced in responses with textual error codes. #139 Query parameters to replace process graph variables in GET /process_graphs/{process_graph_id} . #147 min_parameters and dependencies for parameters in process descriptions returned by GET /processes . Replaced output format properties in favor of an export process, which has resulted in in the removal of: The default output format in GET /output_formats . #153 The output format properties in POST /preview , POST /jobs , PATCH /jobs and GET /jobs/{job_id} requests. #153 gis_data_type (not to be confused with gis_data_types ) in the parameters of output formats in GET /output_formats Fixed \u00b6 Added missing Access-Control-Expose-Headers header to required CORS headers. [0.3.1] - 2018-11-06 \u00b6 Added \u00b6 createProcessGraph method to client development guidelines. JSON file with all specified errors. Textual error codes for each specified error. Allow setting a plan for POST /preview Default billing plan in GET / . #141 Job ID in JSON response for GET /jobs/{job_id}/results . Changed \u00b6 Several optional fields such as output , title and description are now nullable instead of requiring to omit them. The output format is not required in POST /preview any more and thus allows falling back to the default. The output_format parameter in createJob and execute in client development guidelines. The extent parameters in filter_bbox and filter_daterange are formally required now. Deprecated \u00b6 Numeric openEO error codes are soon to be replaced with textual error codes. eo:resolution in collection bands is a duplicate of eo:gsd . Use eo:gsd instead. Fixed \u00b6 Fixed a wrong definition of the header OpenEO-Costs in POST /preview . Fixed typo in method authenticateOIDC in client development guidelines. Fixed the definition of spatial extents by swapping north and south. Replaced the outdated occurrences of srs with crs in spatial extents. Added missing required descriptions to process definitions. Added missing error messages. Fixed unclear specification for arrays used as process graph arguments. Fixed inconsist schema of openEO error responses: Field is now consistently named message instead of description . [0.3.0] - 2018-09-21 \u00b6 First version after proof of concept tackling many major issues. No changelog available. [0.0.2] - 2018-03-22 \u00b6 Version for proof of concept. No changelog available. [0.0.1] - 2018-02-07 \u00b6 Initial version.","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#040-unreleased","text":"","title":"[0.4.0] - Unreleased"},{"location":"changelog/#added","text":"GET /jobs/{job_id}/estimate can return the estimated required storage capacity. #122 GET /jobs/{job_id} has a property progress to indicate the progress. #82 GET /.well-known/openeo allows clients to choose between versions. #148 GET / (Capabilities): Requires to return a title ( title ), a description ( description ) and the back-end version ( backend_version ). #154 Billing plans have an additional required property paid . #157 Should provide a link to the Well-Known URI in the new links property. GET /processes (Process discovery): Processes can be categorizes with the category property. Parameters can be ordered with the parameter_order property instead of having a random order. Support for references to other processes in descriptions. GET /output_formats and GET /service_types can now provide links per entry. GET /udf_runtimes provide a list of UDF runtime environments. #87","title":"Added"},{"location":"changelog/#changed","text":"Changed process graph to a flexible graph-like structure, which also allows callbacks. #160 The process_graph_id of stored process graphs, the service_id of services and the job_id of jobs has changed to id in responses. #130 The name property of files has changed its name to path . #133 The status property of jobs is now required. POST /validation returns HTTP status code 200 for valid and invalid process graphs and responds with a list of errors. #144 version in response of GET / renamed to api_version . Endpoint paths in GET / must follow the openAPI specification. #128 Added authentication information where missing and allowed to call POST /validation without authentication. #151 Improved client development guidelines. #124 GET /processes (Process discovery): The name property of processes has changed to id . #130 mime_type replaced with media_type in the input parameters and return values. The schema for exceptions follows the general schema for openEO errors. #139 Changed the structure of examples .","title":"Changed"},{"location":"changelog/#removed","text":"Numeric openEO error codes. Replaced in responses with textual error codes. #139 Query parameters to replace process graph variables in GET /process_graphs/{process_graph_id} . #147 min_parameters and dependencies for parameters in process descriptions returned by GET /processes . Replaced output format properties in favor of an export process, which has resulted in in the removal of: The default output format in GET /output_formats . #153 The output format properties in POST /preview , POST /jobs , PATCH /jobs and GET /jobs/{job_id} requests. #153 gis_data_type (not to be confused with gis_data_types ) in the parameters of output formats in GET /output_formats","title":"Removed"},{"location":"changelog/#fixed","text":"Added missing Access-Control-Expose-Headers header to required CORS headers.","title":"Fixed"},{"location":"changelog/#031-2018-11-06","text":"","title":"[0.3.1] - 2018-11-06"},{"location":"changelog/#added_1","text":"createProcessGraph method to client development guidelines. JSON file with all specified errors. Textual error codes for each specified error. Allow setting a plan for POST /preview Default billing plan in GET / . #141 Job ID in JSON response for GET /jobs/{job_id}/results .","title":"Added"},{"location":"changelog/#changed_1","text":"Several optional fields such as output , title and description are now nullable instead of requiring to omit them. The output format is not required in POST /preview any more and thus allows falling back to the default. The output_format parameter in createJob and execute in client development guidelines. The extent parameters in filter_bbox and filter_daterange are formally required now.","title":"Changed"},{"location":"changelog/#deprecated","text":"Numeric openEO error codes are soon to be replaced with textual error codes. eo:resolution in collection bands is a duplicate of eo:gsd . Use eo:gsd instead.","title":"Deprecated"},{"location":"changelog/#fixed_1","text":"Fixed a wrong definition of the header OpenEO-Costs in POST /preview . Fixed typo in method authenticateOIDC in client development guidelines. Fixed the definition of spatial extents by swapping north and south. Replaced the outdated occurrences of srs with crs in spatial extents. Added missing required descriptions to process definitions. Added missing error messages. Fixed unclear specification for arrays used as process graph arguments. Fixed inconsist schema of openEO error responses: Field is now consistently named message instead of description .","title":"Fixed"},{"location":"changelog/#030-2018-09-21","text":"First version after proof of concept tackling many major issues. No changelog available.","title":"[0.3.0] - 2018-09-21"},{"location":"changelog/#002-2018-03-22","text":"Version for proof of concept. No changelog available.","title":"[0.0.2] - 2018-03-22"},{"location":"changelog/#001-2018-02-07","text":"Initial version.","title":"[0.0.1] - 2018-02-07"},{"location":"codeofconduct/","text":"Contributor Code of Conduct \u00b6 As contributors and maintainers of this project, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities. We are committed to making participation in this project a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. Project maintainers who do not follow the Code of Conduct may be removed from the project team. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an issue or contacting one or more of the project maintainers. This Code of Conduct is adapted from the Contributor Covenant , version 1.0.0, available at http://contributor-covenant.org/version/1/0/0/ .","title":"Contributor Code of Conduct"},{"location":"codeofconduct/#contributor-code-of-conduct","text":"As contributors and maintainers of this project, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities. We are committed to making participation in this project a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. Project maintainers who do not follow the Code of Conduct may be removed from the project team. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an issue or contacting one or more of the project maintainers. This Code of Conduct is adapted from the Contributor Covenant , version 1.0.0, available at http://contributor-covenant.org/version/1/0/0/ .","title":"Contributor Code of Conduct"},{"location":"collections/","text":"Data Discovery (Collections) \u00b6 openEO strives for compatibility with STAC and OGC WFS 3.0 as far as possible. Implementing the data discovery endpoints of openEO should also produce mostly valid STAC and WFS 3.0 responses, including an incomplete compatibility with their APIs (see below). Warning STAC and OGC WFS 3.0, as well as openEO, are still under development and openEO currently only integrates intermediate dev versions due to time constraints. Therefore, it is very likely that further changes and adjustments will be made in the future. Extensions \u00b6 STAC has several extensions (see their repository ) that can be used to better describe your data. Clients and server are not required to implement all of them, so be aware that some clients may not be able to read all your meta data. Some commonly used extensions are: EO extension (mostly integrated within openEO) Scientific extension (integrated within openEO) Dimensions extension (draft) Links \u00b6 For data discovery in general and each collection you can specify a set of references. These can be alternate representations, e.g. data discovery via OGC WCS or OGC CSW, references to a license, references to actual raw data for downloading, detailed information about pre-processing, etc. Note STAC requires to add a link with relation type self (see below). Although this is not technically necessary for openEO and we do not enforce you with our validation tools to provide such a link, we still recommend to provide it anyway for compatibility reasons. Common link relation types \u00b6 The following table lists relation types that are commonly used as rel types in the links. The scope 'Collections' refers to the links that are related to a specific collection, 'Discovery' refers to links that are related to data discovery in general and are not about a specific collection. Type Description Scope self Absolute URL to the data discovery endpoint or the collection itself. Discovery +Collections root / parent URL to the data discovery endpoint. Collections child URL to a child STAC Catalog or STAC Dataset. Collections item URL to a STAC Item. Collections license The license URL for the dataset SHOULD be specified if the license field is set to proprietary . If there is no public license URL available, it is RECOMMENDED to supplement the collection with the license text in a separate file and link to this file. Collections alternate An alternative representation of the metadata. This could be a secondary web service such as OGC WCS or OGC CSW or a metadata document following another standard such as ISO 19115, INSPIRE or DCAT. Discovery +Collections about A resource that is related or further explains the entity, e.g. a user guide. Discovery +Collections derived_from Allows referencing the data this collection was derived from. Collections cite-as For all DOI names specified, the respective DOI links SHOULD be added to the links section of the catalog with the rel type cite-as . Collections More relation types may be listed in the STAC documentation. Compatibility with WFS and STAC APIs \u00b6 The data discovery endpoints GET /collections and GET /collections/{name} are compatible with WFS 3.0 and STAC. The only limitation with regard to response compatibility is that openEO allows open date ranges and WFS does not (see issue WFS_FES#155 ). Additionally, STAC and WFS define additional endpoints that need to be implemented to be fully compatible. The additional information can easily be integrated into an openEO API implementation. A rough list of actions for compatibility is available below, but please refer to their specifications to find out the full details. WFS 3.0 compatibility \u00b6 As of now, WFS 3.0 requires more endpoints for full compatibility. You should make the following changes to your API to implement a valid WFS: Add a links property to the GET / request that links to the WFS endpoints. Implement GET /api and return the WFS OpenAPI document. Implement GET /conformance and specify which conformance classes your WFS conforms to. Implement GET /collections/{collection-name}/items and GET /collections/{collection-name}/items/{feature-id} to support retrieval of individual features. STAC compatibility \u00b6 As of now, STAC has two more required endpoints that need to be implemented: GET /stac POST /stac/search","title":"Data Discovery"},{"location":"collections/#data-discovery-collections","text":"openEO strives for compatibility with STAC and OGC WFS 3.0 as far as possible. Implementing the data discovery endpoints of openEO should also produce mostly valid STAC and WFS 3.0 responses, including an incomplete compatibility with their APIs (see below). Warning STAC and OGC WFS 3.0, as well as openEO, are still under development and openEO currently only integrates intermediate dev versions due to time constraints. Therefore, it is very likely that further changes and adjustments will be made in the future.","title":"Data Discovery (Collections)"},{"location":"collections/#extensions","text":"STAC has several extensions (see their repository ) that can be used to better describe your data. Clients and server are not required to implement all of them, so be aware that some clients may not be able to read all your meta data. Some commonly used extensions are: EO extension (mostly integrated within openEO) Scientific extension (integrated within openEO) Dimensions extension (draft)","title":"Extensions"},{"location":"collections/#links","text":"For data discovery in general and each collection you can specify a set of references. These can be alternate representations, e.g. data discovery via OGC WCS or OGC CSW, references to a license, references to actual raw data for downloading, detailed information about pre-processing, etc. Note STAC requires to add a link with relation type self (see below). Although this is not technically necessary for openEO and we do not enforce you with our validation tools to provide such a link, we still recommend to provide it anyway for compatibility reasons.","title":"Links"},{"location":"collections/#common-link-relation-types","text":"The following table lists relation types that are commonly used as rel types in the links. The scope 'Collections' refers to the links that are related to a specific collection, 'Discovery' refers to links that are related to data discovery in general and are not about a specific collection. Type Description Scope self Absolute URL to the data discovery endpoint or the collection itself. Discovery +Collections root / parent URL to the data discovery endpoint. Collections child URL to a child STAC Catalog or STAC Dataset. Collections item URL to a STAC Item. Collections license The license URL for the dataset SHOULD be specified if the license field is set to proprietary . If there is no public license URL available, it is RECOMMENDED to supplement the collection with the license text in a separate file and link to this file. Collections alternate An alternative representation of the metadata. This could be a secondary web service such as OGC WCS or OGC CSW or a metadata document following another standard such as ISO 19115, INSPIRE or DCAT. Discovery +Collections about A resource that is related or further explains the entity, e.g. a user guide. Discovery +Collections derived_from Allows referencing the data this collection was derived from. Collections cite-as For all DOI names specified, the respective DOI links SHOULD be added to the links section of the catalog with the rel type cite-as . Collections More relation types may be listed in the STAC documentation.","title":"Common link relation types"},{"location":"collections/#compatibility-with-wfs-and-stac-apis","text":"The data discovery endpoints GET /collections and GET /collections/{name} are compatible with WFS 3.0 and STAC. The only limitation with regard to response compatibility is that openEO allows open date ranges and WFS does not (see issue WFS_FES#155 ). Additionally, STAC and WFS define additional endpoints that need to be implemented to be fully compatible. The additional information can easily be integrated into an openEO API implementation. A rough list of actions for compatibility is available below, but please refer to their specifications to find out the full details.","title":"Compatibility with WFS and STAC APIs"},{"location":"collections/#wfs-30-compatibility","text":"As of now, WFS 3.0 requires more endpoints for full compatibility. You should make the following changes to your API to implement a valid WFS: Add a links property to the GET / request that links to the WFS endpoints. Implement GET /api and return the WFS OpenAPI document. Implement GET /conformance and specify which conformance classes your WFS conforms to. Implement GET /collections/{collection-name}/items and GET /collections/{collection-name}/items/{feature-id} to support retrieval of individual features.","title":"WFS 3.0 compatibility"},{"location":"collections/#stac-compatibility","text":"As of now, STAC has two more required endpoints that need to be implemented: GET /stac POST /stac/search","title":"STAC compatibility"},{"location":"cors/","text":"Cross-Origin Resource Sharing (CORS) \u00b6 Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources [...] on a web page to be requested from another domain outside the domain from which the first resource was served. [...] CORS defines a way in which a browser and server can interact to determine whether or not it is safe to allow the cross-origin request. It allows for more freedom and functionality than purely same-origin requests, but is more secure than simply allowing all cross-origin requests. Source: https://en.wikipedia.org/wiki/Cross-origin_resource_sharing openEO-based back-ends are usually hosted on a different domain / host than the client that is requesting data from the back-end. Therefore most requests to the back-end are blocked by all modern browsers. This leads to the problem that the JavaScript library (and the Web Editor) can't access any back-end. Therefore, all back-end providers SHOULD support CORS. Without supporting CORS users can't access the back-end with browser-based clients, i.e. the JavaScript client . CORS is a recommendation of the W3C organization. The following chapters will explain how back-end providers can implement CORS support. 1. Supporting the OPTIONS method \u00b6 All endpoints must respond to the OPTIONS HTTP method. This is a response for the preflight requests made by the browsers. It needs to respond with a status code of 204 and send the HTTP headers shown in the table below. No body needs to be provided. Name Description Example Access-Control-Allow-Origin Allowed origin for the request, including protocol, host and port. It is RECOMMENDED to return the value of the request's origin header. If no Origin is sent to the back-end CORS headers SHOULD NOT be sent at all. http://client.isp.com:80 Access-Control-Allow-Credentials If authorization is implemented by the back-end the value MUST be true . true Access-Control-Allow-Headers Comma-separated list of HTTP headers allowed to be send. MUST contain at least Authorization if authorization is implemented by the back-end. Authorization, Content-Type Access-Control-Allow-Methods Comma-separated list of HTTP methods allowed to be requested. Back-ends MUST list all implemented HTTP methods for the endpoint here. OPTIONS, GET, POST, PATCH, PUT, DELETE Access-Control-Expose-Headers Some endpoints send non-safelisted HTTP response headers such as OpenEO-Identifier and OpenEO-Costs . All headers except Cache-Control , Content-Language , Content-Type , Expires , Last-Modified and Pragma must be listed in this header. Currently, the openEO API requires at least the following headers to be listed: OpenEO-Identifier, OpenEO-Costs . OpenEO-Identifier, OpenEO-Costs Content-Type SHOULD return the content type delivered by the request that the permission is requested for. application/json Example request and response \u00b6 Request: OPTIONS /api/v1/jobs HTTP / 1.1 Host : openeo.cloudprovider.com Origin : http://client.org:8080 Access-Control-Request-Method : POST Access-Control-Request-Headers : Authorization, Content-Type Response: HTTP / 1.1 204 No Content Access-Control-Allow-Origin : http://client.org:8080 Access-Control-Allow-Credentials : true Access-Control-Allow-Methods : OPTIONS, GET, POST, PATCH, PUT, DELETE Access-Control-Allow-Headers : Authorization, Content-Type Content-Type : application/json 2. Sending CORS headers \u00b6 The following headers MUST be included with every response: Name Description Example Access-Control-Allow-Origin Allowed origin for the request, including protocol, host and port. It is RECOMMENDED to return the value of the request's origin header. If no Origin is sent to the back-end CORS headers SHOULD NOT be sent at all. http://client.isp.com:80 Access-Control-Allow-Credentials If authorization is implemented by the back-end the value MUST be true . true Access-Control-Expose-Headers Some endpoints send non-safelisted HTTP response headers such as OpenEO-Identifier and OpenEO-Costs . All headers except Cache-Control , Content-Language , Content-Type , Expires , Last-Modified and Pragma must be listed in this header. Currently, the openEO API requires at least the following headers to be listed: OpenEO-Identifier, OpenEO-Costs . OpenEO-Identifier, OpenEO-Costs Tip Most server can send the required headers and the responses to the OPTIONS requests globally. Otherwise you may want to use a proxy server to add the headers and OPTIONS responses.","title":"CORS"},{"location":"cors/#cross-origin-resource-sharing-cors","text":"Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources [...] on a web page to be requested from another domain outside the domain from which the first resource was served. [...] CORS defines a way in which a browser and server can interact to determine whether or not it is safe to allow the cross-origin request. It allows for more freedom and functionality than purely same-origin requests, but is more secure than simply allowing all cross-origin requests. Source: https://en.wikipedia.org/wiki/Cross-origin_resource_sharing openEO-based back-ends are usually hosted on a different domain / host than the client that is requesting data from the back-end. Therefore most requests to the back-end are blocked by all modern browsers. This leads to the problem that the JavaScript library (and the Web Editor) can't access any back-end. Therefore, all back-end providers SHOULD support CORS. Without supporting CORS users can't access the back-end with browser-based clients, i.e. the JavaScript client . CORS is a recommendation of the W3C organization. The following chapters will explain how back-end providers can implement CORS support.","title":"Cross-Origin Resource Sharing (CORS)"},{"location":"cors/#1-supporting-the-options-method","text":"All endpoints must respond to the OPTIONS HTTP method. This is a response for the preflight requests made by the browsers. It needs to respond with a status code of 204 and send the HTTP headers shown in the table below. No body needs to be provided. Name Description Example Access-Control-Allow-Origin Allowed origin for the request, including protocol, host and port. It is RECOMMENDED to return the value of the request's origin header. If no Origin is sent to the back-end CORS headers SHOULD NOT be sent at all. http://client.isp.com:80 Access-Control-Allow-Credentials If authorization is implemented by the back-end the value MUST be true . true Access-Control-Allow-Headers Comma-separated list of HTTP headers allowed to be send. MUST contain at least Authorization if authorization is implemented by the back-end. Authorization, Content-Type Access-Control-Allow-Methods Comma-separated list of HTTP methods allowed to be requested. Back-ends MUST list all implemented HTTP methods for the endpoint here. OPTIONS, GET, POST, PATCH, PUT, DELETE Access-Control-Expose-Headers Some endpoints send non-safelisted HTTP response headers such as OpenEO-Identifier and OpenEO-Costs . All headers except Cache-Control , Content-Language , Content-Type , Expires , Last-Modified and Pragma must be listed in this header. Currently, the openEO API requires at least the following headers to be listed: OpenEO-Identifier, OpenEO-Costs . OpenEO-Identifier, OpenEO-Costs Content-Type SHOULD return the content type delivered by the request that the permission is requested for. application/json","title":"1. Supporting the OPTIONS method"},{"location":"cors/#example-request-and-response","text":"Request: OPTIONS /api/v1/jobs HTTP / 1.1 Host : openeo.cloudprovider.com Origin : http://client.org:8080 Access-Control-Request-Method : POST Access-Control-Request-Headers : Authorization, Content-Type Response: HTTP / 1.1 204 No Content Access-Control-Allow-Origin : http://client.org:8080 Access-Control-Allow-Credentials : true Access-Control-Allow-Methods : OPTIONS, GET, POST, PATCH, PUT, DELETE Access-Control-Allow-Headers : Authorization, Content-Type Content-Type : application/json","title":"Example request and response"},{"location":"cors/#2-sending-cors-headers","text":"The following headers MUST be included with every response: Name Description Example Access-Control-Allow-Origin Allowed origin for the request, including protocol, host and port. It is RECOMMENDED to return the value of the request's origin header. If no Origin is sent to the back-end CORS headers SHOULD NOT be sent at all. http://client.isp.com:80 Access-Control-Allow-Credentials If authorization is implemented by the back-end the value MUST be true . true Access-Control-Expose-Headers Some endpoints send non-safelisted HTTP response headers such as OpenEO-Identifier and OpenEO-Costs . All headers except Cache-Control , Content-Language , Content-Type , Expires , Last-Modified and Pragma must be listed in this header. Currently, the openEO API requires at least the following headers to be listed: OpenEO-Identifier, OpenEO-Costs . OpenEO-Identifier, OpenEO-Costs Tip Most server can send the required headers and the responses to the OPTIONS requests globally. Otherwise you may want to use a proxy server to add the headers and OPTIONS responses.","title":"2. Sending CORS headers"},{"location":"errors/","text":"Status and error handling \u00b6 The success of requests MUST be indicated using HTTP status codes according to RFC 7231 . If the API responds with a status code between 100 and 399 the back-end indicates that the request has been handled successfully. In general an error is communicated with a status code between 400 and 599. Client errors are defined as a client passing invalid data to the service and the service correctly rejecting that data. Examples include invalid credentials, incorrect parameters, unknown versions, or similar. These are generally \"4xx\" HTTP error codes and are the result of a client passing incorrect or invalid data. Client errors do not contribute to overall API availability. Server errors are defined as the server failing to correctly return in response to a valid client request. These are generally \"5xx\" HTTP error codes. Server errors do contribute to the overall API availability. Calls that fail due to rate limiting or quota failures MUST NOT count as server errors. JSON error object \u00b6 A JSON error object SHOULD be sent with all responses that have a status code between 400 and 599. { \"id\" : \"936DA01F-9ABD-4D9D-80C7-02AF85C822A8\" , \"code\" : \"SampleError\" , \"message\" : \"A sample error message.\" , \"url\" : \"http://www.openeo.org/docs/errors/SampleError\" } Sending code and message is REQUIRED. A back-end MAY add a free-form id (unique identifier) to the error response to be able to log and track errors with further non-disclosable details. The code is either one of the standardized textual openEO error codes below or a proprietary error code. The message explains the reason the server is rejecting the request. For \"4xx\" error codes the message explains how the client needs to modify the request. By default the message MUST be sent in English language. Content Negotiation is used to localize the error messages: If an Accept-Language header is sent by the client and a translation is available, the message should be translated accordingly and the Content-Language header must be present in the response. See \" How to localize your API \" for more information. url is an OPTIONAL attribute and contains a link to a resource that is explaining the error and potential solutions in-depth. Standardized status codes \u00b6 The openEO API usually uses the following HTTP status codes for successful requests: 200 OK : Indicates a successful request with a response body being sent. 201 Created Indicates a successful request that successfully created a new resource. Sends a Location header to the newly created resource without a response body. 202 Accepted Indicates a successful request that successfully queued the creation of a new resource, but it has not been created yet. The response is sent without a response body. 204 No Content : Indicates a successful request without a response body being sent. The openEO API often uses the following HTTP status codes for failed requests: 400 Bad request : The back-end responds with this error code whenever the error has its origin on client side and no other HTTP status code in the 400 range is suitable. 401 Unauthorized : The client did not provide any authentication details for a resource requiring authentication or the provided authentication details are not correct. 403 Forbidden : The client did provided correct authentication details, but the privileges/permissions of the provided credentials do not allow to request the resource. 404 Not Found : The resource specified by the path does not exist, i.e. one of the resources belonging to the specified identifiers are not available at the back-end. Note: Unsupported endpoints MUST use HTTP status code 501. 500 Internal Server Error : The error has its origin on server side and no other status code in the 500 range is suitable. 501 Not implemented : An endpoint is specified in the openEO API, but is not supported. If a HTTP status code in the 400 range is returned, the client SHOULD NOT repeat the request without modifications. For HTTP status code in the 500 range, the client MAY repeat the same request later. All HTTP status codes defined in RFC 7231 in the 400 and 500 ranges can be used as openEO error code in addition to the most used status codes mentioned here. Responding with openEO error codes 400 and 500 SHOULD be avoided in favor of any more specific standardized or proprietary openEO error code. openEO error codes \u00b6 The following table of error codes is incomplete . These error codes will evolve over time. If you are missing any common error, please contribute it by adding an issue , creating a pull request or get in contact in our chat room . The whole table of error codes is available as JSON file , which can be used by implementors to automatically generate error responses. Categories Account Management EO Data Discovery File Management General Job Management Process Graph Management Processes Secondary Services Management Subscriptions Account Management openEO Error Code Description Message HTTP Status Code AuthenticationRequired The client did not provide any authentication details for a resource requiring authentication or the provided authentication details are not correct. Unauthorized. 401 AuthenticationSchemeInvalid Invalid authentication scheme (e.g. Bearer). Authentication method not supported. 403 CredentialsInvalid Credentials are not correct. 403 TokenInalid Authorization token invalid or expired. Session has expired. 403 EO Data Discovery openEO Error Code Description Message HTTP Status Code CollectionNotFound The requested collection does not exist. Collection does not exist. 404 File Management openEO Error Code Description Message HTTP Status Code ContentTypeInvalid The specified media (MIME) type used in the Content-Type header is not allowed. Media type specified in the request is not supported. Supported media types: {types} 400 FileContentInvalid The content of the file is invalid. File content is invalid. 400 FileLocked The file is locked by a running job or another process. File '{file}' is locked. 400 FileNotFound The requested file does not exist. File does not exist. 404 FileOperationUnsupported The specified path is not a file and the operation is only supported for files. Path is likely a directory. Operation is only supported for files. 400 FilePathInvalid The specified path is invalid or not accessible. Path could contain invalid characters, an invalid user ID or point to an existing folder or a location outside of the user folder. File path is invalid. 400 FileSizeExceeded File exceeds allowed maximum file size. File size it too large. Maximum file size: {size} 400 FileTypeInvalid File format, file extension or media (MIME) type is not allowed. File type not allowed. Allowed file types: {types} 400 StorageFailure Server couldn't store file(s) due to server-side reasons. Unable to store file(s). 500 StorageQuotaExceeded The storage quota has been exceeded by the user. Insufficient Storage. 400 General openEO Error Code Description Message HTTP Status Code ContentTypeInvalid The specified media (MIME) type used in the Content-Type header is not allowed. Media type specified in the request is not supported. Supported media types: {types} 400 FeatureUnsupported The back-end responds with this error whenever an endpoint is specified in the openEO API, but is not supported. Feature not supported. 501 InfrastructureBusy Service is generally available, but the infrastructure can't handle it at the moment as too many requests are processed. Service is not available at the moment due to overloading. Please try again later. 503 InfrastructureMaintenance Service is currently not available, but the infrastructure is currently undergoing maintenance work. Service is not available at the moment due to maintenance work. Please try again later. 503 Internal An internal server error with a proprietary message. Server error: {message} 500 NotFound To be used if the requested resource does not exist. Note: Unsupported endpoints MUST send an 'FeatureUnsupported' error. There are also specialized errors for missing jobs (JobNotFound), files (FileNotFound), etc. Resource not found. 404 Timeout The request took too long and timed out. Request timed out. 408 Job Management openEO Error Code Description Message HTTP Status Code BillingPlanInvalid The specified billing plan is not on the list of available plans. The specified billing plan is not valid. 400 BudgetInvalid The specified budget is too low as it is either smaller than or equal to 0 or below the costs. The specified budget is too low. 400 FormatArgumentInvalid The value specified for the output format argument '{argument}' is invalid: {reason} 400 FormatArgumentUnsupported Output format argument '{argument}' is not supported. 400 FormatUnsuitable Data can't be transformed into the requested output format. 400 FormatUnsupported Output format not supported. 400 JobLocked The job is currently locked due to a running batch computation and can't be modified meanwhile. Job is locked due to a queued or running batch computation. 400 JobNotFinished Job has not finished computing the results yet. Please try again later. 400 JobNotFound The requested job does not exist. The job does not exist. 404 JobNotStarted Job has not been queued or started yet or was canceled and not restarted by the user. Job hasn't been started yet. 400 NoDataForUpdate For PATCH requests: No valid data specified at all. No valid data specified to be updated. 400 PaymentRequired The budget required to fulfil the request are insufficient. Payment required. 402 ProcessGraphMissing No valid process graph specified. 400 PropertyNotEditable For PATCH requests: The specified parameter can't be updated. It is read-only. Specified property '{property}' is read-only. 400 StorageFailure Server couldn't store file(s) due to server-side reasons. Unable to store file(s). 500 StorageQuotaExceeded The storage quota has been exceeded by the user. Insufficient Storage. 400 Timeout The request took too long and timed out. Request timed out. 408 VariableDefaultValueTypeInvalid The default value specified for the process graph variable '{variable_id}' is not of type '{type}'. 400 VariableIdInvalid A specified variable ID is not valid. 400 VariableTypeInvalid The data type specified for the process graph variable '{variable_id}' is invalid. Must be one of: string, boolean, number, array or object. 400 VariableValueMissing No value specified for process graph variable '{variable_id}'. 400 Process Graph Management openEO Error Code Description Message HTTP Status Code NoDataForUpdate For PATCH requests: No valid data specified at all. No valid data specified to be updated. 400 ProcessGraphMissing No valid process graph specified. 400 ProcessGraphNotFound The requested process graph does not exist. Process graph does not exist. 404 PropertyNotEditable For PATCH requests: The specified parameter can't be updated. It is read-only. Specified property '{property}' is read-only. 400 VariableDefaultValueTypeInvalid The default value specified for the process graph variable '{variable_id}' is not of type '{type}'. 400 VariableIdInvalid A specified variable ID is not valid. 400 VariableTypeInvalid The data type specified for the process graph variable '{variable_id}' is invalid. Must be one of: string, boolean, number, array or object. 400 VariableValueMissing No value specified for process graph variable '{variable_id}'. 400 Processes openEO Error Code Description Message HTTP Status Code CRSInvalid Invalid or unsupported CRS specified. CRS '{crs}' is invalid. 400 CollectionNotFound The requested collection does not exist. Collection does not exist. 404 CoordinateOutOfBounds Coordinate is out of bounds. 400 FileContentInvalid The content of the file is invalid. File content is invalid. 400 FileNotFound The requested file does not exist. File does not exist. 404 JobNotFound The requested job does not exist. The job does not exist. 404 ProcessArgumentInvalid The value specified for the process argument '{argument}' in process '{process}' is invalid: {reason} 400 ProcessArgumentRequired Process '{process}' requires argument '{argument}'. 400 ProcessArgumentUnsupported Process '{process}' does not support argument '{argument}'. 400 ProcessArgumentsMissing Process '{process}' requires at least '{min_parameters}' parameters. 400 ProcessUnsupported Process '{process}' is not supported. 400 Secondary Services Management openEO Error Code Description Message HTTP Status Code BillingPlanInvalid The specified billing plan is not on the list of available plans. The specified billing plan is not valid. 400 BudgetInvalid The specified budget is too low as it is either smaller than or equal to 0 or below the costs. The specified budget is too low. 400 NoDataForUpdate For PATCH requests: No valid data specified at all. No valid data specified to be updated. 400 PaymentRequired The budget required to fulfil the request are insufficient. Payment required. 402 ProcessGraphMissing No valid process graph specified. 400 PropertyNotEditable For PATCH requests: The specified parameter can't be updated. It is read-only. Specified property '{property}' is read-only. 400 ServiceArgumentInvalid The value specified for the secondary service argument '{argument}' is invalid: {reason} 400 ServiceArgumentRequired Required secondary service argument '{argument}' is missing. 400 ServiceArgumentUnsupported Secondary service argument '{argument}' is not supported. 400 ServiceNotFound The requested secondary service does not exist. Service does not exist. 404 ServiceUnsupported Secondary service type is not supported. 400 VariableValueMissing No value specified for process graph variable '{variable_id}'. 400 Subscriptions openEO Error Code Description Message HTTP Status Code WebSocketUpgradeNotRequested In order to subscribe the connection must be upgradable to WebSockets. Client sent invalid request to establish subscriptions. 400","title":"Error Handling"},{"location":"errors/#status-and-error-handling","text":"The success of requests MUST be indicated using HTTP status codes according to RFC 7231 . If the API responds with a status code between 100 and 399 the back-end indicates that the request has been handled successfully. In general an error is communicated with a status code between 400 and 599. Client errors are defined as a client passing invalid data to the service and the service correctly rejecting that data. Examples include invalid credentials, incorrect parameters, unknown versions, or similar. These are generally \"4xx\" HTTP error codes and are the result of a client passing incorrect or invalid data. Client errors do not contribute to overall API availability. Server errors are defined as the server failing to correctly return in response to a valid client request. These are generally \"5xx\" HTTP error codes. Server errors do contribute to the overall API availability. Calls that fail due to rate limiting or quota failures MUST NOT count as server errors.","title":"Status and error handling"},{"location":"errors/#json-error-object","text":"A JSON error object SHOULD be sent with all responses that have a status code between 400 and 599. { \"id\" : \"936DA01F-9ABD-4D9D-80C7-02AF85C822A8\" , \"code\" : \"SampleError\" , \"message\" : \"A sample error message.\" , \"url\" : \"http://www.openeo.org/docs/errors/SampleError\" } Sending code and message is REQUIRED. A back-end MAY add a free-form id (unique identifier) to the error response to be able to log and track errors with further non-disclosable details. The code is either one of the standardized textual openEO error codes below or a proprietary error code. The message explains the reason the server is rejecting the request. For \"4xx\" error codes the message explains how the client needs to modify the request. By default the message MUST be sent in English language. Content Negotiation is used to localize the error messages: If an Accept-Language header is sent by the client and a translation is available, the message should be translated accordingly and the Content-Language header must be present in the response. See \" How to localize your API \" for more information. url is an OPTIONAL attribute and contains a link to a resource that is explaining the error and potential solutions in-depth.","title":"JSON error object"},{"location":"errors/#standardized-status-codes","text":"The openEO API usually uses the following HTTP status codes for successful requests: 200 OK : Indicates a successful request with a response body being sent. 201 Created Indicates a successful request that successfully created a new resource. Sends a Location header to the newly created resource without a response body. 202 Accepted Indicates a successful request that successfully queued the creation of a new resource, but it has not been created yet. The response is sent without a response body. 204 No Content : Indicates a successful request without a response body being sent. The openEO API often uses the following HTTP status codes for failed requests: 400 Bad request : The back-end responds with this error code whenever the error has its origin on client side and no other HTTP status code in the 400 range is suitable. 401 Unauthorized : The client did not provide any authentication details for a resource requiring authentication or the provided authentication details are not correct. 403 Forbidden : The client did provided correct authentication details, but the privileges/permissions of the provided credentials do not allow to request the resource. 404 Not Found : The resource specified by the path does not exist, i.e. one of the resources belonging to the specified identifiers are not available at the back-end. Note: Unsupported endpoints MUST use HTTP status code 501. 500 Internal Server Error : The error has its origin on server side and no other status code in the 500 range is suitable. 501 Not implemented : An endpoint is specified in the openEO API, but is not supported. If a HTTP status code in the 400 range is returned, the client SHOULD NOT repeat the request without modifications. For HTTP status code in the 500 range, the client MAY repeat the same request later. All HTTP status codes defined in RFC 7231 in the 400 and 500 ranges can be used as openEO error code in addition to the most used status codes mentioned here. Responding with openEO error codes 400 and 500 SHOULD be avoided in favor of any more specific standardized or proprietary openEO error code.","title":"Standardized status codes"},{"location":"errors/#openeo-error-codes","text":"The following table of error codes is incomplete . These error codes will evolve over time. If you are missing any common error, please contribute it by adding an issue , creating a pull request or get in contact in our chat room . The whole table of error codes is available as JSON file , which can be used by implementors to automatically generate error responses.","title":"openEO error codes"},{"location":"examples-poc/","text":"Examples (proof of concept) \u00b6 This page gives a detailed description of the openEO proof of concept use cases. After the proof of concept, this stays in the API to have some basic examples. The proof of concept covered three clearly defined example use cases and how they are translated to sequences of API calls: Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery Create a monthly aggregated Sentinel 1 product from a custom Python script Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons Note CORS and authentication is not included in these examples for simplicity. Repeating calls are also not included as it would not make much sense to list the same discovery requests for each use case individually. Use Case 1 \u00b6 Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery. 1. Requesting the capabilities of the back-end \u00b6 Request GET / Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"api_version\" : \"0.4.0\" \"endpoints\" : [ { \"path\" : \"/collections\" , \"methods\" : [ \"GET\" ] }, { \"path\" : \"/collections/{name}\" , \"methods\" : [ \"GET\" ] }, { \"path\" : \"/processes\" , \"methods\" : [ \"GET\" ] }, { \"path\" : \"/jobs\" , \"methods\" : [ \"GET\" , \"POST\" ] }, { \"path\" : \"/jobs/{job_id}\" , \"methods\" : [ \"GET\" , \"DELETE\" , \"PATCH\" ] }, { \"path\" : \"/jobs/{job_id}/results\" , \"methods\" : [ \"GET\" , \"POST\" , \"DELETE\" ] }, { \"path\" : \"/services\" , \"methods\" : [ \"GET\" , \"POST\" ] }, { \"path\" : \"/services/{service_id}\" , \"methods\" : [ \"GET\" , \"DELETE\" , \"PATCH\" ] } ], \"billing\" : { \"currency\" : \"EUR\" , \"plans\" : [ { \"name\" : \"free\" , \"description\" : \"Free plan. Calculates one tile per second and a maximum amount of 100 tiles per hour.\" , \"url\" : \"http://openeo.org/plans/free-plan\" } ] } } 2. Check whether Sentinel 2A Level 1C data is available at the back-end \u00b6 Request GET /collections HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"collections\" : [ { \"name\" : \"Sentinel-2A\" , \"title\" : \"Sentinel-2A MSI L1C\" , \"description\" : \"Sentinel-2A is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.\" , \"license\" : \"proprietary\" , \"extent\" : { \"spatial\" : [ 180 , -56 , -180 , 83 ], \"temporal\" : [ \"2015-06-23T00:00:00Z\" , null ] }, \"links\" : [ { \"rel\" : \"self\" , \"href\" : \"https://openeo.org/api/collections/Sentinel-2A\" }, { \"rel\" : \"license\" , \"href\" : \"https://scihub.copernicus.eu/twiki/pub/SciHubWebPortal/TermsConditions/Sentinel_Data_Terms_and_Conditions.pdf\" } ] } ], \"links\" : [ { \"rel\" : \"self\" , \"href\" : \"https://openeo.org/api/collections\" } ] } 3. Check that needed processes are available \u00b6 Request GET /processes HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"processes\" : [ { \"name\" : \"get_collection\" , \"summary\" : \"Selects a collection.\" , \"description\" : \"Filters and selects a single collection provided by the back-end. The back-end provider decides which of the potential collections is the most relevant one to be selected.\" , \"min_parameters\" : 1 , \"parameters\" : { \"name\" : { \"description\" : \"Filter by collection name\" , \"schema\" : { \"type\" : \"string\" , \"examples\" : [ \"Sentinel2A-L1C\" ] } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"filter_bands\" , \"summary\" : \"Filters by bands.\" , \"description\" : \"Allows to extract one or multiple bands of multi-band raster image collection.\\nBands can be chosen either by band id, band name or by wavelength.\\n\\nimagery and at one of the other arguments is required to be specified.\" , \"min_parameters\" : 2 , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"bands\" : { \"description\" : \"string or array of strings containing band ids.\" , \"schema\" : { \"type\" : [ \"string\" , \"array\" ], \"items\" : { \"type\" : \"string\" } } }, \"names\" : { \"description\" : \"string or array of strings containing band names.\" , \"schema\" : { \"type\" : [ \"string\" , \"array\" ], \"items\" : { \"type\" : \"string\" } } }, \"wavelengths\" : { \"description\" : \"Either a number specifying a specific wavelength or a two-element array of numbers specifying a minimum and maximum wavelength.\" , \"schema\" : { \"type\" : [ \"number\" , \"array\" ], \"minItems\" : 2 , \"maxItems\" : 2 , \"items\" : { \"type\" : \"number\" } } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"filter_daterange\" , \"summary\" : \"Filters by temporal extent.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"extent\" : { \"description\" : \"Temporal extent specified by a start and an end time, each formatted as a [RFC 3339](https://www.ietf.org/rfc/rfc3339) date-time. Open date ranges are supported and can be specified by setting one of the times to null. Setting both entries to null is not allowed.\" , \"schema\" : { \"type\" : \"array\" , \"format\" : \"temporal_extent\" , \"required\" : true , \"examples\" : [ [ \"2016-01-01T00:00:00Z\" , \"2017-10-01T00:00:00Z\" ] ], \"items\" : { \"type\" : [ \"string\" , \"null\" ], \"format\" : \"date-time\" , \"minItems\" : 2 , \"maxItems\" : 2 } } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"filter_bbox\" , \"summary\" : \"Filters by spatial extent.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"extent\" : { \"description\" : \"Spatial extent, may include a vertical axis (height or depth).\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"spatial_extent\" , \"required\" : [ \"west\" , \"south\" , \"east\" , \"north\" ], \"properties\" : { \"crs\" : { \"description\" : \"Coordinate reference system. EPSG codes must be supported. In addition, proj4 strings should be supported by back-ends. Whenever possible, it is recommended to use EPSG codes instead of proj4 strings.\\nDefaults to `EPSG:4326` unless the client explicitly requests a different coordinate reference system.\" , \"type\" : \"string\" , \"default\" : \"EPSG:4326\" }, \"west\" : { \"description\" : \"West (lower left corner, coordinate axis 1).\" , \"type\" : \"number\" }, \"south\" : { \"description\" : \"South (lower left corner, coordinate axis 2).\" , \"type\" : \"number\" }, \"east\" : { \"description\" : \"East (upper right corner, coordinate axis 1).\" , \"type\" : \"number\" }, \"north\" : { \"description\" : \"North (upper right corner, coordinate axis 2).\" , \"type\" : \"number\" }, \"base\" : { \"description\" : \"Base (optional, lower left corner, coordinate axis 3).\" , \"type\" : \"number\" }, \"height\" : { \"description\" : \"Height (optional, upper right corner, coordinate axis 3).\" , \"type\" : \"number\" } } } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"NDVI\" , \"summary\" : \"Calculates the Normalized Difference Vegetation Index.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"red\" : { \"description\" : \"Band id of the red band.\" , \"required\" : true , \"schema\" : { \"type\" : \"string\" } }, \"nir\" : { \"description\" : \"Band id of the near-infrared band.\" , \"required\" : true , \"schema\" : { \"type\" : \"string\" } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"exceptions\" : { \"RedBandInvalid\" : { \"description\" : \"The specified red band is not available or contains invalid data.\" }, \"NirBandInvalid\" : { \"description\" : \"The specified nir band is not available or contains invalid data.\" } } }, { \"name\" : \"min_time\" , \"summary\" : \"Calculates minimum values of time series.\" , \"description\" : \"Finds the minimum value of time series for all bands of the input dataset.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } } ], \"links\" : {} } 4. Request the supported secondary web service types \u00b6 Request GET /service_types HTTP / 1.1 Content-Type : application/json; charset=utf-8 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"WMS\" : { \"parameters\" : { \"version\" : { \"type\" : \"string\" , \"description\" : \"The WMS version to use.\" , \"default\" : \"1.3.0\" , \"enum\" : [ \"1.1.1\" , \"1.3.0\" ] } }, \"attributes\" : { \"layers\" : { \"type\" : \"array\" , \"description\" : \"Array of layer names.\" , \"example\" : [ \"roads\" , \"countries\" , \"water_bodies\" ] } } } } 5. Create a WMS service \u00b6 Request POST /services HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Min. NDVI for Sentinel 2\" , \"description\" : \"Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery.\" , \"process_graph\" : { \"process_id\" : \"min_time\" , \"imagery\" : { \"process_id\" : \"NDVI\" , \"imagery\" : { \"process_id\" : \"filter_daterange\" , \"imagery\" : { \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"extent\" : [ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"red\" : \"B4\" , \"nir\" : \"B8\" } }, \"type\" : \"WMS\" , \"enabled\" : true , \"parameters\" : { \"version\" : \"1.1.1\" }, \"plan\" : \"free\" } Response HTTP / 1.1 201 Created Location : https://openeo.org/api/v0.4/services/wms-a3cca9 OpenEO-Identifier : wms-a3cca9 6. Requesting the service information \u00b6 Request POST https://openeo.org/api/v0.4/services/wms-a3cca9 HTTP / 1.1 Content-Type : application/json; charset=utf-8 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"service_id\" : \"wms-a3cca9\" , \"title\" : \"Min. NDVI for Sentinel 2\" , \"description\" : \"Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery.\" , \"process_graph\" : { \"process_id\" : \"min_time\" , \"imagery\" : { \"process_id\" : \"NDVI\" , \"imagery\" : { \"process_id\" : \"filter_daterange\" , \"imagery\" : { \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"extent\" : [ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"red\" : \"B4\" , \"nir\" : \"B8\" } }, \"url\" : \"https://openeo.org/wms/a3cca9\" , \"type\" : \"WMS\" , \"enabled\" : true , \"parameters\" : { \"version\" : \"1.1.1\" }, \"attributes\" : { \"layers\" : [ \"min_time\" ] }, \"submitted\" : \"2017-01-01T09:32:12Z\" , \"plan\" : \"free\" , \"budget\" : null } 7. Download the data on demand from the WMS \u00b6 Omitted, not part of the openEO API. WMS is located at https://openeo.org/wms/a3cca9 . Use Case 2 \u00b6 Create a monthly aggregated Sentinel 1 product from a custom Python script. 1. Ask the back-end for available Sentinel 1 data \u00b6 Request GET /collections/Sentinel-1 HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"name\" : \"Sentinel-1\" , \"description\" : \"Sentinel 1 C-band Synthetic Aperture Radar (SAR) Ground Range Data\" , \"license\" : \"proprietary\" , \"keywords\" : [ \"copernicus\" , \"esa\" , \"sentinel\" , \"sar\" ], \"provider\" : [ { \"name\" : \"European Space Agency (ESA)\" , \"url\" : \"https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar\" } ], \"extent\" : { \"spatial\" : [ -34 , 35 , 39 , 71 ], \"temporal\" : [ \"2016-01-01T00:00:00Z\" , null ] }, \"links\" : [ { \"rel\" : \"self\" , \"href\" : \"https://openeo.org/api/collections/Sentinel-1\" }, { \"rel\" : \"license\" , \"href\" : \"https://scihub.copernicus.eu/twiki/pub/SciHubWebPortal/TermsConditions/Sentinel_Data_Terms_and_Conditions.pdf\" } ], \"eo:constellation\" : \"sentinel-1\" , \"eo:bands\" : { \"VV\" : { \"common_name\" : \"VV\" }, \"VH\" : { \"common_name\" : \"VH\" } } } 2. Upload python script \u00b6 Request PUT /files/john_doe/s1_aggregate.py HTTP / 1.1 <File content> Response HTTP / 1.1 204 No Content 3. Create a job \u00b6 Request POST /jobs HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Monthly aggregation on Sentinel 1\" , \"description\" : \"Create a monthly aggregated Sentinel 1 product from a custom Python script.\" , \"process_graph\" :{ \"process_id\" : \"aggregate_time\" , \"script\" : \"/files/john_doe/s1_aggregate.py\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-1\" }, \"extent\" :{ \"west\" : 16.1 , \"south\" : 47.2 , \"east\" : 16.6 , \"north\" : 48.6 } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] } }, \"plan\" : \"free\" } Response HTTP / 1.1 201 Created Location : https://openeo.org/api/v0.4/jobs/132 OpenEO-Identifier : 132 4. Start batch processing the job \u00b6 Request POST /jobs/132/results HTTP / 1.1 Response HTTP / 1.1 202 Accepted 5. Create a TMS service \u00b6 Request POST /services HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Monthly aggregation on Sentinel 1\" , \"description\" : \"Create a monthly aggregated Sentinel 1 product from a custom Python script.\" , \"process_graph\" : { \"process_id\" : \"get_results\" , \"job_id\" : \"132\" }, \"type\" : \"TMS\" , \"enabled\" : true , \"parameters\" : {}, \"plan\" : \"free\" } Response HTTP / 1.1 201 Created Location : https://openeo.org/api/v0.4/services/tms-75ff8c 6. Requesting the service information \u00b6 Request POST https://openeo.org/api/v0.4/services/tms-75ff8c HTTP / 1.1 Content-Type : application/json; charset=utf-8 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"service_id\" : \"tms-75ff8c\" , \"title\" : \"Monthly aggregation on Sentinel 1\" , \"description\" : \"Create a monthly aggregated Sentinel 1 product from a custom Python script.\" , \"process_graph\" : { \"process_id\" : \"get_results\" , \"job_id\" : \"132\" }, \"url\" : \"https://openeo.org/tms/75ff8c\" , \"type\" : \"TMS\" , \"enabled\" : true , \"parameters\" : {}, \"attributes\" : {}, \"submitted\" : \"2018-01-01T12:32:12Z\" , \"plan\" : \"free\" , \"budget\" : null } 7. Download the data on demand from the WMS \u00b6 Omitted, not part of the openEO API. TMS is located at https://openeo.org/tms/75ff8c . Use Case 3 \u00b6 Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons. 1. Upload a GeoJSON Polygon \u00b6 Request PUT /files/john_doe/polygon1.geojson HTTP / 1.1 <File content> Response HTTP / 1.1 204 No Content 2. Create a job \u00b6 Request POST /jobs HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Zonal Statistics / Sentinel 2\" , \"description\" : \"Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons.\" , \"process_graph\" :{ \"process_id\" : \"zonal_statistics\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"bands\" : \"B8\" }, \"extent\" :{ \"west\" : 16.1 , \"south\" : 47.2 , \"east\" : 16.6 , \"north\" : 48.6 } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"regions\" : \"/files/john_doe/polygon1.geojson\" , \"func\" : \"mean\" }, \"output\" :{ \"format\" : \"GPKG\" }, \"plan\" : \"free\" , \"budget\" : null } Response HTTP / 1.1 201 Created Location : https://openeo.org/jobs/133 OpenEO-Identifier : 133 3. Start batch processing the job \u00b6 Request POST /jobs/133/results HTTP / 1.1 Response HTTP / 1.1 202 Accepted 4. Check job status \u00b6 Request GET /jobs/133 HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"job_id\" : \"133\" , \"title\" : \"Zonal Statistics / Sentinel 2\" , \"description\" : \"Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons.\" , \"process_graph\" :{ \"process_id\" : \"zonal_statistics\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"bands\" : \"B8\" }, \"extent\" :{ \"west\" : 16.1 , \"south\" : 47.2 , \"east\" : 16.6 , \"north\" : 48.6 } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"regions\" : \"/files/john_doe/polygon1.geojson\" , \"func\" : \"mean\" }, \"output\" :{ \"format\" : \"GPKG\" }, \"status\" : \"finished\" , \"submitted\" : \"2017-02-01T09:32:12Z\" , \"updated\" : \"2017-02-01T09:36:18Z\" , \"plan\" : \"free\" , \"costs\" : 0 , \"budget\" : null } 5. Retrieve download links \u00b6 Request GET /jobs/133/results HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"title\" : \"Zonal Statistics / Sentinel 2\" , \"description\" : \"Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons.\" , \"updated\" : \"2017-02-01T09:36:18Z\" , \"links\" : [ { \"href\" : \"https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/result.gpkg\" , \"type\" : \"application/geopackage+sqlite3\" } ] } 6. Download file(s) \u00b6 Request GET https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/result.gpkg HTTP / 1.1 Response A GeoPackage file, content omitted.","title":"Examples (proof of concept)"},{"location":"examples-poc/#examples-proof-of-concept","text":"This page gives a detailed description of the openEO proof of concept use cases. After the proof of concept, this stays in the API to have some basic examples. The proof of concept covered three clearly defined example use cases and how they are translated to sequences of API calls: Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery Create a monthly aggregated Sentinel 1 product from a custom Python script Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons Note CORS and authentication is not included in these examples for simplicity. Repeating calls are also not included as it would not make much sense to list the same discovery requests for each use case individually.","title":"Examples (proof of concept)"},{"location":"examples-poc/#use-case-1","text":"Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery.","title":"Use Case 1"},{"location":"examples-poc/#1-requesting-the-capabilities-of-the-back-end","text":"Request GET / Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"api_version\" : \"0.4.0\" \"endpoints\" : [ { \"path\" : \"/collections\" , \"methods\" : [ \"GET\" ] }, { \"path\" : \"/collections/{name}\" , \"methods\" : [ \"GET\" ] }, { \"path\" : \"/processes\" , \"methods\" : [ \"GET\" ] }, { \"path\" : \"/jobs\" , \"methods\" : [ \"GET\" , \"POST\" ] }, { \"path\" : \"/jobs/{job_id}\" , \"methods\" : [ \"GET\" , \"DELETE\" , \"PATCH\" ] }, { \"path\" : \"/jobs/{job_id}/results\" , \"methods\" : [ \"GET\" , \"POST\" , \"DELETE\" ] }, { \"path\" : \"/services\" , \"methods\" : [ \"GET\" , \"POST\" ] }, { \"path\" : \"/services/{service_id}\" , \"methods\" : [ \"GET\" , \"DELETE\" , \"PATCH\" ] } ], \"billing\" : { \"currency\" : \"EUR\" , \"plans\" : [ { \"name\" : \"free\" , \"description\" : \"Free plan. Calculates one tile per second and a maximum amount of 100 tiles per hour.\" , \"url\" : \"http://openeo.org/plans/free-plan\" } ] } }","title":"1. Requesting the capabilities of the back-end"},{"location":"examples-poc/#2-check-whether-sentinel-2a-level-1c-data-is-available-at-the-back-end","text":"Request GET /collections HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"collections\" : [ { \"name\" : \"Sentinel-2A\" , \"title\" : \"Sentinel-2A MSI L1C\" , \"description\" : \"Sentinel-2A is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.\" , \"license\" : \"proprietary\" , \"extent\" : { \"spatial\" : [ 180 , -56 , -180 , 83 ], \"temporal\" : [ \"2015-06-23T00:00:00Z\" , null ] }, \"links\" : [ { \"rel\" : \"self\" , \"href\" : \"https://openeo.org/api/collections/Sentinel-2A\" }, { \"rel\" : \"license\" , \"href\" : \"https://scihub.copernicus.eu/twiki/pub/SciHubWebPortal/TermsConditions/Sentinel_Data_Terms_and_Conditions.pdf\" } ] } ], \"links\" : [ { \"rel\" : \"self\" , \"href\" : \"https://openeo.org/api/collections\" } ] }","title":"2. Check whether Sentinel 2A Level 1C data is available at the back-end"},{"location":"examples-poc/#3-check-that-needed-processes-are-available","text":"Request GET /processes HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"processes\" : [ { \"name\" : \"get_collection\" , \"summary\" : \"Selects a collection.\" , \"description\" : \"Filters and selects a single collection provided by the back-end. The back-end provider decides which of the potential collections is the most relevant one to be selected.\" , \"min_parameters\" : 1 , \"parameters\" : { \"name\" : { \"description\" : \"Filter by collection name\" , \"schema\" : { \"type\" : \"string\" , \"examples\" : [ \"Sentinel2A-L1C\" ] } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"filter_bands\" , \"summary\" : \"Filters by bands.\" , \"description\" : \"Allows to extract one or multiple bands of multi-band raster image collection.\\nBands can be chosen either by band id, band name or by wavelength.\\n\\nimagery and at one of the other arguments is required to be specified.\" , \"min_parameters\" : 2 , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"bands\" : { \"description\" : \"string or array of strings containing band ids.\" , \"schema\" : { \"type\" : [ \"string\" , \"array\" ], \"items\" : { \"type\" : \"string\" } } }, \"names\" : { \"description\" : \"string or array of strings containing band names.\" , \"schema\" : { \"type\" : [ \"string\" , \"array\" ], \"items\" : { \"type\" : \"string\" } } }, \"wavelengths\" : { \"description\" : \"Either a number specifying a specific wavelength or a two-element array of numbers specifying a minimum and maximum wavelength.\" , \"schema\" : { \"type\" : [ \"number\" , \"array\" ], \"minItems\" : 2 , \"maxItems\" : 2 , \"items\" : { \"type\" : \"number\" } } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"filter_daterange\" , \"summary\" : \"Filters by temporal extent.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"extent\" : { \"description\" : \"Temporal extent specified by a start and an end time, each formatted as a [RFC 3339](https://www.ietf.org/rfc/rfc3339) date-time. Open date ranges are supported and can be specified by setting one of the times to null. Setting both entries to null is not allowed.\" , \"schema\" : { \"type\" : \"array\" , \"format\" : \"temporal_extent\" , \"required\" : true , \"examples\" : [ [ \"2016-01-01T00:00:00Z\" , \"2017-10-01T00:00:00Z\" ] ], \"items\" : { \"type\" : [ \"string\" , \"null\" ], \"format\" : \"date-time\" , \"minItems\" : 2 , \"maxItems\" : 2 } } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"filter_bbox\" , \"summary\" : \"Filters by spatial extent.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"extent\" : { \"description\" : \"Spatial extent, may include a vertical axis (height or depth).\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"spatial_extent\" , \"required\" : [ \"west\" , \"south\" , \"east\" , \"north\" ], \"properties\" : { \"crs\" : { \"description\" : \"Coordinate reference system. EPSG codes must be supported. In addition, proj4 strings should be supported by back-ends. Whenever possible, it is recommended to use EPSG codes instead of proj4 strings.\\nDefaults to `EPSG:4326` unless the client explicitly requests a different coordinate reference system.\" , \"type\" : \"string\" , \"default\" : \"EPSG:4326\" }, \"west\" : { \"description\" : \"West (lower left corner, coordinate axis 1).\" , \"type\" : \"number\" }, \"south\" : { \"description\" : \"South (lower left corner, coordinate axis 2).\" , \"type\" : \"number\" }, \"east\" : { \"description\" : \"East (upper right corner, coordinate axis 1).\" , \"type\" : \"number\" }, \"north\" : { \"description\" : \"North (upper right corner, coordinate axis 2).\" , \"type\" : \"number\" }, \"base\" : { \"description\" : \"Base (optional, lower left corner, coordinate axis 3).\" , \"type\" : \"number\" }, \"height\" : { \"description\" : \"Height (optional, upper right corner, coordinate axis 3).\" , \"type\" : \"number\" } } } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, { \"name\" : \"NDVI\" , \"summary\" : \"Calculates the Normalized Difference Vegetation Index.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"red\" : { \"description\" : \"Band id of the red band.\" , \"required\" : true , \"schema\" : { \"type\" : \"string\" } }, \"nir\" : { \"description\" : \"Band id of the near-infrared band.\" , \"required\" : true , \"schema\" : { \"type\" : \"string\" } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } }, \"exceptions\" : { \"RedBandInvalid\" : { \"description\" : \"The specified red band is not available or contains invalid data.\" }, \"NirBandInvalid\" : { \"description\" : \"The specified nir band is not available or contains invalid data.\" } } }, { \"name\" : \"min_time\" , \"summary\" : \"Calculates minimum values of time series.\" , \"description\" : \"Finds the minimum value of time series for all bands of the input dataset.\" , \"parameters\" : { \"imagery\" : { \"description\" : \"EO data to process.\" , \"required\" : true , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } }, \"returns\" : { \"description\" : \"Processed EO data.\" , \"schema\" : { \"type\" : \"object\" , \"format\" : \"eodata\" } } } ], \"links\" : {} }","title":"3. Check that needed processes are available"},{"location":"examples-poc/#4-request-the-supported-secondary-web-service-types","text":"Request GET /service_types HTTP / 1.1 Content-Type : application/json; charset=utf-8 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"WMS\" : { \"parameters\" : { \"version\" : { \"type\" : \"string\" , \"description\" : \"The WMS version to use.\" , \"default\" : \"1.3.0\" , \"enum\" : [ \"1.1.1\" , \"1.3.0\" ] } }, \"attributes\" : { \"layers\" : { \"type\" : \"array\" , \"description\" : \"Array of layer names.\" , \"example\" : [ \"roads\" , \"countries\" , \"water_bodies\" ] } } } }","title":"4. Request the supported secondary web service types"},{"location":"examples-poc/#5-create-a-wms-service","text":"Request POST /services HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Min. NDVI for Sentinel 2\" , \"description\" : \"Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery.\" , \"process_graph\" : { \"process_id\" : \"min_time\" , \"imagery\" : { \"process_id\" : \"NDVI\" , \"imagery\" : { \"process_id\" : \"filter_daterange\" , \"imagery\" : { \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"extent\" : [ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"red\" : \"B4\" , \"nir\" : \"B8\" } }, \"type\" : \"WMS\" , \"enabled\" : true , \"parameters\" : { \"version\" : \"1.1.1\" }, \"plan\" : \"free\" } Response HTTP / 1.1 201 Created Location : https://openeo.org/api/v0.4/services/wms-a3cca9 OpenEO-Identifier : wms-a3cca9","title":"5. Create a WMS service"},{"location":"examples-poc/#6-requesting-the-service-information","text":"Request POST https://openeo.org/api/v0.4/services/wms-a3cca9 HTTP / 1.1 Content-Type : application/json; charset=utf-8 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"service_id\" : \"wms-a3cca9\" , \"title\" : \"Min. NDVI for Sentinel 2\" , \"description\" : \"Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery.\" , \"process_graph\" : { \"process_id\" : \"min_time\" , \"imagery\" : { \"process_id\" : \"NDVI\" , \"imagery\" : { \"process_id\" : \"filter_daterange\" , \"imagery\" : { \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"extent\" : [ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"red\" : \"B4\" , \"nir\" : \"B8\" } }, \"url\" : \"https://openeo.org/wms/a3cca9\" , \"type\" : \"WMS\" , \"enabled\" : true , \"parameters\" : { \"version\" : \"1.1.1\" }, \"attributes\" : { \"layers\" : [ \"min_time\" ] }, \"submitted\" : \"2017-01-01T09:32:12Z\" , \"plan\" : \"free\" , \"budget\" : null }","title":"6. Requesting the service information"},{"location":"examples-poc/#7-download-the-data-on-demand-from-the-wms","text":"Omitted, not part of the openEO API. WMS is located at https://openeo.org/wms/a3cca9 .","title":"7. Download the data on demand from the WMS"},{"location":"examples-poc/#use-case-2","text":"Create a monthly aggregated Sentinel 1 product from a custom Python script.","title":"Use Case 2"},{"location":"examples-poc/#1-ask-the-back-end-for-available-sentinel-1-data","text":"Request GET /collections/Sentinel-1 HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"name\" : \"Sentinel-1\" , \"description\" : \"Sentinel 1 C-band Synthetic Aperture Radar (SAR) Ground Range Data\" , \"license\" : \"proprietary\" , \"keywords\" : [ \"copernicus\" , \"esa\" , \"sentinel\" , \"sar\" ], \"provider\" : [ { \"name\" : \"European Space Agency (ESA)\" , \"url\" : \"https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar\" } ], \"extent\" : { \"spatial\" : [ -34 , 35 , 39 , 71 ], \"temporal\" : [ \"2016-01-01T00:00:00Z\" , null ] }, \"links\" : [ { \"rel\" : \"self\" , \"href\" : \"https://openeo.org/api/collections/Sentinel-1\" }, { \"rel\" : \"license\" , \"href\" : \"https://scihub.copernicus.eu/twiki/pub/SciHubWebPortal/TermsConditions/Sentinel_Data_Terms_and_Conditions.pdf\" } ], \"eo:constellation\" : \"sentinel-1\" , \"eo:bands\" : { \"VV\" : { \"common_name\" : \"VV\" }, \"VH\" : { \"common_name\" : \"VH\" } } }","title":"1. Ask the back-end for available Sentinel 1 data"},{"location":"examples-poc/#2-upload-python-script","text":"Request PUT /files/john_doe/s1_aggregate.py HTTP / 1.1 <File content> Response HTTP / 1.1 204 No Content","title":"2. Upload python script"},{"location":"examples-poc/#3-create-a-job","text":"Request POST /jobs HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Monthly aggregation on Sentinel 1\" , \"description\" : \"Create a monthly aggregated Sentinel 1 product from a custom Python script.\" , \"process_graph\" :{ \"process_id\" : \"aggregate_time\" , \"script\" : \"/files/john_doe/s1_aggregate.py\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-1\" }, \"extent\" :{ \"west\" : 16.1 , \"south\" : 47.2 , \"east\" : 16.6 , \"north\" : 48.6 } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] } }, \"plan\" : \"free\" } Response HTTP / 1.1 201 Created Location : https://openeo.org/api/v0.4/jobs/132 OpenEO-Identifier : 132","title":"3. Create a job"},{"location":"examples-poc/#4-start-batch-processing-the-job","text":"Request POST /jobs/132/results HTTP / 1.1 Response HTTP / 1.1 202 Accepted","title":"4. Start batch processing the job"},{"location":"examples-poc/#5-create-a-tms-service","text":"Request POST /services HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Monthly aggregation on Sentinel 1\" , \"description\" : \"Create a monthly aggregated Sentinel 1 product from a custom Python script.\" , \"process_graph\" : { \"process_id\" : \"get_results\" , \"job_id\" : \"132\" }, \"type\" : \"TMS\" , \"enabled\" : true , \"parameters\" : {}, \"plan\" : \"free\" } Response HTTP / 1.1 201 Created Location : https://openeo.org/api/v0.4/services/tms-75ff8c","title":"5. Create a TMS service"},{"location":"examples-poc/#6-requesting-the-service-information_1","text":"Request POST https://openeo.org/api/v0.4/services/tms-75ff8c HTTP / 1.1 Content-Type : application/json; charset=utf-8 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"service_id\" : \"tms-75ff8c\" , \"title\" : \"Monthly aggregation on Sentinel 1\" , \"description\" : \"Create a monthly aggregated Sentinel 1 product from a custom Python script.\" , \"process_graph\" : { \"process_id\" : \"get_results\" , \"job_id\" : \"132\" }, \"url\" : \"https://openeo.org/tms/75ff8c\" , \"type\" : \"TMS\" , \"enabled\" : true , \"parameters\" : {}, \"attributes\" : {}, \"submitted\" : \"2018-01-01T12:32:12Z\" , \"plan\" : \"free\" , \"budget\" : null }","title":"6. Requesting the service information"},{"location":"examples-poc/#7-download-the-data-on-demand-from-the-wms_1","text":"Omitted, not part of the openEO API. TMS is located at https://openeo.org/tms/75ff8c .","title":"7. Download the data on demand from the WMS"},{"location":"examples-poc/#use-case-3","text":"Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons.","title":"Use Case 3"},{"location":"examples-poc/#1-upload-a-geojson-polygon","text":"Request PUT /files/john_doe/polygon1.geojson HTTP / 1.1 <File content> Response HTTP / 1.1 204 No Content","title":"1. Upload a GeoJSON Polygon"},{"location":"examples-poc/#2-create-a-job","text":"Request POST /jobs HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"title\" : \"Zonal Statistics / Sentinel 2\" , \"description\" : \"Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons.\" , \"process_graph\" :{ \"process_id\" : \"zonal_statistics\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"bands\" : \"B8\" }, \"extent\" :{ \"west\" : 16.1 , \"south\" : 47.2 , \"east\" : 16.6 , \"north\" : 48.6 } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"regions\" : \"/files/john_doe/polygon1.geojson\" , \"func\" : \"mean\" }, \"output\" :{ \"format\" : \"GPKG\" }, \"plan\" : \"free\" , \"budget\" : null } Response HTTP / 1.1 201 Created Location : https://openeo.org/jobs/133 OpenEO-Identifier : 133","title":"2. Create a job"},{"location":"examples-poc/#3-start-batch-processing-the-job","text":"Request POST /jobs/133/results HTTP / 1.1 Response HTTP / 1.1 202 Accepted","title":"3. Start batch processing the job"},{"location":"examples-poc/#4-check-job-status","text":"Request GET /jobs/133 HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"job_id\" : \"133\" , \"title\" : \"Zonal Statistics / Sentinel 2\" , \"description\" : \"Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons.\" , \"process_graph\" :{ \"process_id\" : \"zonal_statistics\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel-2A\" }, \"bands\" : \"B8\" }, \"extent\" :{ \"west\" : 16.1 , \"south\" : 47.2 , \"east\" : 16.6 , \"north\" : 48.6 } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"regions\" : \"/files/john_doe/polygon1.geojson\" , \"func\" : \"mean\" }, \"output\" :{ \"format\" : \"GPKG\" }, \"status\" : \"finished\" , \"submitted\" : \"2017-02-01T09:32:12Z\" , \"updated\" : \"2017-02-01T09:36:18Z\" , \"plan\" : \"free\" , \"costs\" : 0 , \"budget\" : null }","title":"4. Check job status"},{"location":"examples-poc/#5-retrieve-download-links","text":"Request GET /jobs/133/results HTTP / 1.1 Response HTTP / 1.1 200 OK Content-Type : application/json; charset=utf-8 { \"title\" : \"Zonal Statistics / Sentinel 2\" , \"description\" : \"Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons.\" , \"updated\" : \"2017-02-01T09:36:18Z\" , \"links\" : [ { \"href\" : \"https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/result.gpkg\" , \"type\" : \"application/geopackage+sqlite3\" } ] }","title":"5. Retrieve download links"},{"location":"examples-poc/#6-download-files","text":"Request GET https://cdn.openeo.org/4854b51643548ab8a858e2b8282711d8/result.gpkg HTTP / 1.1 Response A GeoPackage file, content omitted.","title":"6. Download file(s)"},{"location":"gettingstarted-backends/","text":"Getting started for back-end providers \u00b6 As a back-end provider who wants to provide its datasets, processes and infrastructure to a broader audience through a standardized interface you may want to implement a driver for openEO. First of all, you should go through the list of openEO repositories and check whether there is already a back-end driver that suits your needs. In this case you don't need to develop your own driver, but \"only\" need to ingest your data, adopt your required processes and set-up the infrastructure. Please follow the documentation for the individual driver you want to use. If your preferred technology has no back-end driver yet, you may consider writing your own driver. All software written for openEO should follow the software development guidelines . You certainly need to understand the architecture of openEO and concepts behind jobs , processes and process graphs . This helps you read and understand the API specification . Technical API related documents like CORS and error handing should be read, too. If you do not want to start from scratch, you could try to generate a server stub from the OpenAPI 3.0 -based API specification with the Swagger code generator . If you are using Python or NodeJS to implement your driver you may re-use some common modules of existing driver implementations: Python Driver NodeJS Driver You can implement a back-end in iterations. It is recommended to start by implementing the Capabilities microservice. EO Data Discovery , Process Discovery are important for the client libraries to be available, too. Afterwards you should implement Job Management or synchronous data processing . All other microservices can be added later and are not strictly required to run openEO services. Keep in mind that you don't need to implement all endpoints in the first iteration and that you can specify in the Capabilities, which endpoints you are supporting. For example, you could start by implementing the following endpoints in the first iteration: Capabilities: GET / and GET /output_formats Data discovery: GET /collections and GET /collections/{name} Process discovery: GET /processes Data processing: POST /preview Authentication (if required): GET /credentials/basic Afterwards you can already start experimenting with your first process graphs and process EO data with our client libraries on your back-end. More information will follow soon, for example about back-end compliance testing.","title":"Back-end Providers"},{"location":"gettingstarted-backends/#getting-started-for-back-end-providers","text":"As a back-end provider who wants to provide its datasets, processes and infrastructure to a broader audience through a standardized interface you may want to implement a driver for openEO. First of all, you should go through the list of openEO repositories and check whether there is already a back-end driver that suits your needs. In this case you don't need to develop your own driver, but \"only\" need to ingest your data, adopt your required processes and set-up the infrastructure. Please follow the documentation for the individual driver you want to use. If your preferred technology has no back-end driver yet, you may consider writing your own driver. All software written for openEO should follow the software development guidelines . You certainly need to understand the architecture of openEO and concepts behind jobs , processes and process graphs . This helps you read and understand the API specification . Technical API related documents like CORS and error handing should be read, too. If you do not want to start from scratch, you could try to generate a server stub from the OpenAPI 3.0 -based API specification with the Swagger code generator . If you are using Python or NodeJS to implement your driver you may re-use some common modules of existing driver implementations: Python Driver NodeJS Driver You can implement a back-end in iterations. It is recommended to start by implementing the Capabilities microservice. EO Data Discovery , Process Discovery are important for the client libraries to be available, too. Afterwards you should implement Job Management or synchronous data processing . All other microservices can be added later and are not strictly required to run openEO services. Keep in mind that you don't need to implement all endpoints in the first iteration and that you can specify in the Capabilities, which endpoints you are supporting. For example, you could start by implementing the following endpoints in the first iteration: Capabilities: GET / and GET /output_formats Data discovery: GET /collections and GET /collections/{name} Process discovery: GET /processes Data processing: POST /preview Authentication (if required): GET /credentials/basic Afterwards you can already start experimenting with your first process graphs and process EO data with our client libraries on your back-end. More information will follow soon, for example about back-end compliance testing.","title":"Getting started for back-end providers"},{"location":"gettingstarted-clients/","text":"Getting started for client developers \u00b6 For easy access to openEO back-ends it is essential to provide client libraries for users in their well-known programming languages or working environments. This can be either a client library for a specific programming language that hides the technical details of the openEO API or an application with a user interface, e.g. a GIS software plugin or a web-based tool. All software written for openEO should follow the software development guidelines . Client library developers \u00b6 If your preferred programming language is not part of the available client libraries you may consider writing your own client library. Our client libraries are basically translating the openEO API into native concepts of the programming languages. Working with openEO should feel like being a first-class citizen of the programming language. Get started by reading the guidelines to develop client libraries , which have been written to ensure the client libraries provide a consistent feel and behavior across programming languages. You certainly need to understand the concepts behind jobs , processes and process graphs . This helps you understand the API specification and related documents. If you do not want to start from scratch, you could try to generate a client library stub from the OpenAPI 3.0 -based API specification with the Swagger code generator . Make sure the generated code complies to the client library guidelines mentioned above. More information will follow soon, for example about client testing. Applications and Software plugins \u00b6 Standalone applications and software plugins written in a certain programming language could use the existing client libraries to facilitate access to openEO back-ends. Web applications potentially could use the JavaScript client to access openEO back-ends. Back-Ends may also provide standardized web interfaces such as OGC WMS or OGC WCS to access processed EO data. More information will follow soon...","title":"Client Developers"},{"location":"gettingstarted-clients/#getting-started-for-client-developers","text":"For easy access to openEO back-ends it is essential to provide client libraries for users in their well-known programming languages or working environments. This can be either a client library for a specific programming language that hides the technical details of the openEO API or an application with a user interface, e.g. a GIS software plugin or a web-based tool. All software written for openEO should follow the software development guidelines .","title":"Getting started for client developers"},{"location":"gettingstarted-clients/#client-library-developers","text":"If your preferred programming language is not part of the available client libraries you may consider writing your own client library. Our client libraries are basically translating the openEO API into native concepts of the programming languages. Working with openEO should feel like being a first-class citizen of the programming language. Get started by reading the guidelines to develop client libraries , which have been written to ensure the client libraries provide a consistent feel and behavior across programming languages. You certainly need to understand the concepts behind jobs , processes and process graphs . This helps you understand the API specification and related documents. If you do not want to start from scratch, you could try to generate a client library stub from the OpenAPI 3.0 -based API specification with the Swagger code generator . Make sure the generated code complies to the client library guidelines mentioned above. More information will follow soon, for example about client testing.","title":"Client library developers"},{"location":"gettingstarted-clients/#applications-and-software-plugins","text":"Standalone applications and software plugins written in a certain programming language could use the existing client libraries to facilitate access to openEO back-ends. Web applications potentially could use the JavaScript client to access openEO back-ends. Back-Ends may also provide standardized web interfaces such as OGC WMS or OGC WCS to access processed EO data. More information will follow soon...","title":"Applications and Software plugins"},{"location":"gettingstarted-users/","text":"Getting started for users \u00b6 Currently, there are three official client libraries and a web-based interface for openEO. If you are unfamiliar with programming, you could start using the web-based editor for openEO . It supports visual modelling of your algorithms and a simplified JavaScript based access to the openEO workflows and providers. If you are familiar with programming, you could choose a client library for three programming languages: JavaScript (client-side and server-side) Python R Follow the links above to find usage instructions for each of the client libraries. Contribute \u00b6 Didn't find your programming language? You can also access the openEO API implementations directly or start implementing your own client library . If you are missing any functionality in the API feel free to open an issue or actively start proposing API changes as Pull Requests. Make sure to read the API Development Guidelines before. Feel free to contact us for further assistance.","title":"Users"},{"location":"gettingstarted-users/#getting-started-for-users","text":"Currently, there are three official client libraries and a web-based interface for openEO. If you are unfamiliar with programming, you could start using the web-based editor for openEO . It supports visual modelling of your algorithms and a simplified JavaScript based access to the openEO workflows and providers. If you are familiar with programming, you could choose a client library for three programming languages: JavaScript (client-side and server-side) Python R Follow the links above to find usage instructions for each of the client libraries.","title":"Getting started for users"},{"location":"gettingstarted-users/#contribute","text":"Didn't find your programming language? You can also access the openEO API implementations directly or start implementing your own client library . If you are missing any functionality in the API feel free to open an issue or actively start proposing API changes as Pull Requests. Make sure to read the API Development Guidelines before. Feel free to contact us for further assistance.","title":"Contribute"},{"location":"glossary/","text":"Glossary \u00b6 This glossary introduces the major technical terms used in the openEO project. General terms \u00b6 API : application programming interface ( wikipedia ); a communication protocol between client and back-end client : software environment (software) that end-users directly interact with, e.g. R (rstudio), Python (jupyter notebook), and JavaScript (web browser); R and Python are two major data science platforms; JavaScript is a major language for web development (cloud) back-end : server; computer infrastructure (one or more physical computers or virtual machines) used for storing EO data and processing it big Earth observation cloud back-end : server infrastructure where industry and researchers analyse large amounts of EO data User defined functions (UDFs) : concept, that enables the users to upload custom code and have it executed e.g. for every pixel of a scene, allowing custom calculations on server-side data. See the section on UDFs for more information. EO data \u00b6 In our domain, different terms are used to describe EO data(sets). Within openEO, a granule typically refers to a limited area and a single overpass leading to a very short observation period (seconds) or a temporal aggregation of such data (e.g. for 16-day MODIS composites) while a collection is an aggregation of granules sharing the same product specification. It typically corresponds to the series of products derived from data acquired by a sensor on board a satellite and having the same mode of operation. The CEOS OpenSearch Best Practice Document v1.2 lists synonyms used (by organizations) for: granule : dataset (ESA, ISO 19115), granule (NASA), product (ESA, CNES), scene (JAXA) collection : dataset series (ESA, ISO 19115), collection (CNES, NASA), dataset (JAXA), product (JAXA) Processes and process graphs \u00b6 The terms process and process graph have specific meanings in the openEO API specification. A process is an operation provided by the back end that performs a specific task on a set of parameters and returns a result. An example is computing a statistical operation, such as mean or median, on selected EO data. A process is similar to a function or method in programming languages. A process graph chains specific process calls. Similarly to scripts in the context of programming, process graphs organize and automate the execution of one or more processes that could alternatively be executed individually. In a process graph, processes need to be specific, i.e. concrete values for input parameters need to be specified. These arguments can again be process graphs, scalar values, arrays or objects. Aggregation and resampling \u00b6 Aggregation computes new values from sets of values that are uniquely assigned to groups. It involves a grouping predicate (e.g. monthly, 100 m x 100 m grid cells), and an aggregation function (e.g., mean ) that computes one or more new values from the original ones. Examples: a time series aggregation may return a regression slope and intercept for every pixel time series, for a single band (grouping predicate: full time extent) a time series may be aggregated to monthly values by computing the mean for all values in a month (grouping predicate: months) spatial aggregation involves computing e.g. mean pixel values on a 100 x 100 m grid, from 10 m x 10 m pixels, where each original pixel is assigned uniquely to a larger pixel (grouping predicate: 100 m x 100 m grid cells) Note that for the first example, the aggregation function not only requires time series values, but also their time stamps. Resampling (also called scaling ) is a broader term where we have data at one resolution, and need values at another. In case we have values at a 100 m x 100 m grid and need values at a 10 m x 10 m grid, the original values will be reused many times, and may be simply assigned to the nearest high resolution grid cells (nearest neighbor method), or may be interpolated using various methods (e.g. by bilinear interpolation). Resampling from finer to coarser grid may again be a special case of aggregation. When the target grid or time series has a lower resolution (larger grid cells) or lower frequency (longer time intervals) than the source grid, aggregation might be used for resampling. For example, if the resolutions are similar, (e.g. the source collection provides 10 day intervals and the target needs values for 16 day intervals), then some form of interpolation may be more appropriate than aggregation as defined here. User-defined functions \u00b6 The abbreviation UDF stands for user-defined function . With this concept, users are able to upload custom code and have it executed e.g. for every pixel of a scene, allowing custom calculations on server-side data.","title":"Glossary"},{"location":"glossary/#glossary","text":"This glossary introduces the major technical terms used in the openEO project.","title":"Glossary"},{"location":"glossary/#general-terms","text":"API : application programming interface ( wikipedia ); a communication protocol between client and back-end client : software environment (software) that end-users directly interact with, e.g. R (rstudio), Python (jupyter notebook), and JavaScript (web browser); R and Python are two major data science platforms; JavaScript is a major language for web development (cloud) back-end : server; computer infrastructure (one or more physical computers or virtual machines) used for storing EO data and processing it big Earth observation cloud back-end : server infrastructure where industry and researchers analyse large amounts of EO data User defined functions (UDFs) : concept, that enables the users to upload custom code and have it executed e.g. for every pixel of a scene, allowing custom calculations on server-side data. See the section on UDFs for more information.","title":"General terms"},{"location":"glossary/#eo-data","text":"In our domain, different terms are used to describe EO data(sets). Within openEO, a granule typically refers to a limited area and a single overpass leading to a very short observation period (seconds) or a temporal aggregation of such data (e.g. for 16-day MODIS composites) while a collection is an aggregation of granules sharing the same product specification. It typically corresponds to the series of products derived from data acquired by a sensor on board a satellite and having the same mode of operation. The CEOS OpenSearch Best Practice Document v1.2 lists synonyms used (by organizations) for: granule : dataset (ESA, ISO 19115), granule (NASA), product (ESA, CNES), scene (JAXA) collection : dataset series (ESA, ISO 19115), collection (CNES, NASA), dataset (JAXA), product (JAXA)","title":"EO data"},{"location":"glossary/#processes-and-process-graphs","text":"The terms process and process graph have specific meanings in the openEO API specification. A process is an operation provided by the back end that performs a specific task on a set of parameters and returns a result. An example is computing a statistical operation, such as mean or median, on selected EO data. A process is similar to a function or method in programming languages. A process graph chains specific process calls. Similarly to scripts in the context of programming, process graphs organize and automate the execution of one or more processes that could alternatively be executed individually. In a process graph, processes need to be specific, i.e. concrete values for input parameters need to be specified. These arguments can again be process graphs, scalar values, arrays or objects.","title":"Processes and process graphs"},{"location":"glossary/#aggregation-and-resampling","text":"Aggregation computes new values from sets of values that are uniquely assigned to groups. It involves a grouping predicate (e.g. monthly, 100 m x 100 m grid cells), and an aggregation function (e.g., mean ) that computes one or more new values from the original ones. Examples: a time series aggregation may return a regression slope and intercept for every pixel time series, for a single band (grouping predicate: full time extent) a time series may be aggregated to monthly values by computing the mean for all values in a month (grouping predicate: months) spatial aggregation involves computing e.g. mean pixel values on a 100 x 100 m grid, from 10 m x 10 m pixels, where each original pixel is assigned uniquely to a larger pixel (grouping predicate: 100 m x 100 m grid cells) Note that for the first example, the aggregation function not only requires time series values, but also their time stamps. Resampling (also called scaling ) is a broader term where we have data at one resolution, and need values at another. In case we have values at a 100 m x 100 m grid and need values at a 10 m x 10 m grid, the original values will be reused many times, and may be simply assigned to the nearest high resolution grid cells (nearest neighbor method), or may be interpolated using various methods (e.g. by bilinear interpolation). Resampling from finer to coarser grid may again be a special case of aggregation. When the target grid or time series has a lower resolution (larger grid cells) or lower frequency (longer time intervals) than the source grid, aggregation might be used for resampling. For example, if the resolutions are similar, (e.g. the source collection provides 10 day intervals and the target needs values for 16 day intervals), then some form of interpolation may be more appropriate than aggregation as defined here.","title":"Aggregation and resampling"},{"location":"glossary/#user-defined-functions","text":"The abbreviation UDF stands for user-defined function . With this concept, users are able to upload custom code and have it executed e.g. for every pixel of a scene, allowing custom calculations on server-side data.","title":"User-defined functions"},{"location":"guidelines-api/","text":"API Development Guidelines \u00b6 To provide the smoothest possible experience, it's important to have these APIs follow consistent design guidelines, thus making using them easy and intuitive. Language \u00b6 Language \u00b6 Generally, English language MUST be used for all names, documentation etc. In the specification the key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 . Casing \u00b6 Unless otherwise stated the API works case sensitive. All names SHOULD be written in snake case, i.e. words are separated with one underscore character (_) and no spaces, with all letters lowercased. Example: hello_world . This applies particularly to endpoints and JSON property names. HTTP header fields follow their respective casing conventions, e.g. Content-Type or OpenEO-Costs , despite being case-insensitive according to RFC 7230 . Technical requirements \u00b6 HTTP \u00b6 The API developed by the openEO project uses HTTP REST Level 2 for communication between client and back-end server. Public APIs MUST be available via HTTPS only and all inbound calls MUST be HTTPS. Verbs Endpoints SHOULD use meaningful HTTP verbs (e.g. GET, POST, PUT, PATCH, DELETE). If there is a need to transfer big chunks of data via GET requests, POST requests MAY be used as a replacement as they support to send data via request body. Unless otherwise stated, PATCH requests are only defined to work on the direct (first-level) children of the full JSON object. Therefore, changing a property on a deeper level of the full JSON object always requires to send the whole JSON object defined by the first-level property. Resource naming Naming of endpoints SHOULD follow the REST principles. Therefore, endpoints SHOULD be centered around resources. Resource identifiers MUST be named with a noun in plural form except for single actions that can not be modelled with the regular HTTP verbs. Single actions MUST be single endpoint with a single HTTP verb (POST is RECOMMENDED) and no other endpoints beneath it. Cross-Origin Resource Sharing (CORS) All back-end providers SHOULD support CORS. More information can be found in the corresponding section . Status codes and error handling The success of requests MUST be indicated using HTTP status codes according to RFC 7231 . More information can be found in the section about status und error handling . Requests and response formats \u00b6 JSON Web-based communication, especially when a mobile or other low-bandwidth client is involved, has moved quickly in the direction of JSON for a variety of reasons, including its tendency to be lighter weight and its ease of consumption with JavaScript-based clients. Therefore, services SHOULD use JSON as the default encoding. Other response formats can be requested using Content Negotiation . Clients and servers MUST NOT rely on the order in which properties appears in JSON responses. When supported by the service, clients MAY request that array elements be returned in a specific order. Collections SHOULD NOT include nested JSON objects if those information can be requested from the individual resources. Temporal data Date, time, intervals and durations MUST be formatted based on ISO 8601 or any profile ( RFC 3339 is strongly recommended) if there is an appropriate encoding available in the standard. All temporal data MUST by specified based on the Gregorian calendar.","title":"API Specification"},{"location":"guidelines-api/#api-development-guidelines","text":"To provide the smoothest possible experience, it's important to have these APIs follow consistent design guidelines, thus making using them easy and intuitive.","title":"API Development Guidelines"},{"location":"guidelines-api/#language","text":"","title":"Language"},{"location":"guidelines-api/#language_1","text":"Generally, English language MUST be used for all names, documentation etc. In the specification the key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 .","title":"Language"},{"location":"guidelines-api/#casing","text":"Unless otherwise stated the API works case sensitive. All names SHOULD be written in snake case, i.e. words are separated with one underscore character (_) and no spaces, with all letters lowercased. Example: hello_world . This applies particularly to endpoints and JSON property names. HTTP header fields follow their respective casing conventions, e.g. Content-Type or OpenEO-Costs , despite being case-insensitive according to RFC 7230 .","title":"Casing"},{"location":"guidelines-api/#technical-requirements","text":"","title":"Technical requirements"},{"location":"guidelines-api/#http","text":"The API developed by the openEO project uses HTTP REST Level 2 for communication between client and back-end server. Public APIs MUST be available via HTTPS only and all inbound calls MUST be HTTPS.","title":"HTTP"},{"location":"guidelines-api/#requests-and-response-formats","text":"","title":"Requests and response formats"},{"location":"guidelines-clients/","text":"Client library development guidelines \u00b6 This is a proposal for workflows that client libraries should support to make the experience with each library similar and users can easily adopt examples and workflows. For best experience libraries should still embrace best practices common in their environments. This means clients can... choose which kind of casing they use (see below). feel free to implement aliases for methods. Conventions \u00b6 Casing \u00b6 Clients can use snake_case , camelCase or any method used commonly in their environment. For example, the API request to get a list of collections can either be names get_collections or getCollections . This applies for all names, including scopes, method names and parameters. Scopes \u00b6 Each method belongs to a scope. To achieve this in object-oriented (OO) programming languages, methods would be part of a class. If programming languages don't support scopes, you may need to simulate it somehow to prevent name collisions, e.g. by adding a prefix to the method names (like in the \"procedural style\" example below). Best practices for this will likely evolve over time. Example for the clientVersion method in openEO : Procedural style: openeo_client_version() Object-oriented style: OpenEO obj = new OpenEO (); obj . clientVersion (); If you can't store scope data in an object, you may need to pass these information as argument(s) to the method. Example: Procedural style: $connection = openeo_connect(\"https://openeo.org\"); openeo_get_capabilities($connection); Object-oriented style: OpenEO obj = new OpenEO (); Connection con = obj . connect ( \"https://openeo.org\" ); con . getCapabilities (); Scope categories \u00b6 Each scope is assigned to a scope category, of which there are three: Root category: Contains only the scope openEO . API category: Mostly methods hiding API calls to the back-ends. Methods may be implemented asynchronously. Contains the scopes Connection , File , Job , ProcessGraph , Service . Content : Mostly methods hiding the complexity of response content. Methods are usually implemented synchronously. Currently contains only the scope Capabilities . Method names should be prefixed if name collisions are likely. Method names across ALL the scopes that belong to the root or API categories MUST be unique. This is the case because the parameter in hasFeature(method_name) must be unambiguous. Method names of scopes in the Content category may collide with method names of scopes in the root / API categories and names should be prefixed if collisions of names between different scope categories are to be expected. Parameters \u00b6 The parameters usually follow the request schemas in the openAPI specification. The parameters should follow their characteristics, for example regarding the default values. Some methods have a long list of (optional) parameters. This is easy to implement in languages that support named parameters such as R. For example, creating a job in R with a budget would lead to this method call: createJob ( process_graph = { ... }, budget = 123 ) Other languages that only support non-named parameters (i.e. the order of parameters is fixed) need to fill many parameters with default values, which is not convenient for a user. The example above in PHP would be: createJob({...}, null, null, null, null, null, 123) To avoid such method calls client developers should consider to pass either an instance of a class, which contains all parameters as member variables or the required parameters directly and the optional parameters as a dictionary (see example below). This basically emulates named parameters. The member variables / dictionary keys should use the same names as the parameters. The exemplary method call in PHP could be improved as follows: createJob({...}, [budget => 123]) Method mappings \u00b6 Note: Subscriptions and some scopes for response JSON objects are still missing. We are open for proposals. Parameters with a leading ? are optional. Scope: openEO (root category) \u00b6 Description Client method Connect to a back-end, including authentication. Returns Connection . connect(url, ?authType, ?authOptions) Get client library version. clientVersion() Parameters authType in connect : null , basic or oidc (non-exclusive). Defaults to null (no authentication). authOptions in connect : May hold additional data for authentication, for example a username and password for basic authentication. Scope: Connection (API category) \u00b6 Description API Request Client method Get the capabilities of the back-end. Returns Capabilities . GET / capabilities() List the supported output file formats. GET /output_formats listFileTypes() List the supported secondary service types. GET /service_types listServiceTypes() List all collections available on the back-end. GET /collections listCollections() Get information about a single collection. GET /collections/{name} describeCollection(name) List all processes available on the back-end. GET /processes listProcesses() Authenticate with OpenID Connect (if not specified in connect ). GET /credentials/oidc authenticateOIDC(?options) Authenticate with HTTP Basic (if not specified in connect ). GET /credentials/basic authenticateBasic(username, password) Get information about the authenticated user. GET /me describeAccount() Lists all files from a user. Returns a list of File . GET /files/{user_id} listFiles(?userId) Creates a (virtual) file. Returns a File . None createFile(path, ?userId) Validates a process graph. POST /validate validateProcessGraph(processGraph) Lists all process graphs of the authenticated user. Returns a list of ProcessGraph . GET /process_graphs listProcessGraphs() Creates a new stored process graph. Returns a ProcessGraph . POST /process_graphs createProcessGraph(processGraph, ?title, ?description) Executes a process graph synchronously. POST /preview execute(processGraph, ?outputFormat, ?outputParameters, ?budget) Lists all jobs of the authenticated user. Returns a list of Job . GET /jobs listJobs() Creates a new job. Returns a Job . POST /jobs createJob(processGraph, ?outputFormat, ?outputParameters, ?title, ?description, ?plan, ?budget, ?additional) Lists all secondary services of the authenticated user. Returns a list of Service . GET /services listServices() Creates a new secondary service. Returns a Service . POST /services createService(processGraph, type, ?title, ?description, ?enabled, ?parameters, ?plan, ?budget) Parameters userId in listFiles and createFile : Defaults to the user id of the authenticated user. options in authenticateOIDC : May hold additional data required for OpenID connect authentication. Scope Capabilities (Content category) \u00b6 Should be prefixed with Capabilities if collisions of names between different scope categories are to be expected. Description Field Client method Get the implemented openEO version. api_version apiVersion() Get the back-end version. backend_version backendVersion() List all supported features / endpoints. endpoints listFeatures() Check whether a feature / endpoint is supported. endpoints > ... hasFeature(methodName) Get default billing currency. billing > currency currency() List all billing plans. billing > plans listPlans() Parameters methodName in hasFeature : The name of a client method in any of the scopes that are part of the API category. E.g. hasFeature(\"describeAccount\") checks whether the GET /me endpoint is contained in the capabilities response's endpoints object. Scope: File (API category) \u00b6 The File scope internally knows the user_id and the path . Description API Request Client method Download a user file. GET /files/{user_id}/{path} downloadFile(target) Upload a user file. PUT /files/{user_id}/{path} uploadFile(source) Delete a user file. DELETE /files/{user_id}/{path} deleteFile() Parameters target in downloadFile : Path to a local file or folder. Scope: Job (API category) \u00b6 The Job scope internally knows the job_id . Description API Request Client method Get all job information. GET /jobs/{job_id} describeJob() Update a job. PATCH /jobs/{job_id} updateJob(?processGraph, ?outputFormat, ?outputParameters, ?title, ?description, ?plan, ?budget, ?additional) Delete a job DELETE /jobs/{job_id} deleteJob() Calculate an time/cost estimate for a job. GET /jobs/{job_id}/estimate estimateJob() Start / queue a job for processing. POST /jobs/{job_id}/results startJob() Stop / cancel job processing. DELETE /jobs/{job_id}/results stopJob() Get document with download links. GET /jobs/{job_id}/results listResults(?type) Download job results. GET /jobs/{job_id}/results > ... downloadResults(target) Parameters type in listResult : Either json or metalink (non-exclusive). Defaults to json . target in downloadResults : Path to a local folder. Scope: ProcessGraph (API category) \u00b6 The ProcessGraph scope internally knows the pg_id ( process_graph_id ). Description API Request Client method Get all information about a stored process graph. GET /process_graphs/{pg_id} describeProcessGraph() Update a stored process graph. PATCH /process_graphs/{pg_id} updateProcessGraph(?processGraph, ?title, ?description) Delete a stored process graph. DELETE /process_graphs/{pg_id} deleteProcessGraph() Scope: Service (API category) \u00b6 The Service scope internally knows the service_id . Description API Request Client method Get all information about a secondary web service. GET /services/{service_id} describeService() Update a secondary web service. PATCH /services/{service_id} updateService(?processGraph, ?title, ?description, ?enabled, ?parameters, ?plan, ?budget) Delete a secondary web service. DELETE /services/{service_id} deleteService() Processes \u00b6 The processes a back-end supports may be offered by the clients as methods in its own scope. The method names should follow the process names, but the conventions listed above can be applied here as well, e.g. converting filter_bands to filterBands . As parameters have no natural or technical ordering in the JSON objects, clients must come up with a reasonable ordering of parameters if required. This could be inspired by existing clients. The way of building a process graph from processes heavily depends on the technical capabilities of the programming language. Therefore it may differ between the client libraries. Follow the best practices of the programming language, e.g. support method chaining if possible. Workflow example \u00b6 Some simplified example workflows using different programming styles are listed below. The following steps are executed: Loading the client library. Connecting to a back-end and authenticating with username and password via OpenID Connect. Requesting the capabilities and showing the implemented openEO version of the back-end. Showing information about the \"Sentinel-2A\" collection. Showing information about all processes supported by the back-end. Building a simple process graph. Creating a job. Pushing the job to the processing queue. After a while, showing the job details, e.g. checking the job status. Once processing is finished, downloading the job results to the local directory /tmp/job_results/ . R (functional style) \u00b6 library ( openeo ) con = connect ( \"https://openeo.org\" , \"username\" , \"password\" ) cap = capabilities () cap %>% apiVersion () con %>% describeCollection ( \"Sentinel-2A\" ) con %>% listProcesses () processgraph = process ( \"get_collection\" , name = \"Sentinel-2A\" ) %>% process ( \"filterBbox\" , west = 672000 , south = 5181000 , east = 652000 , north = 5161000 , crs = \"EPSG:32632\" ) %>% process ( \"filterDaterange\" , extent = c ( \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" )) %>% process ( \"NDVI\" , nir = \"B4\" , red = \"B8A\" ) %>% process ( \"minTime\" ) job = con %>% createJob ( processgraph ) job %>% startJob () job %>% describeJob () job %>% downloadResults ( \"/tmp/job_results/\" ) Python (mixed style) \u00b6 import openeo con = openeo . connect ( \"https://openeo.org\" , \"username\" , \"password\" ) cap = con . capabilities () print ( cap . api_version ()) print ( con . describe_collection ( \"Sentinel-2A\" )) print ( con . list_processes ()) processes = con . get_processes () pg = processes . get_collection ( name = \"Sentinel-2A\" ) pg = processes . filter_bbox ( pg , west = 672000 , south = 5181000 , east = 652000 , north = 5161000 , crs = \"EPSG:32632\" ) pg = processes . filter_daterange ( pg , extent = [ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ]) pg = processes . NDVI ( pg , nir = \"B4\" , red = \"B8A\" ) pg = processes . min_time ( pg ) job = con . create_job ( pg . graph ) job . start_job () print job . describe_job () job . download_results ( \"/tmp/job_results/\" ) Java (object oriented style) \u00b6 import org.openeo.* ; OpenEO obj = new OpenEO (); Connection con = obj . connect ( \"https://openeo.org\" , \"username\" , \"password\" ); Capabilities cap = con . capabilities (); System . out . println ( cap . apiVersion ()); System . out . println ( con . describeCollection ( \"Sentinel-2A\" )); System . out . println ( con . listProcesses ()); ProcessGraphBuilder pgb = con . getProcessGraphBuilder () // Chain processes... ProcessGraph processGraph = pgb . buildProcessGraph (); Job job = con . createJob ( processGraph ); job . startJob (); System . out . println ( job . describeJob ()); job . downloadResults ( \"/tmp/job_results/\" ); PHP (procedural style) \u00b6 require_once(\"/path/to/openeo.php\"); $connection = openeo_connect(\"http://openeo.org\", \"username\", \"password\"); $capabilities = openeo_capabilities($connection); echo openeo_api_version($capabilites); echo openeo_describe_collection($connection, \"Sentinel-2A\"); echo openeo_list_processes($connection); $pg = openeo_process($pg, \"get_collection\", [\"name\" => \"Sentinel-2A\"]); $pg = openeo_process($pg, \"filter_bbox\", [\"west\" => 672000, \"south\" => 5181000, \"east\" => 652000, \"north\" => 5161000, \"crs\" => \"EPSG:32632\"]); $pg = openeo_process($pg, \"filter_daterange\", [\"extent\" => [\"2017-01-01T00:00:00Z\", \"2017-01-31T23:59:59Z\"]]); $pg = openeo_process($pg, \"NDVI\", [\"red\" => \"B4\", \"nir\" => \"B8A\"]); $pg = openeo_process($pg, \"min_time\"); $job = openeo_create_job($connection, $pg); openeo_start_job($job); echo openeo_describe_job($job); openeo_download_results($job, \"/tmp/job_results/\");","title":"Client Library Development"},{"location":"guidelines-clients/#client-library-development-guidelines","text":"This is a proposal for workflows that client libraries should support to make the experience with each library similar and users can easily adopt examples and workflows. For best experience libraries should still embrace best practices common in their environments. This means clients can... choose which kind of casing they use (see below). feel free to implement aliases for methods.","title":"Client library development guidelines"},{"location":"guidelines-clients/#conventions","text":"","title":"Conventions"},{"location":"guidelines-clients/#casing","text":"Clients can use snake_case , camelCase or any method used commonly in their environment. For example, the API request to get a list of collections can either be names get_collections or getCollections . This applies for all names, including scopes, method names and parameters.","title":"Casing"},{"location":"guidelines-clients/#scopes","text":"Each method belongs to a scope. To achieve this in object-oriented (OO) programming languages, methods would be part of a class. If programming languages don't support scopes, you may need to simulate it somehow to prevent name collisions, e.g. by adding a prefix to the method names (like in the \"procedural style\" example below). Best practices for this will likely evolve over time. Example for the clientVersion method in openEO : Procedural style: openeo_client_version() Object-oriented style: OpenEO obj = new OpenEO (); obj . clientVersion (); If you can't store scope data in an object, you may need to pass these information as argument(s) to the method. Example: Procedural style: $connection = openeo_connect(\"https://openeo.org\"); openeo_get_capabilities($connection); Object-oriented style: OpenEO obj = new OpenEO (); Connection con = obj . connect ( \"https://openeo.org\" ); con . getCapabilities ();","title":"Scopes"},{"location":"guidelines-clients/#scope-categories","text":"Each scope is assigned to a scope category, of which there are three: Root category: Contains only the scope openEO . API category: Mostly methods hiding API calls to the back-ends. Methods may be implemented asynchronously. Contains the scopes Connection , File , Job , ProcessGraph , Service . Content : Mostly methods hiding the complexity of response content. Methods are usually implemented synchronously. Currently contains only the scope Capabilities . Method names should be prefixed if name collisions are likely. Method names across ALL the scopes that belong to the root or API categories MUST be unique. This is the case because the parameter in hasFeature(method_name) must be unambiguous. Method names of scopes in the Content category may collide with method names of scopes in the root / API categories and names should be prefixed if collisions of names between different scope categories are to be expected.","title":"Scope categories"},{"location":"guidelines-clients/#parameters","text":"The parameters usually follow the request schemas in the openAPI specification. The parameters should follow their characteristics, for example regarding the default values. Some methods have a long list of (optional) parameters. This is easy to implement in languages that support named parameters such as R. For example, creating a job in R with a budget would lead to this method call: createJob ( process_graph = { ... }, budget = 123 ) Other languages that only support non-named parameters (i.e. the order of parameters is fixed) need to fill many parameters with default values, which is not convenient for a user. The example above in PHP would be: createJob({...}, null, null, null, null, null, 123) To avoid such method calls client developers should consider to pass either an instance of a class, which contains all parameters as member variables or the required parameters directly and the optional parameters as a dictionary (see example below). This basically emulates named parameters. The member variables / dictionary keys should use the same names as the parameters. The exemplary method call in PHP could be improved as follows: createJob({...}, [budget => 123])","title":"Parameters"},{"location":"guidelines-clients/#method-mappings","text":"Note: Subscriptions and some scopes for response JSON objects are still missing. We are open for proposals. Parameters with a leading ? are optional.","title":"Method mappings"},{"location":"guidelines-clients/#scope-openeo-root-category","text":"Description Client method Connect to a back-end, including authentication. Returns Connection . connect(url, ?authType, ?authOptions) Get client library version. clientVersion()","title":"Scope: openEO (root category)"},{"location":"guidelines-clients/#scope-connection-api-category","text":"Description API Request Client method Get the capabilities of the back-end. Returns Capabilities . GET / capabilities() List the supported output file formats. GET /output_formats listFileTypes() List the supported secondary service types. GET /service_types listServiceTypes() List all collections available on the back-end. GET /collections listCollections() Get information about a single collection. GET /collections/{name} describeCollection(name) List all processes available on the back-end. GET /processes listProcesses() Authenticate with OpenID Connect (if not specified in connect ). GET /credentials/oidc authenticateOIDC(?options) Authenticate with HTTP Basic (if not specified in connect ). GET /credentials/basic authenticateBasic(username, password) Get information about the authenticated user. GET /me describeAccount() Lists all files from a user. Returns a list of File . GET /files/{user_id} listFiles(?userId) Creates a (virtual) file. Returns a File . None createFile(path, ?userId) Validates a process graph. POST /validate validateProcessGraph(processGraph) Lists all process graphs of the authenticated user. Returns a list of ProcessGraph . GET /process_graphs listProcessGraphs() Creates a new stored process graph. Returns a ProcessGraph . POST /process_graphs createProcessGraph(processGraph, ?title, ?description) Executes a process graph synchronously. POST /preview execute(processGraph, ?outputFormat, ?outputParameters, ?budget) Lists all jobs of the authenticated user. Returns a list of Job . GET /jobs listJobs() Creates a new job. Returns a Job . POST /jobs createJob(processGraph, ?outputFormat, ?outputParameters, ?title, ?description, ?plan, ?budget, ?additional) Lists all secondary services of the authenticated user. Returns a list of Service . GET /services listServices() Creates a new secondary service. Returns a Service . POST /services createService(processGraph, type, ?title, ?description, ?enabled, ?parameters, ?plan, ?budget)","title":"Scope: Connection (API category)"},{"location":"guidelines-clients/#scope-capabilities-content-category","text":"Should be prefixed with Capabilities if collisions of names between different scope categories are to be expected. Description Field Client method Get the implemented openEO version. api_version apiVersion() Get the back-end version. backend_version backendVersion() List all supported features / endpoints. endpoints listFeatures() Check whether a feature / endpoint is supported. endpoints > ... hasFeature(methodName) Get default billing currency. billing > currency currency() List all billing plans. billing > plans listPlans()","title":"Scope Capabilities (Content category)"},{"location":"guidelines-clients/#scope-file-api-category","text":"The File scope internally knows the user_id and the path . Description API Request Client method Download a user file. GET /files/{user_id}/{path} downloadFile(target) Upload a user file. PUT /files/{user_id}/{path} uploadFile(source) Delete a user file. DELETE /files/{user_id}/{path} deleteFile()","title":"Scope: File (API category)"},{"location":"guidelines-clients/#scope-job-api-category","text":"The Job scope internally knows the job_id . Description API Request Client method Get all job information. GET /jobs/{job_id} describeJob() Update a job. PATCH /jobs/{job_id} updateJob(?processGraph, ?outputFormat, ?outputParameters, ?title, ?description, ?plan, ?budget, ?additional) Delete a job DELETE /jobs/{job_id} deleteJob() Calculate an time/cost estimate for a job. GET /jobs/{job_id}/estimate estimateJob() Start / queue a job for processing. POST /jobs/{job_id}/results startJob() Stop / cancel job processing. DELETE /jobs/{job_id}/results stopJob() Get document with download links. GET /jobs/{job_id}/results listResults(?type) Download job results. GET /jobs/{job_id}/results > ... downloadResults(target)","title":"Scope: Job (API category)"},{"location":"guidelines-clients/#scope-processgraph-api-category","text":"The ProcessGraph scope internally knows the pg_id ( process_graph_id ). Description API Request Client method Get all information about a stored process graph. GET /process_graphs/{pg_id} describeProcessGraph() Update a stored process graph. PATCH /process_graphs/{pg_id} updateProcessGraph(?processGraph, ?title, ?description) Delete a stored process graph. DELETE /process_graphs/{pg_id} deleteProcessGraph()","title":"Scope: ProcessGraph (API category)"},{"location":"guidelines-clients/#scope-service-api-category","text":"The Service scope internally knows the service_id . Description API Request Client method Get all information about a secondary web service. GET /services/{service_id} describeService() Update a secondary web service. PATCH /services/{service_id} updateService(?processGraph, ?title, ?description, ?enabled, ?parameters, ?plan, ?budget) Delete a secondary web service. DELETE /services/{service_id} deleteService()","title":"Scope: Service (API category)"},{"location":"guidelines-clients/#processes","text":"The processes a back-end supports may be offered by the clients as methods in its own scope. The method names should follow the process names, but the conventions listed above can be applied here as well, e.g. converting filter_bands to filterBands . As parameters have no natural or technical ordering in the JSON objects, clients must come up with a reasonable ordering of parameters if required. This could be inspired by existing clients. The way of building a process graph from processes heavily depends on the technical capabilities of the programming language. Therefore it may differ between the client libraries. Follow the best practices of the programming language, e.g. support method chaining if possible.","title":"Processes"},{"location":"guidelines-clients/#workflow-example","text":"Some simplified example workflows using different programming styles are listed below. The following steps are executed: Loading the client library. Connecting to a back-end and authenticating with username and password via OpenID Connect. Requesting the capabilities and showing the implemented openEO version of the back-end. Showing information about the \"Sentinel-2A\" collection. Showing information about all processes supported by the back-end. Building a simple process graph. Creating a job. Pushing the job to the processing queue. After a while, showing the job details, e.g. checking the job status. Once processing is finished, downloading the job results to the local directory /tmp/job_results/ .","title":"Workflow example"},{"location":"guidelines-clients/#r-functional-style","text":"library ( openeo ) con = connect ( \"https://openeo.org\" , \"username\" , \"password\" ) cap = capabilities () cap %>% apiVersion () con %>% describeCollection ( \"Sentinel-2A\" ) con %>% listProcesses () processgraph = process ( \"get_collection\" , name = \"Sentinel-2A\" ) %>% process ( \"filterBbox\" , west = 672000 , south = 5181000 , east = 652000 , north = 5161000 , crs = \"EPSG:32632\" ) %>% process ( \"filterDaterange\" , extent = c ( \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" )) %>% process ( \"NDVI\" , nir = \"B4\" , red = \"B8A\" ) %>% process ( \"minTime\" ) job = con %>% createJob ( processgraph ) job %>% startJob () job %>% describeJob () job %>% downloadResults ( \"/tmp/job_results/\" )","title":"R (functional style)"},{"location":"guidelines-clients/#python-mixed-style","text":"import openeo con = openeo . connect ( \"https://openeo.org\" , \"username\" , \"password\" ) cap = con . capabilities () print ( cap . api_version ()) print ( con . describe_collection ( \"Sentinel-2A\" )) print ( con . list_processes ()) processes = con . get_processes () pg = processes . get_collection ( name = \"Sentinel-2A\" ) pg = processes . filter_bbox ( pg , west = 672000 , south = 5181000 , east = 652000 , north = 5161000 , crs = \"EPSG:32632\" ) pg = processes . filter_daterange ( pg , extent = [ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ]) pg = processes . NDVI ( pg , nir = \"B4\" , red = \"B8A\" ) pg = processes . min_time ( pg ) job = con . create_job ( pg . graph ) job . start_job () print job . describe_job () job . download_results ( \"/tmp/job_results/\" )","title":"Python (mixed style)"},{"location":"guidelines-clients/#java-object-oriented-style","text":"import org.openeo.* ; OpenEO obj = new OpenEO (); Connection con = obj . connect ( \"https://openeo.org\" , \"username\" , \"password\" ); Capabilities cap = con . capabilities (); System . out . println ( cap . apiVersion ()); System . out . println ( con . describeCollection ( \"Sentinel-2A\" )); System . out . println ( con . listProcesses ()); ProcessGraphBuilder pgb = con . getProcessGraphBuilder () // Chain processes... ProcessGraph processGraph = pgb . buildProcessGraph (); Job job = con . createJob ( processGraph ); job . startJob (); System . out . println ( job . describeJob ()); job . downloadResults ( \"/tmp/job_results/\" );","title":"Java (object oriented style)"},{"location":"guidelines-clients/#php-procedural-style","text":"require_once(\"/path/to/openeo.php\"); $connection = openeo_connect(\"http://openeo.org\", \"username\", \"password\"); $capabilities = openeo_capabilities($connection); echo openeo_api_version($capabilites); echo openeo_describe_collection($connection, \"Sentinel-2A\"); echo openeo_list_processes($connection); $pg = openeo_process($pg, \"get_collection\", [\"name\" => \"Sentinel-2A\"]); $pg = openeo_process($pg, \"filter_bbox\", [\"west\" => 672000, \"south\" => 5181000, \"east\" => 652000, \"north\" => 5161000, \"crs\" => \"EPSG:32632\"]); $pg = openeo_process($pg, \"filter_daterange\", [\"extent\" => [\"2017-01-01T00:00:00Z\", \"2017-01-31T23:59:59Z\"]]); $pg = openeo_process($pg, \"NDVI\", [\"red\" => \"B4\", \"nir\" => \"B8A\"]); $pg = openeo_process($pg, \"min_time\"); $job = openeo_create_job($connection, $pg); openeo_start_job($job); echo openeo_describe_job($job); openeo_download_results($job, \"/tmp/job_results/\");","title":"PHP (procedural style)"},{"location":"guidelines-software/","text":"Software Development Guidelines \u00b6 This document describes guidelines for software developers, written for the openEO project. Since the openEO infrastructure will encompasses several programming languages and software environments, this document does not prescribe particular tools or platforms but rather focuses on general principles and methods behind them. License: all software developed in the openEO project and published on the openEO GitHub organisation shall be licensed under the Apache 2.0 license . If software repositories deviate from this, or contain code or other artifacts that deviates from this, this shall be described in the README.md file. Location: Official openEO software is developed under the openEO GitHub organisation . Proof-of-concept versus sustainable: each repository shall indicate its status: either proof-of-concept , or sustainable . Proof-of-concept code is meant to work but comes without quality assurance. Software repositories with proof-of-concept developments shall clearly say so in the first paragraph of the README.md file. Sustainable code should undergo standard quality checks , and point out its documentation . Sustainable code shall undergo code review ; no direct commits to master; any commit shall come in the form of a PR, commit after review. Sustainable code shall be written in a Test-driven manner , and repositories shall at the top of their README.md give indication of the degree to which code is covered by tests. Continuous integration shall be used to indicate code currently passes its test on CI platforms. A Code of conduct describes the rules and constraints to developers and contributors. Version numbers of sustainable software releases shall follow Semantic Versioning 2.0.0 . Software quality guidelines \u00b6 software shall be written in such a way that another person can understand its intention comment lines shall be used sparsely, but effectively reuse of unstable or esoteric libraries shall be avoided Software documentation guidelines \u00b6 Software documentation shall include: installation instructions usage instructions explain in detail the intention of the software pointers to reference documents explaining overarching concepts Each repository's README.md shall point to the documentation. Reference documentation shall be written using well-defined reference documentation language, such as RFC2119 or arc42 , and refer to the definitions used. Software review \u00b6 sustainable software development shall take place by always having two persons involved in a change to the master branch: individuals push to branches, pull request indicate readiness to be taken up in the master branch, a second developer reviews the pull request before merging it into the master branch. software review discussions shall be intelligible for external developers, and serve as implicit documentation of development decisions taken Test-driven development \u00b6 Software shall be developed in a test-driven fashion, meaning that while the code is written, tests are developed that verify, to a reasonable extent, the correctness of the code. Tools such as codecov.io to automatically indicate the amount of code covered by tests, and code that is not covered by tests shall be used in combination with a continuous integration framework. Continuous integration \u00b6 Repositories containing running software shall use an appropriate continuous integration platform, such as Travis CI or similar, to show whether the current build passes all checks. This helps understand contributors that the software passes tests on an independent platform, and may give insights in the way the software is compiled, deployed and tested. Additional guidelines \u00b6 There a specific guidelines for client library development and API development .","title":"Software Development"},{"location":"guidelines-software/#software-development-guidelines","text":"This document describes guidelines for software developers, written for the openEO project. Since the openEO infrastructure will encompasses several programming languages and software environments, this document does not prescribe particular tools or platforms but rather focuses on general principles and methods behind them. License: all software developed in the openEO project and published on the openEO GitHub organisation shall be licensed under the Apache 2.0 license . If software repositories deviate from this, or contain code or other artifacts that deviates from this, this shall be described in the README.md file. Location: Official openEO software is developed under the openEO GitHub organisation . Proof-of-concept versus sustainable: each repository shall indicate its status: either proof-of-concept , or sustainable . Proof-of-concept code is meant to work but comes without quality assurance. Software repositories with proof-of-concept developments shall clearly say so in the first paragraph of the README.md file. Sustainable code should undergo standard quality checks , and point out its documentation . Sustainable code shall undergo code review ; no direct commits to master; any commit shall come in the form of a PR, commit after review. Sustainable code shall be written in a Test-driven manner , and repositories shall at the top of their README.md give indication of the degree to which code is covered by tests. Continuous integration shall be used to indicate code currently passes its test on CI platforms. A Code of conduct describes the rules and constraints to developers and contributors. Version numbers of sustainable software releases shall follow Semantic Versioning 2.0.0 .","title":"Software Development Guidelines"},{"location":"guidelines-software/#software-quality-guidelines","text":"software shall be written in such a way that another person can understand its intention comment lines shall be used sparsely, but effectively reuse of unstable or esoteric libraries shall be avoided","title":"Software quality guidelines"},{"location":"guidelines-software/#software-documentation-guidelines","text":"Software documentation shall include: installation instructions usage instructions explain in detail the intention of the software pointers to reference documents explaining overarching concepts Each repository's README.md shall point to the documentation. Reference documentation shall be written using well-defined reference documentation language, such as RFC2119 or arc42 , and refer to the definitions used.","title":"Software documentation guidelines"},{"location":"guidelines-software/#software-review","text":"sustainable software development shall take place by always having two persons involved in a change to the master branch: individuals push to branches, pull request indicate readiness to be taken up in the master branch, a second developer reviews the pull request before merging it into the master branch. software review discussions shall be intelligible for external developers, and serve as implicit documentation of development decisions taken","title":"Software review"},{"location":"guidelines-software/#test-driven-development","text":"Software shall be developed in a test-driven fashion, meaning that while the code is written, tests are developed that verify, to a reasonable extent, the correctness of the code. Tools such as codecov.io to automatically indicate the amount of code covered by tests, and code that is not covered by tests shall be used in combination with a continuous integration framework.","title":"Test-driven development"},{"location":"guidelines-software/#continuous-integration","text":"Repositories containing running software shall use an appropriate continuous integration platform, such as Travis CI or similar, to show whether the current build passes all checks. This helps understand contributors that the software passes tests on an independent platform, and may give insights in the way the software is compiled, deployed and tested.","title":"Continuous integration"},{"location":"guidelines-software/#additional-guidelines","text":"There a specific guidelines for client library development and API development .","title":"Additional guidelines"},{"location":"jobs/","text":"Processing data using a process graph \u00b6 Process graphs can be executed in three different ways. Results can be pre-computed by creating a batch job using POST /jobs . They are submitted to the back office's processing system, but will remain inactive until POST /jobs/{job_id}/results has been called. They will run only once and store results after execution. Results can be downloaded. Batch jobs are typically time consuming such that user interaction is not possible. Another way of processing and accessing data are secondary web services . They allow web-based access using different protocols such as OGC WMS , OGC WCS or XYZ tiles . These protocols usually allow users to change the viewing extent or level of detail (zoom level). Therefore, computations may run on demand , i.e. the requested data is calculated during the request. Back-ends should make sure to cache processed data to avoid additional/high costs and waiting times for the user. Process graphs can also be executed synchronously ( POST /jobs/previews ). Results are delivered with the request itself and no job is created. Only lightweight computations, for example small previews, should be executed using this approach as timeouts are to be expected for long-polling HTTP requests . Data processing details \u00b6 Heterogeneous datasets are unified by the back-ends based on the processes in the process graphs. For instance, the difference between a PROBA-V image and a Sentinel image, which have e a different projection and resolution, are automatically resampled and projected by the back-ends as soon as it is required to do so. Clients are not responsible to ensure that the data matches by first applying resampling or projections processes. Temporal references are always specified on the basis of the Gregorian calendar . Examples \u00b6 Synchronously executed jobs \u00b6 Retrieval of a GeoTIFF Request POST /preview HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"process_graph\" :{ \"process_id\" : \"min_time\" , \"imagery\" :{ \"process_id\" : \"NDVI\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"S2_L2A_T32TPS_20M\" }, \"extent\" :{ \"west\" : 672000 , \"south\" : 5181000 , \"east\" : 652000 , \"north\" : 5161000 , \"crs\" : \"EPSG:32632\" } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"red\" : \"B04\" , \"nir\" : \"B8A\" } }, \"output\" :{ \"format\" : \"GTiff\" , \"args\" :{ \"tiled\" : true , \"compress\" : \"jpeg\" , \"photometric\" : \"YCBCR\" , \"jpeg_quality\" : 80 } } } Response HTTP / 1.1 200 OK Content-Type : image/tiff Access-Control-Allow-Origin : <Origin> omitted (the GeoTiff file contents) Retrieval of time series Request POST /preview HTTP / 1.1 Content-Type : application/json; charset=utf-8 { \"process_graph\" :{ \"process_id\" : \"zonal_statistics\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel2-L1C\" }, \"bands\" : 8 }, \"extent\" :{ \"west\" : 16.1 , \"south\" : 47.2 , \"east\" : 16.6 , \"north\" : 48.6 } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , null ] }, \"regions\" : \"/users/me/files/\" , \"func\" : \"avg\" }, \"output\" :{ \"format\" : \"GPKG\" } } Response HTTP / 1.1 200 OK Content-Type : application/octet-stream Access-Control-Allow-Origin : <Origin> omitted (the GeoPackage file contents)","title":"Jobs"},{"location":"jobs/#processing-data-using-a-process-graph","text":"Process graphs can be executed in three different ways. Results can be pre-computed by creating a batch job using POST /jobs . They are submitted to the back office's processing system, but will remain inactive until POST /jobs/{job_id}/results has been called. They will run only once and store results after execution. Results can be downloaded. Batch jobs are typically time consuming such that user interaction is not possible. Another way of processing and accessing data are secondary web services . They allow web-based access using different protocols such as OGC WMS , OGC WCS or XYZ tiles . These protocols usually allow users to change the viewing extent or level of detail (zoom level). Therefore, computations may run on demand , i.e. the requested data is calculated during the request. Back-ends should make sure to cache processed data to avoid additional/high costs and waiting times for the user. Process graphs can also be executed synchronously ( POST /jobs/previews ). Results are delivered with the request itself and no job is created. Only lightweight computations, for example small previews, should be executed using this approach as timeouts are to be expected for long-polling HTTP requests .","title":"Processing data using a process graph"},{"location":"jobs/#data-processing-details","text":"Heterogeneous datasets are unified by the back-ends based on the processes in the process graphs. For instance, the difference between a PROBA-V image and a Sentinel image, which have e a different projection and resolution, are automatically resampled and projected by the back-ends as soon as it is required to do so. Clients are not responsible to ensure that the data matches by first applying resampling or projections processes. Temporal references are always specified on the basis of the Gregorian calendar .","title":"Data processing details"},{"location":"jobs/#examples","text":"","title":"Examples"},{"location":"jobs/#synchronously-executed-jobs","text":"","title":"Synchronously executed jobs"},{"location":"processes/","text":"Processes \u00b6 A process is an operation that performs a specific task, see the glossary for a detailed definition. It consists of a name, a set of parameters, a return type and may throw errors or exceptions. In openEO, processes are used to build a chain of processes ( process graph ), which can be applied to EO data to derive your own findings from the data. Core processes \u00b6 There are some processes that we define to be core processes that are pre-defined and back-ends SHOULD follow these specifications to be interoperable. Not all processes need to be implemented by all back-ends. See the process reference for pre-defined processes. Defining processes \u00b6 Any back-end provider can either implement a set of pre-defined processes (STRONGLY RECOMMENDED) or define new processes for their domain. To define new processes, back-end providers should consider: The name is the identifier for the process and MUST only contain a forward slash / . Each parameter has a name and the content follows a schema. The content returned by a process also follows a schema. The schema usually defines the data type and a format according to JSON schema. There are openEO specific formats defined below. openEO specific formats \u00b6 In addition to the native data formats specified by JSON schema, openEO defines a set of specific formats that should be re-used in process schema definitions: Format Name Description callback An openEO process graph that is passed as an argument and is expected to be execute by the process. date Date only representation, as defined for full-date by RFC 3339 in section 5.6 . The time zone is UTC. date-time Date and time representation, as defined for date-time by RFC 3339 in section 5.6 . geojson GeoJSON as defined by RFC 7946 . JSON Schemas for validation are available. raster-cube A raster data cube, an image collection stored at the back-end. Different back-ends have different internal representations for this data structure. time Time only representation, as defined for full-time by RFC 3339 in section 5.6 . vector-cube A vector data cube, a vector collection stored at the back-end. Different back-ends have different internal representations for this data structure","title":"Processes"},{"location":"processes/#processes","text":"A process is an operation that performs a specific task, see the glossary for a detailed definition. It consists of a name, a set of parameters, a return type and may throw errors or exceptions. In openEO, processes are used to build a chain of processes ( process graph ), which can be applied to EO data to derive your own findings from the data.","title":"Processes"},{"location":"processes/#core-processes","text":"There are some processes that we define to be core processes that are pre-defined and back-ends SHOULD follow these specifications to be interoperable. Not all processes need to be implemented by all back-ends. See the process reference for pre-defined processes.","title":"Core processes"},{"location":"processes/#defining-processes","text":"Any back-end provider can either implement a set of pre-defined processes (STRONGLY RECOMMENDED) or define new processes for their domain. To define new processes, back-end providers should consider: The name is the identifier for the process and MUST only contain a forward slash / . Each parameter has a name and the content follows a schema. The content returned by a process also follows a schema. The schema usually defines the data type and a format according to JSON schema. There are openEO specific formats defined below.","title":"Defining processes"},{"location":"processes/#openeo-specific-formats","text":"In addition to the native data formats specified by JSON schema, openEO defines a set of specific formats that should be re-used in process schema definitions: Format Name Description callback An openEO process graph that is passed as an argument and is expected to be execute by the process. date Date only representation, as defined for full-date by RFC 3339 in section 5.6 . The time zone is UTC. date-time Date and time representation, as defined for date-time by RFC 3339 in section 5.6 . geojson GeoJSON as defined by RFC 7946 . JSON Schemas for validation are available. raster-cube A raster data cube, an image collection stored at the back-end. Different back-ends have different internal representations for this data structure. time Time only representation, as defined for full-time by RFC 3339 in section 5.6 . vector-cube A vector data cube, a vector collection stored at the back-end. Different back-ends have different internal representations for this data structure","title":"openEO specific formats"},{"location":"processgraphs/","text":"Process graphs \u00b6 A process graph is a chain of specific processes . Similarly to scripts in the context of programming, process graphs organize and automate the execution of one or more processes that could alternatively be executed individually. In a process graph, processes need to be specific, i.e. concrete values for input parameters need to be specified. These arguments can again be process graphs, scalar values, arrays or objects. Schematic definition \u00b6 A process graph is defined to consist of chained processes: <ProcessGraph> := <Process> An argument value of a process can hold a Process again. This allows chaining of processes. Process \u00b6 A single process in a process graph is defined as follows: <Process> := { \"process_id\": <string>, \"process_description\": <string>, \"<ArgumentName>\": <Value>, ... } A process MUST always contain a key-value-pair named process_id and MAY contain a process_description . It MAY hold an arbitrary number of additional elements as arguments for the process. process_id can contain any of the processes defined by a back-end, which are all listed at GET /processes , e.g. get_collection to retrieve data from a specific collection for processing. Arguments \u00b6 A process can have an arbitrary number of arguments. The key <ArgumentName> can be any valid JSON key, but it is RECOMMENDED to use snake case and limit the characters to a-z , 0-9 and _ . <ArgumentName> MUST NOT use the names process_id or process_description as it would result in a naming conflict. A value is defined as follows: <Value> := <string|number|boolean|null|array|object|Process|Variable> Note \u200b The specified data types except Process and Variable (see definition above) are the native data types supported by JSON. Limitations apply: \u200b * Objects are not allowed to have keys with the following names: \u200b * process_id , except for objects of type Process \u200b * variable_id , except for objects of type Variable Caution \u200b The expected names of arguments are defined by the process descriptions, which can be discovered with calls to GET /processes . Therefore, the key name for a key-value-pair holding an image collection as value doesn't necessarily need to be named imagery . The name depends on the name of the corresponding process argument the image collection is assigned to. Example 2 demonstrates this by using collection as a key once. Variables \u00b6 Process graphs can also hold a variable, which can be filled in later. For shared process graphs this can be useful to make them more portable, e.g in case a back-end specific product name would be stored with the process graph. Variables are defined as follows: <Variable> := { \"variable_id\": <string>, \"description\": <string>, \"type\": <string>, \"default\": <Value> } The value for type is the expected data type for the content of the variable and MUST be one of string (default), number , boolean , array or object . The value for variable_id is the name of the variable and can be any valid JSON key, but it is RECOMMENDED to use snake case and limit the characters to a-z , 0-9 and _ . Whenever no value for the variable is defined, the default value is used. <Value> can be used as defined above, but MUST NOT be a Variable . Values for variables can be specified in the query string or body of endpoints supporting variables. See the API reference for more information. Examples \u00b6 Example 1: A full process graph definition including a variable for the collection name . { \"process_id\" : \"min_time\" , \"imagery\" :{ \"process_id\" : \"/udf/Python/custom_ndvi\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" :{ \"variable_id\" : \"product\" , \"description\" : \"Identifier of the collection\" , \"type\" : \"string\" , \"default\" : \"S2_L2A_T32TPS_20M\" } }, \"extent\" :{ \"west\" : 652000 , \"south\" : 5181000 , \"east\" : 672000 , \"north\" : 5161000 , \"crs\" : \"EPSG:32632\" } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"red\" : \"B04\" , \"nir\" : \"B8A\" } } Example 2: If a process needs multiple processes as input, it is allowed to use arrays of the respective types. { \"imagery\" :{ \"process_id\" : \"union\" , \"collection\" :[ { \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel2-L1C\" }, \"bands\" : \"8\" }, { \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel2-L1C\" }, \"bands\" : \"5\" } ] } }","title":"Process Graphs"},{"location":"processgraphs/#process-graphs","text":"A process graph is a chain of specific processes . Similarly to scripts in the context of programming, process graphs organize and automate the execution of one or more processes that could alternatively be executed individually. In a process graph, processes need to be specific, i.e. concrete values for input parameters need to be specified. These arguments can again be process graphs, scalar values, arrays or objects.","title":"Process graphs"},{"location":"processgraphs/#schematic-definition","text":"A process graph is defined to consist of chained processes: <ProcessGraph> := <Process> An argument value of a process can hold a Process again. This allows chaining of processes.","title":"Schematic definition"},{"location":"processgraphs/#process","text":"A single process in a process graph is defined as follows: <Process> := { \"process_id\": <string>, \"process_description\": <string>, \"<ArgumentName>\": <Value>, ... } A process MUST always contain a key-value-pair named process_id and MAY contain a process_description . It MAY hold an arbitrary number of additional elements as arguments for the process. process_id can contain any of the processes defined by a back-end, which are all listed at GET /processes , e.g. get_collection to retrieve data from a specific collection for processing.","title":"Process"},{"location":"processgraphs/#arguments","text":"A process can have an arbitrary number of arguments. The key <ArgumentName> can be any valid JSON key, but it is RECOMMENDED to use snake case and limit the characters to a-z , 0-9 and _ . <ArgumentName> MUST NOT use the names process_id or process_description as it would result in a naming conflict. A value is defined as follows: <Value> := <string|number|boolean|null|array|object|Process|Variable> Note \u200b The specified data types except Process and Variable (see definition above) are the native data types supported by JSON. Limitations apply: \u200b * Objects are not allowed to have keys with the following names: \u200b * process_id , except for objects of type Process \u200b * variable_id , except for objects of type Variable Caution \u200b The expected names of arguments are defined by the process descriptions, which can be discovered with calls to GET /processes . Therefore, the key name for a key-value-pair holding an image collection as value doesn't necessarily need to be named imagery . The name depends on the name of the corresponding process argument the image collection is assigned to. Example 2 demonstrates this by using collection as a key once.","title":"Arguments"},{"location":"processgraphs/#variables","text":"Process graphs can also hold a variable, which can be filled in later. For shared process graphs this can be useful to make them more portable, e.g in case a back-end specific product name would be stored with the process graph. Variables are defined as follows: <Variable> := { \"variable_id\": <string>, \"description\": <string>, \"type\": <string>, \"default\": <Value> } The value for type is the expected data type for the content of the variable and MUST be one of string (default), number , boolean , array or object . The value for variable_id is the name of the variable and can be any valid JSON key, but it is RECOMMENDED to use snake case and limit the characters to a-z , 0-9 and _ . Whenever no value for the variable is defined, the default value is used. <Value> can be used as defined above, but MUST NOT be a Variable . Values for variables can be specified in the query string or body of endpoints supporting variables. See the API reference for more information.","title":"Variables"},{"location":"processgraphs/#examples","text":"Example 1: A full process graph definition including a variable for the collection name . { \"process_id\" : \"min_time\" , \"imagery\" :{ \"process_id\" : \"/udf/Python/custom_ndvi\" , \"imagery\" :{ \"process_id\" : \"filter_daterange\" , \"imagery\" :{ \"process_id\" : \"filter_bbox\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" :{ \"variable_id\" : \"product\" , \"description\" : \"Identifier of the collection\" , \"type\" : \"string\" , \"default\" : \"S2_L2A_T32TPS_20M\" } }, \"extent\" :{ \"west\" : 652000 , \"south\" : 5181000 , \"east\" : 672000 , \"north\" : 5161000 , \"crs\" : \"EPSG:32632\" } }, \"extent\" :[ \"2017-01-01T00:00:00Z\" , \"2017-01-31T23:59:59Z\" ] }, \"red\" : \"B04\" , \"nir\" : \"B8A\" } } Example 2: If a process needs multiple processes as input, it is allowed to use arrays of the respective types. { \"imagery\" :{ \"process_id\" : \"union\" , \"collection\" :[ { \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel2-L1C\" }, \"bands\" : \"8\" }, { \"process_id\" : \"filter_bands\" , \"imagery\" :{ \"process_id\" : \"get_collection\" , \"name\" : \"Sentinel2-L1C\" }, \"bands\" : \"5\" } ] } }","title":"Examples"},{"location":"processreference/","text":"Placeholder for generated process specifications.","title":"Process Reference"},{"location":"udfs/","text":"User-defined functions \u00b6 The abbreviation UDF stands for user-defined function . With this concept, users are able to upload custom code and have it executed e.g. for every pixel of a scene, allowing custom calculations on server-side data. UDFs are currently developed and evaluated outside of the core API. More information regarding the current draft for UDFs can be found in a separate repository . There is additional documentation available for the UDF Framework and the UDF API .","title":"UDFs"},{"location":"udfs/#user-defined-functions","text":"The abbreviation UDF stands for user-defined function . With this concept, users are able to upload custom code and have it executed e.g. for every pixel of a scene, allowing custom calculations on server-side data. UDFs are currently developed and evaluated outside of the core API. More information regarding the current draft for UDFs can be found in a separate repository . There is additional documentation available for the UDF Framework and the UDF API .","title":"User-defined functions"},{"location":"usermanagement/","text":"User Management and Accounting \u00b6 In general, the openEO API only defines a minimum subset of user management and accounting functionality. It allows to authenticate and authorize a user, which may include user registration with OpenID Connect , handle storage space limits (disk quota), manage billing, which includes to query the credit a user has available, estimate costs for certain operations (data processing and downloading), get information about produced costs, limit costs of certain operations. Therefore, the API leaves some aspects open that have to be handled by the back-ends separately, including credential recovery, e.g. retrieving a forgotten password user data management, e.g. changing the users payment details or email address payments, i.e. topping up credits for pre-paid services or paying for post-paid services other accounting related tasks, e.g. creating invoices, user registration (only specified when OpenID Connect is implemented).","title":"User Management and Accounting"},{"location":"usermanagement/#user-management-and-accounting","text":"In general, the openEO API only defines a minimum subset of user management and accounting functionality. It allows to authenticate and authorize a user, which may include user registration with OpenID Connect , handle storage space limits (disk quota), manage billing, which includes to query the credit a user has available, estimate costs for certain operations (data processing and downloading), get information about produced costs, limit costs of certain operations. Therefore, the API leaves some aspects open that have to be handled by the back-ends separately, including credential recovery, e.g. retrieving a forgotten password user data management, e.g. changing the users payment details or email address payments, i.e. topping up credits for pre-paid services or paying for post-paid services other accounting related tasks, e.g. creating invoices, user registration (only specified when OpenID Connect is implemented).","title":"User Management and Accounting"}]}